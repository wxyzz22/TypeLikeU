{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7w5XGhYI8Dka",
        "bdq7roqd_P1r",
        "1xUDr6ev_st6",
        "a3Sx1uf9LeQ-",
        "MUMZX-e33kAr",
        "JGIvDDoD7JS9",
        "rYEaDSDUyoJb",
        "ZHPoTbzqgkTY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/COMP576/training-logs/tensorboard')\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import os\n",
        "import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "tf.config.list_physical_devices('GPU')\n",
        "!nvidia-smi\n",
        "\n",
        "!pip install importnb\n",
        "# import our preprocessing from ipynb\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/COMP576/final-project')\n",
        "from importnb import Notebook\n",
        "with Notebook():\n",
        "    import KDR_Preprocessing as prep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM5oCAJOMYc8",
        "outputId": "d97f7272-aa3c-4cf3-a5c1-c6737c61722a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Wed Dec  7 21:25:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    27W /  70W |      3MiB / 15109MiB |      4%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting importnb\n",
            "  Downloading importnb-2022.10.24-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: importnb\n",
            "Successfully installed importnb-2022.10.24\n",
            "Hello from KDR_Preprocessing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "qP336BCU2Lf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate `data, train_data, test_data, uni_encoder, di_encoder`\n",
        "\n",
        "* `data, train_data, test_data, uni_encoder, di_encoder = processing_folder(folder_path, sample_size, train_size)`"
      ],
      "metadata": {
        "id": "ouBlEizy2Phm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processing_folder(folder_path, sample_size, train_size):\n",
        "    os.chdir(folder_path)\n",
        "    files = sorted(os.listdir(folder_path), key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
        "    train_samples = []\n",
        "    test_samples = []\n",
        "    samples = []\n",
        "    cols = []\n",
        "    # text_count_id = 0\n",
        "    for i, path in enumerate(files):\n",
        "        if i >= sample_size:\n",
        "            break\n",
        "        with open(path, encoding='utf-8',           ##https://stackoverflow.com/questions/12468179/unicodedecodeerror-utf8-codec-cant-decode-byte-0x9c\n",
        "                 errors='ignore') as f:\n",
        "            lines = f.readlines()\n",
        "        ## extract column names (once)\n",
        "        if i == 0:\n",
        "            ls = lines[0].split('\\t')\n",
        "            if re.findall(r'\\w+|\\d+', ls[-1]):\n",
        "                ls[-1] = re.findall(r'\\w+|\\d+', ls[-1])[0]\n",
        "                cols = ls\n",
        "        ## extracting all samples from the current file\n",
        "        sample = []\n",
        "        curr_text_id = ''\n",
        "        curr_index = -1\n",
        "        for line in lines[1:]:\n",
        "            ls = line.split('\\t')\n",
        "            if re.findall(r'\\w+|\\d+', ls[-1]):\n",
        "                ls[-1] = re.findall(r'\\w+|\\d+', ls[-1])[0]\n",
        "                if ls[1] != curr_text_id:\n",
        "                    curr_index = 0\n",
        "                    curr_text_id = ls[1]\n",
        "                    # text_count_id += 1\n",
        "                else:\n",
        "                    curr_index += 1\n",
        "                # ls.extend([curr_index, text_count_id])\n",
        "                ls.append(curr_index)\n",
        "                sample.append(ls)\n",
        "        ##  split the current data into train-test-sets\n",
        "        split_index = int(train_size * len(sample))\n",
        "        train_samples = train_samples + sample[:split_index]\n",
        "        test_samples = test_samples + sample[split_index:]\n",
        "        samples = samples + sample\n",
        "    ## forming dataframes\n",
        "    df_all = pd.DataFrame(samples)\n",
        "    df_train = pd.DataFrame(train_samples)\n",
        "    df_test = pd.DataFrame(test_samples)\n",
        "    ## renaming columns\n",
        "    # cols = cols + ['INDEX'] + ['TEXT_COUNT_ID']\n",
        "    cols = cols + ['INDEX']\n",
        "    df_all.columns, df_train.columns, df_test.columns = cols, cols, cols\n",
        "    ## construct onehot encoders from train data\n",
        "    df_train['K1'], df_train['K2'] = df_train['KEYCODE'], df_train['KEYCODE']\n",
        "    KEYCODE_enc = OneHotEncoder(handle_unknown='ignore').fit(df_train[['KEYCODE']])\n",
        "    K1_enc = OneHotEncoder(handle_unknown='ignore').fit(df_train[['K1']])\n",
        "    K2_enc = OneHotEncoder(handle_unknown='ignore').fit(df_train[['K2']])\n",
        "    K1_K2_enc = OneHotEncoder(handle_unknown='ignore').fit(df_train[['K1', 'K2']])\n",
        "    df_train = df_train.drop(columns=['K1', 'K2'])\n",
        "    return df_all, df_train, df_test, KEYCODE_enc, K1_K2_enc, K1_enc, K2_enc"
      ],
      "metadata": {
        "id": "GOlJBw-D1aMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keyboard Dictionary\n",
        "\n",
        "* `keyboard_dict = Keyboard(get_qwerty_keyboard()).keyboard_dict()`"
      ],
      "metadata": {
        "id": "DwKv3fIT2VzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_qwerty_keyboard():\n",
        "    first_row = [27, 27, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 0, 0, 145, 126, 0, 0, 0, 0, 0]\n",
        "    space = [0] * 23\n",
        "    second_row = [192, 49, 50, 51, 52, 53, 54, 55, 56, 57, 48, 189, 187, 8, 0, 45, 36, 33, 0, 144, 111, 106, 109]\n",
        "    third_row = [9, 81, 87, 69, 82, 84, 89, 85, 73, 79, 80, 219, 221, 220, 0, 46, 35, 34, 0, 103, 104, 105, 107]\n",
        "    fourth_row = [20, 65, 83, 68, 70, 71, 72, 74, 75, 76, 186, 222, 13, 13, 0, 0, 0, 0, 0, 100, 101, 102, 107]\n",
        "    fifth_row = [16, 16, 90, 88, 67, 86, 66, 78, 77, 188, 190, 191, 16, 16, 0, 0, 38, 0, 0, 97, 98, 99, 13]\n",
        "    sixth_row = [17, 17, 191, 18, 32, 32, 32, 32, 32, 18, 92, 93, 17, 17, 0, 37, 40, 39, 0, 96, 96, 110, 13]\n",
        "    qwerty_keyboard = pd.DataFrame({'1st': first_row,\n",
        "                                    'space': space,\n",
        "                                    '2nd': second_row,\n",
        "                                    '3rd': third_row,\n",
        "                                    '4th': fourth_row,\n",
        "                                    '5th': fifth_row,\n",
        "                                    '6th': sixth_row}).transpose()\n",
        "    qwerty_keyboard.index = list(range(7))\n",
        "    return qwerty_keyboard\n",
        "\n",
        "class Keyboard:\n",
        "    def __init__(self, keyboard_df):\n",
        "        self.keyboard = keyboard_df\n",
        "        self.keycode_pos = self.get_keycode_pos()\n",
        "    \n",
        "    def get_keycode_pos(self):\n",
        "        '''\n",
        "        Generates Python dictionary encoding the keyboard keycode positions, i.e.\n",
        "              - keys = javascript keycode\n",
        "              - values = [i, j] of the corresponding keycode position on the keyboard\n",
        "        Return: Python dict\n",
        "        '''\n",
        "        keyboard_dict = {}\n",
        "        for row in self.keyboard.index:\n",
        "            for col, entry in enumerate(self.keyboard.iloc[row, :]):\n",
        "                if entry in keyboard_dict:\n",
        "                    keyboard_dict[entry].append([row, col])\n",
        "                else:\n",
        "                    keyboard_dict[entry] = [[row, col]]\n",
        "        return keyboard_dict\n",
        "        \n",
        "    def keycode_distance(self, keycode1, keycode2):\n",
        "        '''\n",
        "        Given a pair of keycodes, return their relative distance on the keyboard\n",
        "        '''\n",
        "        keycode1 = int(keycode1)\n",
        "        keycode2 = int(keycode2)\n",
        "        def manhattan_dist(arr1, arr2):\n",
        "            return abs(arr1[0] - arr2[0]) + abs(arr1[1] - arr2[1])\n",
        "        distance = 30 ## any integer larger than 22+6\n",
        "        if keycode1 in self.keycode_pos and keycode2 in self.keycode_pos:\n",
        "            for arr1 in self.keycode_pos[keycode1]:\n",
        "                for arr2 in self.keycode_pos[keycode2]:\n",
        "                    curr_dist = manhattan_dist(arr1, arr2)\n",
        "                    if curr_dist < distance:\n",
        "                        distance = curr_dist\n",
        "            if distance < 5:\n",
        "                return distance\n",
        "        return 5\n",
        "    \n",
        "    def home_distance(self, keycode_list):\n",
        "        '''\n",
        "        Computes the AVERAGE distance of a list of keycodes to the home keys, where\n",
        "        In QWERTY keyboard, F and J are the home keys with keycodes 70 and 74 resp.\n",
        "        '''\n",
        "        sum = 0\n",
        "        for key in keycode_list:\n",
        "            key = int(key)\n",
        "            sum += min([self.keycode_distance(70, key), self.keycode_distance(74, key)])\n",
        "        return sum/len(keycode_list)\n",
        "    \n",
        "    def keyboard_dict(self):\n",
        "        return {'keycode': self.keycode_distance, 'home': self.home_distance}"
      ],
      "metadata": {
        "id": "LDGlcTFz2Dvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extractor \n",
        "\n",
        "* `train_extractor = Extractors(train_data, keyboard_dict, avg_mode, add_layout, remove_outliers, conn_latency)`\n",
        "\n",
        "* unigraph dataframe = `train_extractor.unigraph`\n",
        "* digraph dataframe = `train_extractor.digraph`\n",
        "* key-only dataframe (i.e. unigraph with no PL) = `train_extractor.key_only`"
      ],
      "metadata": {
        "id": "25dvty2B2rAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Extractors:\n",
        "    def __init__(self, sub_data, keyboard_dict, latencies):\n",
        "        self.keyboard_dict = keyboard_dict\n",
        "        self.latencies = latencies\n",
        "\n",
        "        self.unigraph = self.unigraph_extractor(sub_data)\n",
        "        self.digraph = self.digraph_extractor(sub_data)\n",
        "    \n",
        "    def unigraph_extractor(self, df, user_str=True, keycode_str=True, drop_user=False):\n",
        "        df = df[['PARTICIPANT_ID', 'TEST_SECTION_ID', 'PRESS_TIME', 'RELEASE_TIME', 'KEYCODE', 'INDEX']]\n",
        "        df = df.astype('float64')\n",
        "        if user_str:\n",
        "            df['PARTICIPANT_ID'] = df['PARTICIPANT_ID'].astype('int64').astype(str)\n",
        "        df = df.rename(columns={'PARTICIPANT_ID': 'USER'})\n",
        "        if drop_user:\n",
        "            df = df.drop(columns=['USER'])\n",
        "        if keycode_str:\n",
        "            df['KEYCODE'] = df['KEYCODE'].astype('int64').astype(str)\n",
        "        ## construct new features\n",
        "        if 'HL' in self.latencies:\n",
        "            df['HL'] = df['RELEASE_TIME'] - df['PRESS_TIME']\n",
        "        if 'IL' in self.latencies:\n",
        "            df['IL'] = pd.concat([df['PRESS_TIME'][1:], pd.Series([0])], ignore_index=True) - df['RELEASE_TIME']\n",
        "        if 'RL' in self.latencies:\n",
        "            df['RL'] = pd.concat([df['RELEASE_TIME'][1:], pd.Series([0])], ignore_index=True) - df['RELEASE_TIME']\n",
        "        if 'PL' in self.latencies:\n",
        "            df['PL'] = pd.concat([df['PRESS_TIME'][1:], pd.Series([0])], ignore_index=True) - df['PRESS_TIME']\n",
        "        ## dropping rows where the NEXT row has INDEX==0 (indicating a transition to next sentence)\n",
        "        shift_txt = pd.concat([df['TEST_SECTION_ID'][1:], df['TEST_SECTION_ID'][-1:]], ignore_index=True) - df['TEST_SECTION_ID']\n",
        "        mask = shift_txt == 0\n",
        "        df = df.loc[mask]\n",
        "        ## cleaning irrelavant info\n",
        "        df = df.drop(columns=['PRESS_TIME', 'RELEASE_TIME', 'TEST_SECTION_ID'])\n",
        "        df = df.iloc[:-1, :]\n",
        "        return df\n",
        "    \n",
        "    def digraph_extractor(self, df, user_str=True, keycode_str=True, drop_user=False):\n",
        "        df = df[['PARTICIPANT_ID', 'TEST_SECTION_ID', 'PRESS_TIME', 'RELEASE_TIME', 'KEYCODE', 'INDEX']]\n",
        "        df = df.astype('float64')\n",
        "        if user_str:\n",
        "            df['PARTICIPANT_ID'] = df['PARTICIPANT_ID'].astype('int64').astype(str)\n",
        "        df = df.rename(columns={'PARTICIPANT_ID': 'USER'})\n",
        "        if drop_user:\n",
        "            df = df.drop(columns=['USER'])\n",
        "        ## construct new features\n",
        "        df['K1'] = df['KEYCODE']\n",
        "        df['K2'] = pd.concat([df['KEYCODE'][1:], pd.Series([0])], ignore_index=True)\n",
        "        if keycode_str:\n",
        "            df['K1'] = df['K1'].astype('int64').astype(str)\n",
        "            df['K2'] = df['K2'].astype('int64').astype(str)\n",
        "        df['I1'] = df['INDEX']\n",
        "        df['I2'] = pd.concat([df['INDEX'][1:], pd.Series([0])], ignore_index=True)\n",
        "        if 'HL' in self.latencies:\n",
        "            df['HL1'] = df['RELEASE_TIME'] - df['PRESS_TIME']\n",
        "            df['HL2'] = pd.concat([df['HL1'][1:], pd.Series([0])], ignore_index=True)\n",
        "        if 'IL' in self.latencies:\n",
        "            df['IL'] = pd.concat([df['PRESS_TIME'][1:], pd.Series([0])], ignore_index=True) - df['RELEASE_TIME']\n",
        "        if 'RL' in self.latencies:\n",
        "            df['RL'] = pd.concat([df['RELEASE_TIME'][1:], pd.Series([0])], ignore_index=True) - df['RELEASE_TIME']\n",
        "        if 'PL' in self.latencies:\n",
        "            df['PL'] = pd.concat([df['PRESS_TIME'][1:], pd.Series([0])], ignore_index=True) - df['PRESS_TIME']\n",
        "        ## dropping instances where I2 is zero (indicating a transition to next sentence)\n",
        "        shift_txt = pd.concat([df['TEST_SECTION_ID'][1:], df['TEST_SECTION_ID'][-1:]], ignore_index=True) - df['TEST_SECTION_ID']\n",
        "        mask = shift_txt == 0\n",
        "        df = df.loc[mask]\n",
        "        ## cleaning irrelavant info\n",
        "        df = df.drop(columns=['PRESS_TIME', 'RELEASE_TIME', 'KEYCODE', 'INDEX', 'TEST_SECTION_ID'])\n",
        "        df = df.iloc[:-1, :]\n",
        "        return df\n",
        "    \n",
        "    ## https://towardsdatascience.com/do-you-use-apply-in-pandas-there-is-a-600x-faster-way-d2497facfa66\n",
        "    def digraph_avg(self, avg_mode, data=None, drop_origin=True, rename_avg=True, round_avg=True):\n",
        "        if data:\n",
        "            df = data.copy()\n",
        "        else:\n",
        "            df = self.digraph.copy()\n",
        "        df['K1_K2'] = df[['K1', 'K2']].apply(tuple, axis=1)\n",
        "        latencies = self.latencies.copy()\n",
        "        if 'HL' in latencies:\n",
        "            latencies.remove('HL')\n",
        "            latencies.insert(0, 'HL2')\n",
        "            latencies.insert(0, 'HL1')\n",
        "        for XL in latencies:\n",
        "            df[XL+'_avg'] = df[XL]\n",
        "        for pair in df['K1_K2'].unique():\n",
        "            mask = df['K1_K2'] == pair\n",
        "            if avg_mode == 'mean':\n",
        "                avg_df = df.loc[mask, latencies].mean()\n",
        "            else:\n",
        "                avg_df = df.loc[mask, latencies].median()\n",
        "            for XL in latencies:\n",
        "                df.loc[mask, XL+'_avg'] = avg_df[XL]\n",
        "        if round_avg:\n",
        "            for XL in latencies:\n",
        "                df[XL+'_avg'] = round(df[XL+'_avg'])\n",
        "        if drop_origin:\n",
        "            df = df.drop(columns=latencies+['K1_K2'])\n",
        "        if drop_origin and rename_avg:\n",
        "            df = df.rename(columns=lambda name: re.search(r'(.{2,3})(_avg)', name).group(1) if '_avg' in name else name)\n",
        "        return df\n",
        "\n",
        "    def unigraph_avg(self, avg_mode, data=None, drop_origin=True, rename_avg=True, round_avg=True):\n",
        "        if data:\n",
        "            df = data.copy()\n",
        "        else:\n",
        "            df = self.unigraph.copy()\n",
        "        for XL in self.latencies:\n",
        "            df[XL+'_avg'] = df[XL]\n",
        "        for keycode in df['KEYCODE'].unique():\n",
        "            mask = df['KEYCODE'] == keycode\n",
        "            if avg_mode == 'mean':\n",
        "                avg_df = df.loc[mask, self.latencies].mean()\n",
        "            else:\n",
        "                avg_df = df.loc[mask, self.latencies].median()\n",
        "            for XL in self.latencies:\n",
        "                df.loc[mask, XL+'_avg'] = avg_df[XL]\n",
        "        if round_avg:\n",
        "            for XL in self.latencies:\n",
        "                df[XL+'_avg'] = round(df[XL+'_avg'])\n",
        "        if drop_origin:\n",
        "            df = df.drop(columns=self.latencies)\n",
        "        if drop_origin and rename_avg:\n",
        "            df = df.rename(columns=lambda name: name[:2] if '_avg' in name else name)\n",
        "        return df\n",
        "    \n",
        "    def digraph_encode_keyboard(self):\n",
        "        df = self.digraph.copy()\n",
        "        keycode_dist = []\n",
        "        home_dist = []\n",
        "        for row in df.index:\n",
        "            keycode_dist.append(self.keyboard_dict['keycode'](df['K1'][row], df['K2'][row]))\n",
        "            home_dist.append(self.keyboard_dict['home']([df['K1'][row], df['K2'][row]]))\n",
        "        df['KD'] = keycode_dist\n",
        "        df['HD'] = home_dist\n",
        "        # cols = list(df.columns[:-5]) + list(df.columns[-2:]) + list(df.columns[-5:-2])\n",
        "        num_cols = len(df.columns)\n",
        "        cols = list(df.columns[:num_cols-2-(len(self.latencies)+1)]) + list(df.columns[-2:]) + list(df.columns[-2-(len(self.latencies)+1):-2])\n",
        "        df = df[cols]\n",
        "        return df\n",
        "    \n",
        "    def unigraph_encode_keyboard(self):\n",
        "        df = self.unigraph.copy()\n",
        "        home_dist = []\n",
        "        for row in df.index:\n",
        "            home_dist.append(self.keyboard_dict['home']([df['KEYCODE'][row]]))\n",
        "        df['HD'] = home_dist\n",
        "        # cols = list(df.columns[:-3]) + list(df.columns[-1:]) + list(df.columns[-3:-1])\n",
        "        num_cols = len(df.columns)\n",
        "        cols = list(df.columns[:num_cols-1-len(self.latencies)]) + list(df.columns[-1:]) + list(df.columns[-1-len(self.latencies):-1])\n",
        "        df = df[cols]\n",
        "        return df\n",
        "    \n",
        "    def filter_by_IQRs(self, data, folds, latencies):\n",
        "        df = data.copy()\n",
        "        for fold, latency in zip(folds, latencies):\n",
        "            for user in data['USER'].unique():\n",
        "                mask_user = data['USER'] == user\n",
        "                mask_non_user = data['USER'] != user\n",
        "                Q3 = data.loc[mask_user, latency].quantile(.75)\n",
        "                Q1 = data.loc[mask_user, latency].quantile(.25)\n",
        "                IQR = Q3 - Q1\n",
        "                max = Q3 + fold * IQR\n",
        "                min = Q1 - fold * IQR\n",
        "                mask_max = data[latency] <= max\n",
        "                mask_min = data[latency] >= min\n",
        "                df = df.loc[mask_user & mask_max & mask_min | mask_non_user]\n",
        "        return df"
      ],
      "metadata": {
        "id": "rMNTy58J2Idg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KDS_generator\n",
        "\n",
        "* `train_kds_uni = KDS(train_df_uni, n_steps, shift, batch_size, encoder=encoder_uni, mode='uni')`\n",
        "\n",
        "* input shapes = `train_kds_uni.inputA`, `train_kds_uni.inputB`, `train_kds_uni.output`\n",
        "* dataset input = `train_kds_uni.ds_in`\n",
        "* dataset output = `train_kds_uni.ds_out`\n",
        "* dataset (zipped) = `train_kds_uni.ds`"
      ],
      "metadata": {
        "id": "7w5XGhYI8Dka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KDS:\n",
        "    def __init__(self, df, output_dim, n_steps, shift, batch_size, encoders, enc_names, do_onehot=True):\n",
        "        self.df = df\n",
        "        self.window_length = n_steps + 1\n",
        "        self.n_steps = n_steps\n",
        "        self.shift = shift\n",
        "        self.batch = batch_size\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        for i, user in enumerate(self.df['USER'].unique()):\n",
        "            mask = self.df['USER'] == user\n",
        "            curr_df = self.df.loc[mask, :].drop(columns=['USER'])\n",
        "            ## One-hot on 'KEYCODE' (mode=='uni') OR 'K1', 'K2' (mode!='uni')\n",
        "            if len(encoders) == 1 and enc_names[0] == 'KEYCODE':\n",
        "                curr_df = np.concatenate([encoders[0].transform(curr_df[['KEYCODE']].astype(str)).toarray(), curr_df.drop(columns=['KEYCODE'])], axis=1)\n",
        "            elif len(encoders) == 1 and enc_names[0] == 'K1_K2':\n",
        "                curr_df = np.concatenate([encoders[0].transform(curr_df[['K1', 'K2']].astype(str)).toarray(), curr_df.drop(columns=['K1', 'K2'])], axis=1)\n",
        "            else:\n",
        "                k1_onehot = encoders[0].transform(curr_df[['K1']].astype(str)).toarray()\n",
        "                k2_onehot = encoders[1].transform(curr_df[['K2']].astype(str)).toarray()\n",
        "                curr_df = np.concatenate([k1_onehot+k2_onehot, curr_df.drop(columns=['K1', 'K2'])], axis=1)\n",
        "            ## get the TFDS dataset of inputs (inputA, inputB) and output\n",
        "            curr_in, curr_out = self.get_dataset(curr_df)\n",
        "            if i == 0:\n",
        "                self.ds_in = curr_in\n",
        "                self.ds_out = curr_out\n",
        "            else:\n",
        "                self.ds_in = self.ds_in.concatenate(curr_in)\n",
        "                self.ds_out = self.ds_out.concatenate(curr_out)\n",
        "        ## zip the TFDS inputs and output for easy access at training\n",
        "        self.ds = tf.data.Dataset.zip((self.ds_in, self.ds_out))\n",
        "        \n",
        "        for inputA, inputB in self.ds_in.take(1):\n",
        "            self.inputA = inputA.shape\n",
        "            self.inputB = inputB.shape\n",
        "        \n",
        "        for output in self.ds_out.take(1):\n",
        "            self.output = output.shape\n",
        "\n",
        "    def get_dataset(self, df):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(df).window(size=self.window_length, shift=self.shift, drop_remainder=True)\n",
        "        dataset = dataset.flat_map(lambda window: window.batch(self.window_length)).batch(self.batch)\n",
        "        ds_in = dataset.map(lambda window: (window[:, :self.n_steps, :], window[:, -1, :-self.output_dim]))\n",
        "        ds_in = ds_in.prefetch(tf.data.AUTOTUNE)\n",
        "        ds_out = dataset.map(lambda window: window[:, -1, -self.output_dim:])\n",
        "        ds_out = ds_out.prefetch(tf.data.AUTOTUNE)\n",
        "        return ds_in, ds_out"
      ],
      "metadata": {
        "id": "MR6XiEfg_C1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KDI_generator"
      ],
      "metadata": {
        "id": "sXbdCg4ghX9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KDI:\n",
        "    def __init__(self, train_data, df, n_steps, batch_size, mat_length, \n",
        "                 inputA_features, inputB_features, output_features, \n",
        "                 inputB_type='image', encoders=None, keep_smaller_window=False, add_UNK=True):\n",
        "        self.train_data = train_data\n",
        "        self.df = df\n",
        "        self.window_length = n_steps + 1\n",
        "        self.batch_size = batch_size\n",
        "        self.mat_length = mat_length\n",
        "\n",
        "        self.inputA_features = inputA_features\n",
        "        self.inputB_features = inputB_features\n",
        "        self.inputB_type = inputB_type                ## 'image', or 'onehot', else default to 'int'\n",
        "        self.output_features = output_features        ## output_features ('HL', 'XL' in ['PL', 'RL', 'IL'])\n",
        "\n",
        "        self.encoders = encoders\n",
        "        self.keep_smaller_window = keep_smaller_window\n",
        "        self.add_UNK = add_UNK\n",
        "\n",
        "        self.keycode_dict = self.keycode_topfreq_dict(top=self.mat_length-1)\n",
        "\n",
        "        self.inputA, self.inputB, self.output = self.kdi_training_data()\n",
        "        self.ds = self.generate_kds()\n",
        "\n",
        "\n",
        "    def keycode_topfreq_dict(self, top):\n",
        "        '''\n",
        "        generate dictionary for the most popular `top` many keycodes using training data\n",
        "        '''\n",
        "        keycode_dict = {keycode: i for i, keycode in enumerate(self.train_data['KEYCODE'].astype('int32').value_counts()[:top].to_dict().keys())}\n",
        "        if self.add_UNK:\n",
        "            keycode_dict[0] = len(keycode_dict)\n",
        "        return keycode_dict\n",
        "  \n",
        "\n",
        "    def single_input_image(self, curr_chunk, features, mat_length, keycode_dict):\n",
        "        mat_dict = {}\n",
        "        for feature in features:\n",
        "            mat_dict['mat_'+feature] = np.zeros((mat_length, mat_length))\n",
        "        mat_dict['count'] = np.zeros((mat_length, mat_length))\n",
        "\n",
        "        for row in curr_chunk.index:\n",
        "            i = int(curr_chunk.loc[row, 'K1'])\n",
        "            j = int(curr_chunk.loc[row, 'K2'])\n",
        "            if i in keycode_dict:\n",
        "                pos_i = keycode_dict[i]\n",
        "            else:\n",
        "                pos_i = keycode_dict[0]   ## pos_i = top (the last key-value pair)\n",
        "            if j in keycode_dict:\n",
        "                pos_j = keycode_dict[j]\n",
        "            else:\n",
        "                pos_j = keycode_dict[0]\n",
        "            for feature in features:\n",
        "                if feature != 'HL':\n",
        "                    mat_dict['mat_'+feature][pos_i, pos_j] += curr_chunk.loc[row, feature]\n",
        "                else:\n",
        "                    mat_dict['mat_'+feature][pos_i, pos_j] += (i + j) / 2\n",
        "            mat_dict['count'][pos_i, pos_j] += 1\n",
        "        mask_nonzero = mat_dict['count'] != 0\n",
        "        mat_ls = []\n",
        "        for feature in features:\n",
        "            mat_dict['mat_'+feature][mask_nonzero] = mat_dict['mat_'+feature][mask_nonzero] / mat_dict['count'][mask_nonzero]\n",
        "            mat_ls.append(mat_dict['mat_'+feature])\n",
        "        return np.stack(mat_ls, axis=-1)\n",
        "    \n",
        "\n",
        "    def single_kdi_input(self, curr_chunk):\n",
        "        last_index = curr_chunk.index[-1]\n",
        "        output_ls = []\n",
        "        for feature in self.output_features:\n",
        "            output_ls.append(curr_chunk.loc[last_index, feature])\n",
        "        output_np = np.array(output_ls)\n",
        "        ## inputA \n",
        "        inputA = self.single_input_image(curr_chunk.iloc[:-1], self.inputA_features, self.mat_length, self.keycode_dict)\n",
        "        ## inputB\n",
        "        if self.inputB_type == 'image':\n",
        "            inputB = self.single_input_image(curr_chunk.iloc[-1:], self.inputB_features, self.mat_length, self.keycode_dict)\n",
        "        elif self.inputB_type == 'onehot' and self.encoders:\n",
        "            if len(self.encoders) == 1:\n",
        "                inputB_keycode = self.encoders[0].transform(curr_chunk.loc[[last_index], ['K1', 'K2']].astype(str)).toarray()\n",
        "            else:\n",
        "                inputB_k1 = self.encoders[0].transform(curr_chunk.loc[[last_index], ['K1']].astype(str)).toarray()\n",
        "                inputB_k2 = self.encoders[1].transform(curr_chunk.loc[[last_index], ['K2']].astype(str)).toarray()\n",
        "                inputB_keycode = inputB_k1 + inputB_k2\n",
        "            inputB = np.concatenate([inputB_keycode, np.array(curr_chunk.loc[last_index, self.inputB_features])], axis=1)\n",
        "        else:\n",
        "            inputB = np.array(curr_chunk.loc[last_index, self.inputB_features + ['K1', 'K2']])\n",
        "        return inputA, inputB, output_np\n",
        "    \n",
        "\n",
        "    def kdi_training_data(self):\n",
        "        window_length = self.n_steps + 1\n",
        "        inputA_arr, inputB_arr, output_arr = [], [], []\n",
        "        for user in self.df['USER'].unique():\n",
        "            curr_df = self.df[self.df['USER'] == user]\n",
        "            i = 0\n",
        "            while i+window_length < len(curr_df):\n",
        "                curr_chunk = curr_df.iloc[i:i+window_length]\n",
        "                curr_inputA, curr_inputB, curr_output = self.single_kdi_input(curr_chunk)\n",
        "                inputA_arr.append(curr_inputA)\n",
        "                inputB_arr.append(curr_inputB)\n",
        "                output_arr.append(curr_output)\n",
        "                i += self.shift\n",
        "            if self.keep_smaller_window and i < len(curr_df) - 1:    ## i cannot be curr_df[-1:] of length 1, since impossible to split into input and output data\n",
        "                curr_chunk = curr_df.iloc[i:]\n",
        "                curr_inputA, curr_inputB, curr_output = self.single_kdi_input(curr_chunk)\n",
        "                inputA_arr.append(curr_inputA)\n",
        "                inputB_arr.append(curr_inputB)\n",
        "                output_arr.append(curr_output)\n",
        "        return np.stack(inputA_arr, axis=0), np.stack(inputB_arr, axis=0), np.stack(output_arr, axis=0)\n",
        "    \n",
        "\n",
        "    def generate_kds(self):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(({'inputA': self.inputA, 'inputB': self.inputB}, \n",
        "                                                      self.output)).batch(self.batch_size)\n",
        "        return dataset"
      ],
      "metadata": {
        "id": "T90ARBoS8GnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks \n",
        "\n",
        "* `get_callbacks(experiment_name, patience, avg_mode)`\n",
        "  * `create_checkpoint_callback(experiment_name, save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)`\n",
        "  * `create_tensorboard_callback(experiment_name)`\n",
        "  * `create_earlystopping_callback(monitor='val_loss', patience=5)`"
      ],
      "metadata": {
        "id": "bdq7roqd_P1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## functionalize callbacks\n",
        "def create_checkpoint_callback(experiment_name, \n",
        "                               avg_mode,\n",
        "                               save_weights_only=True, \n",
        "                               monitor='val_loss', \n",
        "                               mode='min', \n",
        "                               save_best_only=True):\n",
        "    path = '/content/drive/MyDrive/COMP576/experiments'\n",
        "    now_time = datetime.datetime.now(timezone('America/Chicago'))\n",
        "    checkpoint_filepath = path + \"/\" + \"checkpoints\" + \"/\" + experiment_name + \"/\" + now_time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    checkpoint_filepath = checkpoint_filepath + '-avg' if avg_mode else checkpoint_filepath\n",
        "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                             save_weights_only=save_weights_only,\n",
        "                                                             monitor=monitor,\n",
        "                                                             mode=mode,\n",
        "                                                             save_best_only=save_best_only)\n",
        "    print(f\"Saving ModelCheckpoint files to :{checkpoint_filepath}\")\n",
        "    return checkpoint_callback\n",
        "\n",
        "def create_tensorboard_callback(experiment_name, avg_mode):\n",
        "    path = '/content/drive/MyDrive/COMP576/experiments'\n",
        "    now_time = datetime.datetime.now(timezone('America/Chicago'))\n",
        "    log_dir = path + \"/\" + \"tensorboard\" + \"/\" + experiment_name + \"/\" + now_time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    log_dir = log_dir + '-avg' if avg_mode else log_dir\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "    print(f\"Saving TensorBoard log files to :{log_dir}\")\n",
        "    return tensorboard_callback\n",
        "\n",
        "def create_earlystopping_callback(patience, monitor='val_loss'):\n",
        "    return tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=patience)\n",
        "\n",
        "def get_callbacks(experiment_name, patience, avg_mode):\n",
        "    earlystopping = create_earlystopping_callback(patience)\n",
        "    modelcheckpoint = create_checkpoint_callback(experiment_name=experiment_name, avg_mode=avg_mode)\n",
        "    tensorboard = create_tensorboard_callback(experiment_name=experiment_name, avg_mode=avg_mode)\n",
        "    return [earlystopping, modelcheckpoint, tensorboard]"
      ],
      "metadata": {
        "id": "gv5LheQr_sOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model\n",
        "\n",
        "* `model = create_model(feature_dim, output_dim, user_embedding=None, keycode_embedding=None, concat_model=None)`\n",
        "  * `typenet_base`\n",
        "  * `concate_RNN_base`\n",
        "\n",
        "* `feature_dim = train_kds_uni.inputA[-1]`\n",
        "* `output_dim = train_kds_uni.output[-1]`"
      ],
      "metadata": {
        "id": "1xUDr6ev_st6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def typenet_base(inputA):\n",
        "    name = 'TypeNet-base'\n",
        "    batch_1 = keras.layers.BatchNormalization()(inputA)\n",
        "    lstm_1 = keras.layers.LSTM(128, return_sequences=True)(batch_1)\n",
        "    dropout_1 = keras.layers.Dropout(0.5)(lstm_1)\n",
        "    batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
        "    lstm_2 = keras.layers.LSTM(128)(batch_2)\n",
        "    return name, lstm_2\n",
        "\n",
        "def concate_RNN_base(concat, feature_dim, output_dim):\n",
        "    name = 'ConcatRNN-base'\n",
        "    reshape = keras.layers.Reshape((128+feature_dim-output_dim, 1))(concat)\n",
        "    gru_1 = keras.layers.GRU(64)(reshape)\n",
        "    return name, gru_1\n",
        "\n",
        "def create_model(feature_dim, output_dim, user_embedding=None, keycode_embedding=None, concat_model=None):\n",
        "    inputA = keras.layers.Input(shape=[None, feature_dim], name='InputA')\n",
        "    inputB = keras.layers.Input(shape=[feature_dim-output_dim], name='InputB')\n",
        "    \n",
        "    if user_embedding:\n",
        "        user_name, user_embeded = user_embedding(inputA)\n",
        "    else:\n",
        "        user_name, user_embeded = 'no-user', inputA\n",
        "    if keycode_embedding:\n",
        "        keycode_name, keycode_embeded = keycode_embedding(inputB)\n",
        "    else:\n",
        "        keycode_name, keycode_embeded = 'no-keycode', inputB\n",
        "    concat = keras.layers.concatenate([user_embeded, keycode_embeded])\n",
        "\n",
        "    if concat_model:\n",
        "        concat_name, concat_output = concat_model(concat, feature_dim, output_dim)\n",
        "    else:\n",
        "        concat_name, concat_output = 'no-concat', concat\n",
        "    output = keras.layers.Dense(output_dim)(concat_output)\n",
        "\n",
        "    model_name = user_name + '_' + keycode_name + '_' + concat_name\n",
        "    return keras.Model(inputs=[inputA, inputB], outputs=[output], name=model_name)"
      ],
      "metadata": {
        "id": "S7oxqipSCQxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorBoard"
      ],
      "metadata": {
        "id": "a3Sx1uf9LeQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext tensorboard\n",
        "\n",
        "# # Clear any logs from previous runs\n",
        "# rm -rf ./logs/\n",
        "\n",
        "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# %tensorboard --logdir logs/fit\n",
        "\n",
        "# from tensorboard import notebook\n",
        "# notebook.list() # View open TensorBoard instances\n",
        "\n",
        "# # Control TensorBoard display. If no port is provided, \n",
        "# # the most recently launched TensorBoard is used\n",
        "# notebook.display(port=6006, height=1000)\n",
        "# # !kill portPID#"
      ],
      "metadata": {
        "id": "5YUIj2CjLg2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old Experiments: `sample_size = 100`, `train_size = 0.8`\n",
        "\n",
        "Goal: \n",
        "1. have a baseline learning rate (just use one set of parameters)\n",
        "2. decide `avg` shoul be `mean` or `median`\n",
        "\n",
        "Preping mode: \n",
        "* add_layout = False\n",
        "* remove_outliers = 1\n",
        "* conn_latency = 'PL'\n",
        "* n_steps = 30\n",
        "* shift = 1\n",
        "* batch_size = 64\n",
        "\n",
        "Total trainings: 8"
      ],
      "metadata": {
        "id": "MUMZX-e33kAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "y6apeXrEGOse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Loading Parameters\n",
        "folder_path = \"/content/drive/MyDrive/COMP576/keystroke-samples\"      ## up to USER=7001 (inclusive)\n",
        "train_size = 0.8\n",
        "sample_size = 100\n",
        "\n",
        "data, train_data, test_data, uni_encoder, di_encoder = prep.processing_folder(folder_path, sample_size, train_size)\n",
        "\n",
        "print(f\"There are in total {len(train_data['PARTICIPANT_ID'].unique())} many users contained in the train dataset\")\n",
        "print(f\"There are in total {len(test_data['PARTICIPANT_ID'].unique())} many users contained in the test dataset\")\n",
        "print(f\"There are in total {len(data['PARTICIPANT_ID'].unique())} many users contained in the entire dataset\")\n",
        "print(f\"There are in total {len(data)} many keystrokes contained in the dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uo5EjWM3lcQ",
        "outputId": "0369642f-ccc5-4c6d-909f-75f764da65c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are in total 400 many users contained in the train dataset\n",
            "There are in total 400 many users contained in the test dataset\n",
            "There are in total 400 many users contained in the entire dataset\n",
            "There are in total 294546 many keystrokes contained in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latencies = ['HL', 'PL']\n",
        "keyboard_dict = prep.Keyboard(prep.get_qwerty_keyboard()).keyboard_dict()\n",
        "train_extractor = prep.Extractors(train_data, keyboard_dict, latencies)\n",
        "test_extractor = prep.Extractors(test_data, keyboard_dict, latencies)"
      ],
      "metadata": {
        "id": "vWLO21sC39B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 2: Uni-graph + Mean (fixed preprocessor problem on latencies between different sentences)\n",
        "\n",
        "* avg_mode = 'mean'\n",
        "* add_layout = False\n",
        "* remove_outliers = 1\n",
        "* conn_latency = 'PL'\n",
        "\n",
        "* n_steps = 30\n",
        "* shift = 1\n",
        "* batch_size = 64"
      ],
      "metadata": {
        "id": "0q7aKyBSOdFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_mode = 'mean'\n",
        "train_df_uni_mean = train_extractor.unigraph_avg(avg_mode)\n",
        "test_df_uni_mean = test_extractor.unigraph_avg(avg_mode)"
      ],
      "metadata": {
        "id": "BWi5OzZSNpfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 30\n",
        "shift = 1\n",
        "batch_size = 64\n",
        "\n",
        "train_kds_uni_mean = prep.KDS(train_df_uni_mean, n_steps, shift, batch_size, encoder=uni_encoder, mode='uni')\n",
        "test_kds_uni_mean = prep.KDS(test_df_uni_mean, n_steps, shift, batch_size, encoder=uni_encoder, mode='uni')"
      ],
      "metadata": {
        "id": "6gcMHgaeOpR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some STATs"
      ],
      "metadata": {
        "id": "nxt7dC3dPL3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_uni_mean.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "jgoPB641POU_",
        "outputId": "ac4fff3e-a6a5-48bd-d3a7-470143989211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         USER   INDEX      HL      PL\n",
              "count 58246.0 58246.0 58246.0 58246.0\n",
              "mean    180.1    27.0   118.9   275.2\n",
              "std     102.5    19.4    57.2    72.1\n",
              "min       5.0     0.0     0.0    23.0\n",
              "25%      88.0    11.0   105.0   232.0\n",
              "50%     186.0    24.0   107.0   251.0\n",
              "75%     275.0    39.0   113.0   284.0\n",
              "max     346.0   134.0  1051.0  5329.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a4915dc-55b4-4248-a6dd-b0b0590a1c76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER</th>\n",
              "      <th>INDEX</th>\n",
              "      <th>HL</th>\n",
              "      <th>PL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>180.1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>118.9</td>\n",
              "      <td>275.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>102.5</td>\n",
              "      <td>19.4</td>\n",
              "      <td>57.2</td>\n",
              "      <td>72.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>88.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>186.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>251.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>275.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>284.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>346.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>1051.0</td>\n",
              "      <td>5329.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a4915dc-55b4-4248-a6dd-b0b0590a1c76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a4915dc-55b4-4248-a6dd-b0b0590a1c76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a4915dc-55b4-4248-a6dd-b0b0590a1c76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "g1UrauEyPXdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Group 0: `uni_mean` (lr_scheduler to find a sensible learning rate)"
      ],
      "metadata": {
        "id": "mjwcgyGwPiUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds_uni_mean.inputA[-1]\n",
        "output_dim = train_kds_uni_mean.output[-1]\n",
        "user_gru = 64\n",
        "concat_gru = 32\n",
        "\n",
        "inputA = keras.layers.Input(shape=[None, feature_dim], name='InputA')\n",
        "inputB = keras.layers.Input(shape=[feature_dim-output_dim], name='InputB')\n",
        "\n",
        "batch_1 = keras.layers.BatchNormalization()(inputA)\n",
        "gru_1 = keras.layers.GRU(user_gru, return_sequences=True)(batch_1)\n",
        "dropout_1 = keras.layers.Dropout(0.5)(gru_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
        "gru_out = keras.layers.GRU(user_gru)(batch_2)\n",
        "\n",
        "concat = keras.layers.concatenate([gru_out, inputB])\n",
        "\n",
        "reshape = keras.layers.Reshape((user_gru+feature_dim-output_dim, 1))(concat)\n",
        "concat_output = keras.layers.GRU(concat_gru = 32)(reshape)\n",
        "\n",
        "output = keras.layers.Dense(output_dim)(concat_output)\n",
        "\n",
        "model_name = 'Exp2Gp0'\n",
        "model_Exp2Gp0 = keras.Model(inputs=[inputA, inputB], outputs=[output], name=model_name)"
      ],
      "metadata": {
        "id": "5t8sCFMzS4W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds_uni_mean.inputA[-1]\n",
        "output_dim = train_kds_uni_mean.output[-1]\n",
        "\n",
        "##change model name 1\n",
        "model_Exp2Gp0 = prep.create_model(feature_dim, output_dim, \n",
        "                     user_embedding=prep.typenet_base, \n",
        "                     keycode_embedding=None, \n",
        "                     concat_model=prep.concate_RNN_base)\n",
        "\n",
        "##------------------------------------------------------------------------------------------##\n",
        "lr = 0.01\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds_uni_mean.ds\n",
        "testset = test_kds_uni_mean.ds\n",
        "EPOCH = 20\n",
        "patience = 4\n",
        "\n",
        "def lr_finder(epoch):\n",
        "    num1 = 4 - (epoch - 1) // 3\n",
        "    num2 = 1 + (epoch - 1) % 3 * 3\n",
        "    return round(0.1 ** num1 * num2, 7)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = prep.create_tensorboard_callback('Exp1Gp0', avg_mode=True)\n",
        "\n",
        "##change model name 2\n",
        "model_Exp2Gp0.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "\n",
        "##change model name 3 + 4\n",
        "history_Exp2Gp0 = model_Exp2Gp0.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[lr_scheduler, tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "wmrMgHnbPfU8",
        "outputId": "64d7e879-ccab-4a81-85f7-738835593452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/Exp1Gp0/20221206-194351-avg\n",
            "Epoch 1/20\n",
            "909/909 [==============================] - 42s 36ms/step - loss: 190.0348 - mae: 190.7277 - val_loss: 12577.2598 - val_mae: 12577.9531 - lr: 7.0000e-05\n",
            "Epoch 2/20\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 182.6343 - mae: 183.3275 - val_loss: 12571.3613 - val_mae: 12572.0547 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "909/909 [==============================] - 30s 32ms/step - loss: 167.3489 - mae: 168.0419 - val_loss: 12548.9775 - val_mae: 12549.6699 - lr: 4.0000e-04\n",
            "Epoch 4/20\n",
            "909/909 [==============================] - 30s 33ms/step - loss: 134.3790 - mae: 135.0722 - val_loss: 12510.4941 - val_mae: 12511.1904 - lr: 7.0000e-04\n",
            "Epoch 5/20\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 90.7684 - mae: 91.4449 - val_loss: 12476.4980 - val_mae: 12477.1875 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "909/909 [==============================] - 31s 34ms/step - loss: 38.0950 - mae: 38.7621 - val_loss: 12437.2285 - val_mae: 12437.9111 - lr: 0.0040\n",
            "Epoch 7/20\n",
            "909/909 [==============================] - 30s 33ms/step - loss: 29.1866 - mae: 29.8451 - val_loss: 12437.2373 - val_mae: 12437.9268 - lr: 0.0070\n",
            "Epoch 8/20\n",
            "909/909 [==============================] - 30s 33ms/step - loss: 29.1939 - mae: 29.8510 - val_loss: 12437.2822 - val_mae: 12437.9678 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 29.2584 - mae: 29.9178 - val_loss: 12437.3926 - val_mae: 12438.0811 - lr: 0.0400\n",
            "Epoch 10/20\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 29.3617 - mae: 30.0207 - val_loss: 12437.3096 - val_mae: 12437.9932 - lr: 0.0700\n",
            "Epoch 11/20\n",
            "909/909 [==============================] - 32s 35ms/step - loss: 29.3356 - mae: 29.9944 - val_loss: 12437.1934 - val_mae: 12437.8711 - lr: 0.1000\n",
            "Epoch 12/20\n",
            "909/909 [==============================] - 30s 33ms/step - loss: 29.8083 - mae: 30.4732 - val_loss: 12437.8848 - val_mae: 12438.5596 - lr: 0.4000\n",
            "Epoch 13/20\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 30.2281 - mae: 30.8971 - val_loss: 12437.0654 - val_mae: 12437.7510 - lr: 0.7000\n",
            "Epoch 14/20\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 30.9528 - mae: 31.6247 - val_loss: 12439.3896 - val_mae: 12440.0762 - lr: 1.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-891fa89c9b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m##change model name 3 + 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mhistory_Exp2Gp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_Exp2Gp0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1395\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1\n",
        "-----\n",
        "* train_kds_uni_mean\n",
        "* test_kds_uni_mean\n",
        "-----\n",
        "* train_kds_di_mean\n",
        "* test_kds_di_mean\n",
        "-----\n",
        "* train_kds_uni_median\n",
        "* test_kds_uni_median\n",
        "-----\n",
        "* train_kds_di_median\n",
        "* test_kds_di_median\n",
        "-----"
      ],
      "metadata": {
        "id": "3O5KwB6sGVLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group 0: `uni_mean` (lr_scheduler to find a sensible learning rate)"
      ],
      "metadata": {
        "id": "e4fDX_DmG6Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds_uni_mean.inputA[-1]\n",
        "output_dim = train_kds_uni_mean.output[-1]\n",
        "\n",
        "model_Exp1Gp0 = create_model(feature_dim, output_dim, \n",
        "                     user_embedding=typenet_base, \n",
        "                     keycode_embedding=None, \n",
        "                     concat_model=concate_RNN_base)\n",
        "\n",
        "##------------------------------------------------------------------------------------------##\n",
        "lr = 0.01\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds_uni_mean.ds\n",
        "testset = test_kds_uni_mean.ds\n",
        "EPOCH = 20\n",
        "patience = 4\n",
        "\n",
        "def lr_finder(epoch):\n",
        "    num1 = 4 - (epoch - 1) // 3\n",
        "    num2 = 1 + (epoch - 1) % 3 * 3\n",
        "    return round(0.1 ** num1 * num2, 7)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = create_tensorboard_callback('Exp1Gp0', avg_mode=True)\n",
        "\n",
        "model_Exp1Gp0.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "history_Exp1Gp0 = model_Exp1Gp0.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[lr_scheduler, tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g_a0gaFCG3B",
        "outputId": "e8d3bea5-b700-4350-fadd-125a5364c80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/Exp1Gp0/20221205-215531-avg\n",
            "Epoch 1/20\n",
            "933/933 [==============================] - 273s 285ms/step - loss: 5293.8481 - mae: 5294.5342 - val_loss: 10978.1299 - val_mae: 10978.8252 - lr: 7.0000e-05\n",
            "Epoch 2/20\n",
            "933/933 [==============================] - 260s 279ms/step - loss: 5289.5039 - mae: 5290.1992 - val_loss: 10972.6885 - val_mae: 10973.3799 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "933/933 [==============================] - 262s 280ms/step - loss: 5280.3691 - mae: 5281.0605 - val_loss: 10952.4404 - val_mae: 10953.1328 - lr: 4.0000e-04\n",
            "Epoch 4/20\n",
            "933/933 [==============================] - 264s 283ms/step - loss: 5260.9487 - mae: 5261.6377 - val_loss: 10918.8730 - val_mae: 10919.5586 - lr: 7.0000e-04\n",
            "Epoch 5/20\n",
            "933/933 [==============================] - 261s 280ms/step - loss: 5242.5581 - mae: 5243.2334 - val_loss: 10903.9209 - val_mae: 10904.6084 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "933/933 [==============================] - 264s 283ms/step - loss: 5240.0029 - mae: 5240.6689 - val_loss: 10883.7637 - val_mae: 10884.4521 - lr: 0.0040\n",
            "Epoch 7/20\n",
            "933/933 [==============================] - 262s 281ms/step - loss: 5239.5972 - mae: 5240.2656 - val_loss: 10883.9326 - val_mae: 10884.6191 - lr: 0.0070\n",
            "Epoch 8/20\n",
            "933/933 [==============================] - 263s 282ms/step - loss: 5239.5693 - mae: 5240.2397 - val_loss: 10884.1416 - val_mae: 10884.8291 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "933/933 [==============================] - 263s 282ms/step - loss: 5239.6299 - mae: 5240.2925 - val_loss: 10884.7178 - val_mae: 10885.4072 - lr: 0.0400\n",
            "Epoch 10/20\n",
            "933/933 [==============================] - 266s 285ms/step - loss: 5239.3994 - mae: 5240.0591 - val_loss: 10885.2305 - val_mae: 10885.9121 - lr: 0.0700\n",
            "Epoch 11/20\n",
            "933/933 [==============================] - 269s 288ms/step - loss: 5238.4351 - mae: 5239.1025 - val_loss: 10885.9746 - val_mae: 10886.6572 - lr: 0.1000\n",
            "Epoch 12/20\n",
            "933/933 [==============================] - 269s 288ms/step - loss: 5236.9097 - mae: 5237.5850 - val_loss: 10890.6270 - val_mae: 10891.3057 - lr: 0.4000\n",
            "Epoch 13/20\n",
            "933/933 [==============================] - 266s 285ms/step - loss: 5234.2871 - mae: 5234.9663 - val_loss: 10906.6484 - val_mae: 10907.3359 - lr: 0.7000\n",
            "Epoch 14/20\n",
            "933/933 [==============================] - 265s 284ms/step - loss: 5230.7817 - mae: 5231.4531 - val_loss: 10907.8203 - val_mae: 10908.5039 - lr: 1.0000\n",
            "Epoch 15/20\n",
            "933/933 [==============================] - 264s 282ms/step - loss: 5236.7383 - mae: 5237.4224 - val_loss: 10859.1689 - val_mae: 10859.8379 - lr: 4.0000\n",
            "Epoch 16/20\n",
            "933/933 [==============================] - 265s 284ms/step - loss: 5250.0361 - mae: 5250.7246 - val_loss: 10883.7500 - val_mae: 10884.4492 - lr: 7.0000\n",
            "Epoch 17/20\n",
            "933/933 [==============================] - 265s 284ms/step - loss: 5253.1143 - mae: 5253.8047 - val_loss: 10894.8418 - val_mae: 10895.5352 - lr: 10.0000\n",
            "Epoch 18/20\n",
            "933/933 [==============================] - 265s 284ms/step - loss: 5370.1323 - mae: 5370.8242 - val_loss: 10998.7402 - val_mae: 10999.4268 - lr: 40.0000\n",
            "Epoch 19/20\n",
            "933/933 [==============================] - 267s 286ms/step - loss: 5494.5127 - mae: 5495.2031 - val_loss: 11010.3008 - val_mae: 11010.9951 - lr: 70.0000\n",
            "Epoch 20/20\n",
            "933/933 [==============================] - 266s 285ms/step - loss: 5603.6665 - mae: 5604.3618 - val_loss: 11023.2715 - val_mae: 11023.9688 - lr: 100.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot lr versus loss\n",
        "lrs = history_Exp1Gp0.history['lr']\n",
        "loss = history_Exp1Gp0.history['val_mae']\n",
        "plt.semilogx(lrs, loss);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "_Ja-059Lg61d",
        "outputId": "c9e35775-d1dd-4982-d865-4677e71f7b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_Exp1Gp0.predict(test_kds_uni_mean.ds_in.take(1))"
      ],
      "metadata": {
        "id": "prs9fUhv8bCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group 1: `uni_median` (lr_scheduler to find a sensible learning rate)"
      ],
      "metadata": {
        "id": "JGIvDDoD7JS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds_uni_median.inputA[-1]\n",
        "output_dim = train_kds_uni_median.output[-1]\n",
        "\n",
        "model_Exp1Gp1 = create_model(feature_dim, output_dim, \n",
        "                     user_embedding=typenet_base, \n",
        "                     keycode_embedding=None, \n",
        "                     concat_model=concate_RNN_base)\n",
        "\n",
        "##------------------------------------------------------------------------------------------##\n",
        "lr = 0.01\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds_uni_mean.ds\n",
        "testset = test_kds_uni_mean.ds\n",
        "EPOCH = 20\n",
        "patience = 4\n",
        "\n",
        "def lr_finder(epoch):\n",
        "    num1 = 4 - (epoch - 1) // 3\n",
        "    num2 = 1 + (epoch - 1) % 3 * 3\n",
        "    return round(0.1 ** num1 * num2, 7)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = create_tensorboard_callback('Exp1Gp1', avg_mode=True)\n",
        "\n",
        "model_Exp1Gp1.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "history_Exp1Gp1 = model_Exp1Gp1.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[lr_scheduler, tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqPYKeXp76tl",
        "outputId": "03e983b5-60c8-453a-bb9b-de946b5695f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/Exp1Gp1/20221205-234331-avg\n",
            "Epoch 1/20\n",
            "933/933 [==============================] - 39s 32ms/step - loss: 5293.7686 - mae: 5294.4590 - val_loss: 10977.9072 - val_mae: 10978.5986 - lr: 7.0000e-05\n",
            "Epoch 2/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5289.3491 - mae: 5290.0479 - val_loss: 10972.6123 - val_mae: 10973.3047 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5280.1108 - mae: 5280.7993 - val_loss: 10957.2227 - val_mae: 10957.9102 - lr: 4.0000e-04\n",
            "Epoch 4/20\n",
            "933/933 [==============================] - 33s 36ms/step - loss: 5260.6162 - mae: 5261.3091 - val_loss: 10925.7998 - val_mae: 10926.4922 - lr: 7.0000e-04\n",
            "Epoch 5/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5242.4805 - mae: 5243.1543 - val_loss: 10903.9971 - val_mae: 10904.6836 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "933/933 [==============================] - 27s 29ms/step - loss: 5240.0049 - mae: 5240.6738 - val_loss: 10883.8340 - val_mae: 10884.5293 - lr: 0.0040\n",
            "Epoch 7/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5239.5938 - mae: 5240.2622 - val_loss: 10883.8398 - val_mae: 10884.5254 - lr: 0.0070\n",
            "Epoch 8/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5239.5645 - mae: 5240.2295 - val_loss: 10884.1123 - val_mae: 10884.8027 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5239.3931 - mae: 5240.0576 - val_loss: 10886.1699 - val_mae: 10886.8613 - lr: 0.0400\n",
            "Epoch 10/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5238.5508 - mae: 5239.2148 - val_loss: 10883.2939 - val_mae: 10883.9795 - lr: 0.0700\n",
            "Epoch 11/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5237.1318 - mae: 5237.7974 - val_loss: 10883.1895 - val_mae: 10883.8779 - lr: 0.1000\n",
            "Epoch 12/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5235.2026 - mae: 5235.8813 - val_loss: 10889.3174 - val_mae: 10890.0088 - lr: 0.4000\n",
            "Epoch 13/20\n",
            "933/933 [==============================] - 27s 29ms/step - loss: 5230.9614 - mae: 5231.6353 - val_loss: 10919.9951 - val_mae: 10920.6709 - lr: 0.7000\n",
            "Epoch 14/20\n",
            "933/933 [==============================] - 31s 33ms/step - loss: 5227.0225 - mae: 5227.6914 - val_loss: 10906.5605 - val_mae: 10907.2393 - lr: 1.0000\n",
            "Epoch 15/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5238.2451 - mae: 5238.9336 - val_loss: 10853.9961 - val_mae: 10854.6699 - lr: 4.0000\n",
            "Epoch 16/20\n",
            "933/933 [==============================] - 27s 29ms/step - loss: 5248.3223 - mae: 5249.0151 - val_loss: 10880.3555 - val_mae: 10881.0449 - lr: 7.0000\n",
            "Epoch 17/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5255.5796 - mae: 5256.2710 - val_loss: 10870.8135 - val_mae: 10871.5107 - lr: 10.0000\n",
            "Epoch 18/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5329.6216 - mae: 5330.3062 - val_loss: 10904.4951 - val_mae: 10905.1699 - lr: 40.0000\n",
            "Epoch 19/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5447.9365 - mae: 5448.6284 - val_loss: 11299.9482 - val_mae: 11300.6387 - lr: 70.0000\n",
            "Epoch 20/20\n",
            "933/933 [==============================] - 28s 30ms/step - loss: 5533.3706 - mae: 5534.0566 - val_loss: 11250.2793 - val_mae: 11250.9688 - lr: 100.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in test_kds_uni_mean.ds_in.take(1):\n",
        "    inputA = a\n",
        "    inputB = b\n",
        "for a in test_kds_uni_mean.ds_out.take(1):\n",
        "    output = a\n",
        "\n",
        "model_Exp1Gp1.predict((inputA, inputB)), output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uQJ76BDVvns",
        "outputId": "79b06eaa-155b-4389-a69d-37e29fc4cc56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  347.8746 , -2105.7815 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ],\n",
              "        [  407.36996,  -370.2781 ]], dtype=float32),\n",
              " <tf.Tensor: shape=(64, 2), dtype=float64, numpy=\n",
              " array([[ 9.90000e+01,  2.62000e+02],\n",
              "        [ 9.90000e+01,  2.65000e+02],\n",
              "        [ 1.09000e+02, -2.91000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 1.13000e+02,  4.23000e+02],\n",
              "        [ 8.60000e+01,  6.30780e+04],\n",
              "        [ 1.01000e+02,  2.36000e+02],\n",
              "        [ 1.13000e+02,  4.23000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 1.31000e+02,  2.72000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 1.02000e+02,  2.16000e+02],\n",
              "        [ 1.04000e+02,  2.63000e+02],\n",
              "        [ 1.04000e+02,  2.45000e+02],\n",
              "        [ 1.04000e+02,  2.45000e+02],\n",
              "        [ 1.04000e+02,  2.63000e+02],\n",
              "        [ 1.03000e+02,  2.74000e+02],\n",
              "        [ 1.02000e+02,  2.40000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 9.70000e+01,  2.28000e+02],\n",
              "        [ 1.13000e+02,  4.23000e+02],\n",
              "        [ 9.70000e+01,  2.28000e+02],\n",
              "        [ 1.11000e+02,  2.41000e+02],\n",
              "        [ 1.13000e+02,  6.75000e+02],\n",
              "        [ 1.04000e+02,  2.63000e+02],\n",
              "        [ 1.31000e+02,  2.72000e+02],\n",
              "        [ 9.90000e+01,  2.65000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 1.04000e+02,  2.45000e+02],\n",
              "        [ 1.11000e+02,  2.41000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 1.04000e+02,  2.45000e+02],\n",
              "        [ 1.00000e+02,  1.73000e+02],\n",
              "        [ 1.11000e+02,  2.41000e+02],\n",
              "        [ 1.20000e+02, -1.45000e+02],\n",
              "        [ 1.13000e+02,  4.23000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 1.24000e+02,  2.67000e+02],\n",
              "        [ 1.00000e+02,  1.73000e+02],\n",
              "        [ 1.11000e+02,  2.41000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 1.09000e+02, -2.91000e+02],\n",
              "        [ 1.04000e+02,  2.63000e+02],\n",
              "        [ 1.13000e+02,  4.23000e+02],\n",
              "        [ 1.20000e+02, -1.45000e+02],\n",
              "        [ 1.88000e+02, -5.22906e+05],\n",
              "        [ 8.60000e+01,  6.30780e+04],\n",
              "        [ 8.60000e+01,  6.30780e+04],\n",
              "        [ 1.09000e+02, -2.91000e+02],\n",
              "        [ 1.88000e+02, -5.22906e+05],\n",
              "        [ 3.37000e+02,  2.71000e+02],\n",
              "        [ 1.04000e+02,  2.63000e+02],\n",
              "        [ 1.09000e+02, -2.91000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 9.90000e+01,  2.65000e+02],\n",
              "        [ 9.90000e+01,  2.62000e+02],\n",
              "        [ 1.03000e+02,  2.74000e+02],\n",
              "        [ 1.17000e+02,  2.21000e+02],\n",
              "        [ 1.00000e+02,  1.73000e+02],\n",
              "        [ 1.06000e+02,  3.11000e+02],\n",
              "        [ 1.09000e+02, -2.91000e+02],\n",
              "        [ 1.11000e+02,  2.41000e+02],\n",
              "        [ 1.13000e+02,  4.23000e+02],\n",
              "        [ 1.20000e+02, -1.45000e+02]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputA, inputB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9L3Np6BV4jZ",
        "outputId": "66677b03-07ad-4286-b63a-6214d7e321b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 30, 80), dtype=float64, numpy=\n",
              " array([[[   0.,    0.,    0., ...,    7.,  131.,  272.],\n",
              "         [   0.,    0.,    0., ...,    8.,   99.,  265.],\n",
              "         [   0.,    0.,    0., ...,    9.,   99.,  265.],\n",
              "         ...,\n",
              "         [   0.,    0.,    0., ...,    5.,  106.,  311.],\n",
              "         [   0.,    0.,    0., ...,    6.,  124.,  267.],\n",
              "         [   0.,    0.,    0., ...,    7.,  111.,  241.]],\n",
              " \n",
              "        [[   0.,    0.,    0., ...,    8.,   99.,  265.],\n",
              "         [   0.,    0.,    0., ...,    9.,   99.,  265.],\n",
              "         [   0.,    0.,    0., ...,   10.,  106.,  311.],\n",
              "         ...,\n",
              "         [   0.,    0.,    0., ...,    6.,  124.,  267.],\n",
              "         [   0.,    0.,    0., ...,    7.,  111.,  241.],\n",
              "         [   0.,    0.,    0., ...,    8.,   99.,  262.]],\n",
              " \n",
              "        [[   0.,    0.,    0., ...,    9.,   99.,  265.],\n",
              "         [   0.,    0.,    0., ...,   10.,  106.,  311.],\n",
              "         [   0.,    0.,    0., ...,   11.,   96.,  804.],\n",
              "         ...,\n",
              "         [   0.,    0.,    0., ...,    7.,  111.,  241.],\n",
              "         [   0.,    0.,    0., ...,    8.,   99.,  262.],\n",
              "         [   0.,    0.,    0., ...,    9.,   99.,  265.]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[   0.,    0.,    0., ...,   39.,  104.,  245.],\n",
              "         [   0.,    0.,    0., ...,   40.,  100.,  173.],\n",
              "         [   0.,    0.,    0., ...,   41.,  111.,  241.],\n",
              "         ...,\n",
              "         [   0.,    0.,    0., ...,    8.,  100.,  173.],\n",
              "         [   0.,    0.,    0., ...,    9.,  106.,  311.],\n",
              "         [   0.,    0.,    0., ...,   10.,  109., -291.]],\n",
              " \n",
              "        [[   0.,    0.,    0., ...,   40.,  100.,  173.],\n",
              "         [   0.,    0.,    0., ...,   41.,  111.,  241.],\n",
              "         [   0.,    0.,    0., ...,   42.,  120., -145.],\n",
              "         ...,\n",
              "         [   0.,    0.,    0., ...,    9.,  106.,  311.],\n",
              "         [   0.,    0.,    0., ...,   10.,  109., -291.],\n",
              "         [   0.,    0.,    0., ...,   11.,  111.,  241.]],\n",
              " \n",
              "        [[   0.,    0.,    0., ...,   41.,  111.,  241.],\n",
              "         [   0.,    0.,    0., ...,   42.,  120., -145.],\n",
              "         [   0.,    0.,    0., ...,   43.,  113.,  423.],\n",
              "         ...,\n",
              "         [   0.,    0.,    0., ...,   10.,  109., -291.],\n",
              "         [   0.,    0.,    0., ...,   11.,  111.,  241.],\n",
              "         [   0.,    0.,    0., ...,   12.,  113.,  423.]]])>,\n",
              " <tf.Tensor: shape=(64, 78), dtype=float64, numpy=\n",
              " array([[ 0.,  0.,  0., ...,  0.,  0.,  8.],\n",
              "        [ 0.,  0.,  0., ...,  0.,  0.,  9.],\n",
              "        [ 0.,  0.,  0., ...,  0.,  0., 10.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  0., ...,  0.,  0., 11.],\n",
              "        [ 0.,  0.,  0., ...,  0.,  0., 12.],\n",
              "        [ 0.,  0.,  0., ...,  0.,  0., 13.]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot lr versus loss\n",
        "lrs = history_Exp1Gp1.history['lr']\n",
        "loss = history_Exp1Gp1.history['val_mae']\n",
        "plt.semilogx(lrs, loss);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Cy9xHbJ8Wl0o",
        "outputId": "fcf4b3ba-f0ee-40e9-eb24-97a3d380c0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group 2: try `di_median` with lr $\\leq$ 0.01"
      ],
      "metadata": {
        "id": "woaPfTEJWwE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds_di_median.inputA[-1]\n",
        "output_dim = train_kds_di_median.output[-1]\n",
        "\n",
        "## !!! CHANGE MODEL NAME !!! ##\n",
        "model_Exp1Gp2 = create_model(feature_dim, output_dim, \n",
        "                     user_embedding=typenet_base, \n",
        "                     keycode_embedding=None, \n",
        "                     concat_model=concate_RNN_base)\n",
        "\n",
        "##------------------------------------------------------------------------------------------##\n",
        "lr = 0.07\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds_di_mean.ds\n",
        "testset = test_kds_di_mean.ds\n",
        "EPOCH = 20\n",
        "patience = 4\n",
        "\n",
        "def lr_finder(epoch):\n",
        "    num1 = 4 - (epoch - 1) // 3\n",
        "    num2 = 1 + (epoch - 1) % 3 * 3\n",
        "    lr = round(0.1 ** num1 * num2, 7)\n",
        "    if lr < 0.01:\n",
        "        return lr\n",
        "    return 0.01\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = create_tensorboard_callback('Exp1Gp2', avg_mode=True)\n",
        "\n",
        "model_Exp1Gp2.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "history_Exp1Gp2 = model_Exp1Gp2.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[lr_scheduler, tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "LZyvh8_uXNwd",
        "outputId": "83379422-cf40-4ee7-ed5b-2490b62bc326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/Exp1Gp2/20221206-063720-avg\n",
            "Epoch 1/20\n",
            "933/933 [==============================] - 37s 35ms/step - loss: 5609.0708 - mae: 5609.7681 - val_loss: 24029.8418 - val_mae: 24030.5508 - lr: 7.0000e-05\n",
            "Epoch 2/20\n",
            "933/933 [==============================] - 36s 39ms/step - loss: 5602.3403 - mae: 5603.0327 - val_loss: 24023.7598 - val_mae: 24024.4492 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "933/933 [==============================] - 36s 39ms/step - loss: 5587.6587 - mae: 5588.3477 - val_loss: 24000.1992 - val_mae: 24000.8887 - lr: 4.0000e-04\n",
            "Epoch 4/20\n",
            "933/933 [==============================] - 32s 34ms/step - loss: 5555.7461 - mae: 5556.4380 - val_loss: 23959.7168 - val_mae: 23960.3906 - lr: 7.0000e-04\n",
            "Epoch 5/20\n",
            "933/933 [==============================] - 31s 33ms/step - loss: 5515.7705 - mae: 5516.4492 - val_loss: 23924.9395 - val_mae: 23925.6152 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "933/933 [==============================] - 31s 33ms/step - loss: 5479.8760 - mae: 5480.5444 - val_loss: 23899.8750 - val_mae: 23900.5586 - lr: 0.0040\n",
            "Epoch 7/20\n",
            "933/933 [==============================] - 33s 35ms/step - loss: 5476.1035 - mae: 5476.7754 - val_loss: 23899.5918 - val_mae: 23900.2578 - lr: 0.0070\n",
            "Epoch 8/20\n",
            "933/933 [==============================] - 31s 33ms/step - loss: 5475.9526 - mae: 5476.6177 - val_loss: 23899.4004 - val_mae: 23900.0781 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "933/933 [==============================] - 36s 39ms/step - loss: 5475.8223 - mae: 5476.4893 - val_loss: 23899.2617 - val_mae: 23899.9434 - lr: 0.0100\n",
            "Epoch 10/20\n",
            "933/933 [==============================] - 31s 33ms/step - loss: 5475.7793 - mae: 5476.4497 - val_loss: 23899.2051 - val_mae: 23899.8809 - lr: 0.0100\n",
            "Epoch 11/20\n",
            "933/933 [==============================] - 31s 33ms/step - loss: 5475.7529 - mae: 5476.4194 - val_loss: 23899.1875 - val_mae: 23899.8594 - lr: 0.0100\n",
            "Epoch 12/20\n",
            "933/933 [==============================] - 31s 33ms/step - loss: 5475.7124 - mae: 5476.3833 - val_loss: 23899.2188 - val_mae: 23899.9062 - lr: 0.0100\n",
            "Epoch 13/20\n",
            "802/933 [========================>.....] - ETA: 3s - loss: 5559.2026 - mae: 5559.8691"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-03b5d193013f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         metrics=metrics)\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mhistory_Exp1Gp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_Exp1Gp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in test_kds_di_mean.ds_in.take(1):\n",
        "    inputA = a\n",
        "    inputB = b\n",
        "for a in test_kds_di_mean.ds_out.take(1):\n",
        "    output = a\n",
        "\n",
        "model_Exp1Gp2.predict((inputA, inputB)), output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evwvoUahcE_y",
        "outputId": "a637a1ba-d0f2-4827-913a-5d4469d3e1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[107.53589 , 224.28812 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.84769 , 224.4456  ],\n",
              "        [107.849434, 224.44649 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849434, 224.44649 ],\n",
              "        [104.21314 , 222.6099  ],\n",
              "        [107.84947 , 224.4465  ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849434, 224.44649 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.84769 , 224.4456  ],\n",
              "        [107.84936 , 224.44644 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.84949 , 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.79295 , 224.41797 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.84947 , 224.4465  ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.84949 , 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.84917 , 224.44635 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.84949 , 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [ 81.08727 , 210.92972 ],\n",
              "        [107.849434, 224.44649 ],\n",
              "        [107.84769 , 224.4456  ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.82582 , 224.43457 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.84949 , 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.82558 , 224.43443 ],\n",
              "        [107.839386, 224.4414  ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ],\n",
              "        [107.849495, 224.44652 ]], dtype=float32),\n",
              " <tf.Tensor: shape=(64, 2), dtype=float64, numpy=\n",
              " array([[ 1.030000e+02,  2.640000e+02],\n",
              "        [ 1.190000e+02,  2.080000e+02],\n",
              "        [ 1.040000e+02,  1.860000e+02],\n",
              "        [ 1.100000e+02,  4.550000e+02],\n",
              "        [ 7.800000e+01,  4.720000e+02],\n",
              "        [ 1.050000e+02,  3.750000e+02],\n",
              "        [ 1.170000e+02,  2.110000e+02],\n",
              "        [ 1.050000e+02,  7.270000e+02],\n",
              "        [ 1.270000e+02,  3.010000e+02],\n",
              "        [ 1.130000e+02,  1.980000e+02],\n",
              "        [ 1.080000e+02,  3.720000e+02],\n",
              "        [ 1.130000e+02,  2.200000e+02],\n",
              "        [ 1.040000e+02,  2.340000e+02],\n",
              "        [ 1.050000e+02,  1.640000e+02],\n",
              "        [ 1.060000e+02,  1.920000e+02],\n",
              "        [ 1.010000e+02,  2.030000e+02],\n",
              "        [ 1.030000e+02,  1.760000e+02],\n",
              "        [ 1.060000e+02,  1.750000e+02],\n",
              "        [ 9.300000e+01,  3.270000e+02],\n",
              "        [ 1.100000e+02,  1.980000e+02],\n",
              "        [ 9.600000e+01,  2.250000e+02],\n",
              "        [ 1.040000e+02,  1.900000e+02],\n",
              "        [ 1.010000e+02,  2.270000e+02],\n",
              "        [ 1.100000e+02,  7.213000e+03],\n",
              "        [ 1.200000e+02,  1.710000e+02],\n",
              "        [ 8.600000e+01,  2.470000e+02],\n",
              "        [ 1.070000e+02,  2.160000e+02],\n",
              "        [ 1.030000e+02,  1.720000e+03],\n",
              "        [ 1.070000e+02,  1.870000e+02],\n",
              "        [ 1.080000e+02,  1.760000e+02],\n",
              "        [ 1.030000e+02,  1.720000e+03],\n",
              "        [ 9.700000e+01,  1.480000e+02],\n",
              "        [ 1.190000e+02,  1.770000e+02],\n",
              "        [ 1.120000e+02,  2.990000e+02],\n",
              "        [ 1.130000e+02,  2.070000e+02],\n",
              "        [ 1.050000e+02,  7.270000e+02],\n",
              "        [ 1.240000e+02,  3.480000e+02],\n",
              "        [ 1.130000e+02,  2.370000e+02],\n",
              "        [ 1.190000e+02,  1.770000e+02],\n",
              "        [ 1.080000e+02,  1.760000e+02],\n",
              "        [ 1.170000e+02,  2.990000e+02],\n",
              "        [ 1.000000e+02,  1.700000e+02],\n",
              "        [ 1.130000e+02,  1.960000e+02],\n",
              "        [ 1.180000e+02,  2.490000e+02],\n",
              "        [ 9.900000e+01,  3.890000e+02],\n",
              "        [ 8.100000e+01, -2.322301e+06],\n",
              "        [ 8.300000e+01,  1.930000e+02],\n",
              "        [ 1.210000e+02,  2.890000e+02],\n",
              "        [ 7.900000e+01,  6.680000e+02],\n",
              "        [ 3.230000e+02,  5.686000e+03],\n",
              "        [ 9.900000e+01,  1.750000e+02],\n",
              "        [ 1.040000e+02,  3.200000e+02],\n",
              "        [ 1.040000e+02,  1.860000e+02],\n",
              "        [ 1.010000e+02,  2.980000e+02],\n",
              "        [ 8.400000e+01,  2.800000e+02],\n",
              "        [ 1.020000e+02,  2.490000e+02],\n",
              "        [ 1.170000e+02,  3.480000e+02],\n",
              "        [ 1.040000e+02,  1.920000e+02],\n",
              "        [ 1.140000e+02,  1.960000e+02],\n",
              "        [ 1.170000e+02,  2.990000e+02],\n",
              "        [ 1.100000e+02,  1.390000e+02],\n",
              "        [ 9.800000e+01,  3.040000e+02],\n",
              "        [ 1.180000e+02,  2.490000e+02],\n",
              "        [ 1.140000e+02,  2.250000e+02]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Experiments"
      ],
      "metadata": {
        "id": "lELKPo7ygZah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NewExp0: `sample_size = 100`, `train_size = 0.8`\n",
        "\n",
        "Goal: \n",
        "1. have a baseline learning rate (just use one set of parameters)\n",
        "2. decide `avg` should be `mean` or `median`\n",
        "\n",
        "Preping mode: \n",
        "* add_layout = False\n",
        "* remove_outliers = 1\n",
        "* conn_latency = 'PL'\n",
        "* n_steps = 30\n",
        "* shift = 1\n",
        "* batch_size = 64\n",
        "\n",
        "Total trainings: 4"
      ],
      "metadata": {
        "id": "y3BD0XOPnLR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Loading Parameters\n",
        "folder_path = \"/content/drive/MyDrive/COMP576/keystroke-samples\"      ## up to USER=7001 (inclusive)\n",
        "train_size = 0.8\n",
        "sample_size = 100\n",
        "\n",
        "data, train_data, test_data, uni_encoder, di_encoder = prep.processing_folder(folder_path, sample_size, train_size)\n",
        "\n",
        "print(f\"There are in total {len(train_data['PARTICIPANT_ID'].unique())} many users contained in the train dataset\")\n",
        "print(f\"There are in total {len(test_data['PARTICIPANT_ID'].unique())} many users contained in the test dataset\")\n",
        "print(f\"There are in total {len(data['PARTICIPANT_ID'].unique())} many users contained in the entire dataset\")\n",
        "print(f\"There are in total {len(data)} many keystrokes contained in the dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DaZc27Vgbnf",
        "outputId": "adf11e95-a7bd-4880-a725-e0e47428f445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are in total 100 many users contained in the train dataset\n",
            "There are in total 100 many users contained in the test dataset\n",
            "There are in total 100 many users contained in the entire dataset\n",
            "There are in total 74404 many keystrokes contained in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latencies = ['HL', 'PL']\n",
        "\n",
        "keyboard_dict = prep.Keyboard(prep.get_qwerty_keyboard()).keyboard_dict()\n",
        "train_extractor = prep.Extractors(train_data, keyboard_dict, latencies, is_testset=False)\n",
        "test_extractor = prep.Extractors(test_data, keyboard_dict, latencies, is_testset=True)"
      ],
      "metadata": {
        "id": "xh7QMVFLg1_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group 0"
      ],
      "metadata": {
        "id": "RFcPutmDr0l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_mode = 'mean'\n",
        "\n",
        "train_df_uni_mean = train_extractor.unigraph_avg(avg_mode)\n",
        "test_df_uni_mean = test_extractor.unigraph_avg(avg_mode)\n",
        "\n",
        "n_steps = 30\n",
        "shift = 1\n",
        "batch_size = 64\n",
        "\n",
        "train_kds_uni_mean = prep.KDS(train_df_uni_mean, n_steps, shift, batch_size, encoder=uni_encoder, mode='uni')\n",
        "test_kds_uni_mean = prep.KDS(test_df_uni_mean, n_steps, shift, batch_size, encoder=uni_encoder, mode='uni')"
      ],
      "metadata": {
        "id": "tr10X-TAhFtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_uni_mean.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LKXGNOEEiZWC",
        "outputId": "060def51-8c6b-4fb4-ed21-2e3988116a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         USER   INDEX      HL      PL\n",
              "count 58246.0 58246.0 58246.0 58246.0\n",
              "mean    180.1    27.0   118.9   275.2\n",
              "std     102.5    19.4    57.2    72.1\n",
              "min       5.0     0.0     0.0    23.0\n",
              "25%      88.0    11.0   105.0   232.0\n",
              "50%     186.0    24.0   107.0   251.0\n",
              "75%     275.0    39.0   113.0   284.0\n",
              "max     346.0   134.0  1051.0  5329.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfdfbf1a-26f1-4a79-89fa-bfb9216a78c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER</th>\n",
              "      <th>INDEX</th>\n",
              "      <th>HL</th>\n",
              "      <th>PL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>180.1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>118.9</td>\n",
              "      <td>275.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>102.5</td>\n",
              "      <td>19.4</td>\n",
              "      <td>57.2</td>\n",
              "      <td>72.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>88.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>186.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>251.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>275.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>284.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>346.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>1051.0</td>\n",
              "      <td>5329.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfdfbf1a-26f1-4a79-89fa-bfb9216a78c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfdfbf1a-26f1-4a79-89fa-bfb9216a78c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfdfbf1a-26f1-4a79-89fa-bfb9216a78c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_uni_mean.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "L78y_sT8icxC",
        "outputId": "d9a15bba-efd6-4c8f-ffeb-307af5b8c3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         USER   INDEX      HL      PL\n",
              "count 14559.0 14559.0 14559.0 14559.0\n",
              "mean    180.2    29.0   117.1   276.4\n",
              "std     102.5    20.3    60.2    70.0\n",
              "min       5.0     0.0    47.0   142.0\n",
              "25%      88.0    13.0   103.0   242.0\n",
              "50%     186.0    26.0   106.0   256.0\n",
              "75%     275.0    42.0   113.0   292.0\n",
              "max     346.0   117.0   981.0  1846.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09421b67-f6a6-4449-9aa9-32821b3c4b0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER</th>\n",
              "      <th>INDEX</th>\n",
              "      <th>HL</th>\n",
              "      <th>PL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14559.0</td>\n",
              "      <td>14559.0</td>\n",
              "      <td>14559.0</td>\n",
              "      <td>14559.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>180.2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>117.1</td>\n",
              "      <td>276.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>102.5</td>\n",
              "      <td>20.3</td>\n",
              "      <td>60.2</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>142.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>88.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>242.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>186.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>275.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>292.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>346.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>981.0</td>\n",
              "      <td>1846.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09421b67-f6a6-4449-9aa9-32821b3c4b0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09421b67-f6a6-4449-9aa9-32821b3c4b0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09421b67-f6a6-4449-9aa9-32821b3c4b0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds_uni_mean.inputA[-1]\n",
        "output_dim = train_kds_uni_mean.output[-1]\n",
        "user_gru = 128\n",
        "concat_gru = 64\n",
        "\n",
        "inputA = keras.layers.Input(shape=[None, feature_dim], name='InputA')\n",
        "inputB = keras.layers.Input(shape=[feature_dim-output_dim], name='InputB')\n",
        "\n",
        "batch_1 = keras.layers.BatchNormalization()(inputA)\n",
        "gru_1 = keras.layers.GRU(user_gru, return_sequences=True)(batch_1)\n",
        "dropout_1 = keras.layers.Dropout(0.5)(gru_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
        "gru_out = keras.layers.GRU(user_gru)(batch_2)\n",
        "\n",
        "concat = keras.layers.concatenate([gru_out, inputB])\n",
        "\n",
        "reshape = keras.layers.Reshape((user_gru+feature_dim-output_dim, 1))(concat)\n",
        "concat_output = keras.layers.GRU(concat_gru)(reshape)\n",
        "\n",
        "output = keras.layers.Dense(output_dim)(concat_output)\n",
        "\n",
        "##change model name 0\n",
        "model_name = 'NewExp0Gp0'\n",
        "model_NewExp0Gp0 = keras.Model(inputs=[inputA, inputB], outputs=[output], name=model_name)"
      ],
      "metadata": {
        "id": "kEu8jkEAncn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds_uni_mean.ds\n",
        "testset = test_kds_uni_mean.ds\n",
        "EPOCH = 13\n",
        "\n",
        "def lr_finder(epoch):\n",
        "    num1 = 4 - (epoch - 1) // 3\n",
        "    num2 = 1 + (epoch - 1) % 3 * 3\n",
        "    lr = round(0.1 ** num1 * num2, 7)\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = prep.create_tensorboard_callback(model_name, avg_mode=True)\n",
        "\n",
        "##change model name 3\n",
        "model_NewExp0Gp0.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "\n",
        "##change model name 4 + 5\n",
        "history_NewExp0Gp0 = model_NewExp0Gp0.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[lr_scheduler, tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKVc7KePnkaU",
        "outputId": "ae1f48fb-4198-490d-c4f7-57bdc744a9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/NewExp0Gp0/20221206-212725-avg\n",
            "Epoch 1/13\n",
            "909/909 [==============================] - 34s 33ms/step - loss: 189.3641 - mae: 190.0574 - val_loss: 185.5548 - val_mae: 186.2479 - lr: 7.0000e-05\n",
            "Epoch 2/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 182.2309 - mae: 182.9241 - val_loss: 179.1468 - val_mae: 179.8400 - lr: 1.0000e-04\n",
            "Epoch 3/13\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 166.9953 - mae: 167.6887 - val_loss: 154.9515 - val_mae: 155.6446 - lr: 4.0000e-04\n",
            "Epoch 4/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 134.1049 - mae: 134.7980 - val_loss: 113.2508 - val_mae: 113.9431 - lr: 7.0000e-04\n",
            "Epoch 5/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 91.4104 - mae: 92.0864 - val_loss: 75.9256 - val_mae: 76.6105 - lr: 0.0010\n",
            "Epoch 6/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 38.4988 - mae: 39.1659 - val_loss: 27.8813 - val_mae: 28.5665 - lr: 0.0040\n",
            "Epoch 7/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 29.1858 - mae: 29.8442 - val_loss: 27.8936 - val_mae: 28.5797 - lr: 0.0070\n",
            "Epoch 8/13\n",
            "909/909 [==============================] - 29s 32ms/step - loss: 29.1936 - mae: 29.8507 - val_loss: 27.9440 - val_mae: 28.6294 - lr: 0.0100\n",
            "Epoch 9/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 29.2586 - mae: 29.9179 - val_loss: 28.0563 - val_mae: 28.7408 - lr: 0.0400\n",
            "Epoch 10/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 29.2539 - mae: 29.9122 - val_loss: 28.1042 - val_mae: 28.7881 - lr: 0.0700\n",
            "Epoch 11/13\n",
            "909/909 [==============================] - 28s 30ms/step - loss: 28.9724 - mae: 29.6299 - val_loss: 27.6775 - val_mae: 28.3626 - lr: 0.1000\n",
            "Epoch 12/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 28.9628 - mae: 29.6272 - val_loss: 27.2641 - val_mae: 27.9063 - lr: 0.4000\n",
            "Epoch 13/13\n",
            "909/909 [==============================] - 28s 31ms/step - loss: 28.7797 - mae: 29.4483 - val_loss: 27.3286 - val_mae: 27.9923 - lr: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_vs_loss(history_NewExp0Gp0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "l1kSWkiBqpHb",
        "outputId": "d44c40bd-1ec2-4f13-9b70-ab288baa8c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> $0.001$ is a good learning rate"
      ],
      "metadata": {
        "id": "luJVFJTJrl1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in test_kds_uni_mean.ds_in.take(1):\n",
        "    inputA = a\n",
        "    inputB = b\n",
        "for a in test_kds_uni_mean.ds_out.take(1):\n",
        "    output = a\n",
        "model_NewExp0Gp0.predict((inputA, inputB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLpTIZSYq2oQ",
        "outputId": "8b9e1ec4-fe07-4d64-c213-4317cdd6b62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [343.2477 , 261.5991 ],\n",
              "       [109.27468, 247.13338],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109],\n",
              "       [109.23762, 247.13109]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputA.shape, inputB.shape, output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63hpQ2sfs02m",
        "outputId": "c9ce62f6-6637-46dd-8dbf-6ee12362ed06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 30, 80]), TensorShape([64, 78]), TensorShape([64, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovCOR3zurVn3",
        "outputId": "3632a874-6b60-4382-d80b-2bcb20894549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 2), dtype=float64, numpy=\n",
              "array([[  99.,  247.],\n",
              "       [ 109.,  232.],\n",
              "       [ 106.,  372.],\n",
              "       [ 113.,  255.],\n",
              "       [  86.,  304.],\n",
              "       [ 101.,  236.],\n",
              "       [ 113.,  255.],\n",
              "       [ 106.,  372.],\n",
              "       [ 131.,  256.],\n",
              "       [ 106.,  372.],\n",
              "       [ 102.,  216.],\n",
              "       [ 104.,  263.],\n",
              "       [ 104.,  242.],\n",
              "       [ 104.,  242.],\n",
              "       [ 104.,  263.],\n",
              "       [ 103.,  274.],\n",
              "       [ 102.,  217.],\n",
              "       [ 106.,  372.],\n",
              "       [  97.,  228.],\n",
              "       [ 113.,  255.],\n",
              "       [  97.,  228.],\n",
              "       [ 111.,  241.],\n",
              "       [ 113.,  256.],\n",
              "       [ 104.,  263.],\n",
              "       [ 131.,  256.],\n",
              "       [  99.,  247.],\n",
              "       [ 106.,  372.],\n",
              "       [ 104.,  242.],\n",
              "       [ 111.,  241.],\n",
              "       [ 106.,  372.],\n",
              "       [ 104.,  242.],\n",
              "       [ 100.,  203.],\n",
              "       [ 111.,  241.],\n",
              "       [ 120.,  247.],\n",
              "       [ 113.,  255.],\n",
              "       [ 106.,  372.],\n",
              "       [ 124.,  256.],\n",
              "       [ 100.,  203.],\n",
              "       [ 111.,  241.],\n",
              "       [ 106.,  372.],\n",
              "       [ 109.,  232.],\n",
              "       [ 104.,  263.],\n",
              "       [ 113.,  255.],\n",
              "       [ 120.,  247.],\n",
              "       [ 981., 1047.],\n",
              "       [  86.,  304.],\n",
              "       [  86.,  304.],\n",
              "       [ 109.,  232.],\n",
              "       [ 337.,  243.],\n",
              "       [ 104.,  263.],\n",
              "       [ 109.,  232.],\n",
              "       [ 106.,  372.],\n",
              "       [  99.,  247.],\n",
              "       [  99.,  262.],\n",
              "       [ 103.,  274.],\n",
              "       [ 117.,  221.],\n",
              "       [ 100.,  203.],\n",
              "       [ 106.,  372.],\n",
              "       [ 109.,  232.],\n",
              "       [ 111.,  241.],\n",
              "       [ 113.,  255.],\n",
              "       [ 120.,  247.],\n",
              "       [ 103.,  274.],\n",
              "       [ 106.,  452.]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion"
      ],
      "metadata": {
        "id": "rYEaDSDUyoJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction output vectors are almost ALL the same!! Something is probably wrong with the model."
      ],
      "metadata": {
        "id": "Q6tX3txK3TWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group 1 \n",
        "\n",
        "* GRU as backbone of concat model --> Dense layer\n",
        "* epoch 13 --> 10"
      ],
      "metadata": {
        "id": "jJtGkq5AvSNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_mode = 'median'\n",
        "\n",
        "train_df_uni_median = train_extractor.unigraph_avg(avg_mode)\n",
        "test_df_uni_median = test_extractor.unigraph_avg(avg_mode)\n",
        "\n",
        "n_steps = 30\n",
        "shift = 1\n",
        "batch_size = 64\n",
        "\n",
        "train_kds_uni_median = prep.KDS(train_df_uni_mean, n_steps, shift, batch_size, encoder=uni_encoder, mode='uni')\n",
        "test_kds_uni_median = prep.KDS(test_df_uni_mean, n_steps, shift, batch_size, encoder=uni_encoder, mode='uni')"
      ],
      "metadata": {
        "id": "yf5QCTJir4ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Ooooopsss, accidentally still used the mean data since forget to change `prep.KDS(train_df_uni_mean)`"
      ],
      "metadata": {
        "id": "-Jx2nsrYxK_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_uni_median.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "r-o4Y8RdsCfs",
        "outputId": "fd0dbcef-f72c-4a10-8282-5d220e201f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         USER   INDEX      HL      PL\n",
              "count 58246.0 58246.0 58246.0 58246.0\n",
              "mean    180.1    27.0   106.4   185.3\n",
              "std     102.5    19.4    29.8    43.5\n",
              "min       5.0     0.0     0.0    23.0\n",
              "25%      88.0    11.0    95.0   168.0\n",
              "50%     186.0    24.0   103.0   176.0\n",
              "75%     275.0    39.0   107.0   177.0\n",
              "max     346.0   134.0   272.0  5329.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6fa7d14-5b64-4daf-9ef3-c7fd20dec1fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER</th>\n",
              "      <th>INDEX</th>\n",
              "      <th>HL</th>\n",
              "      <th>PL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>180.1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>106.4</td>\n",
              "      <td>185.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>102.5</td>\n",
              "      <td>19.4</td>\n",
              "      <td>29.8</td>\n",
              "      <td>43.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>88.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>168.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>186.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>176.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>275.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>177.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>346.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>272.0</td>\n",
              "      <td>5329.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6fa7d14-5b64-4daf-9ef3-c7fd20dec1fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6fa7d14-5b64-4daf-9ef3-c7fd20dec1fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6fa7d14-5b64-4daf-9ef3-c7fd20dec1fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_uni_median.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "dtrTt1VesHY_",
        "outputId": "d4ae266c-4d67-42e1-b6a4-66704cdec016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         USER   INDEX      HL      PL\n",
              "count 14559.0 14559.0 14559.0 14559.0\n",
              "mean    180.2    29.0   107.2   190.2\n",
              "std     102.5    20.3    31.3    44.9\n",
              "min       5.0     0.0    47.0   142.0\n",
              "25%      88.0    13.0    96.0   174.0\n",
              "50%     186.0    26.0   103.0   179.0\n",
              "75%     275.0    42.0   108.0   185.0\n",
              "max     346.0   117.0   272.0  1846.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a6de9fc-af33-4c05-b8ee-759cc7e88c4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER</th>\n",
              "      <th>INDEX</th>\n",
              "      <th>HL</th>\n",
              "      <th>PL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14559.0</td>\n",
              "      <td>14559.0</td>\n",
              "      <td>14559.0</td>\n",
              "      <td>14559.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>180.2</td>\n",
              "      <td>29.0</td>\n",
              "      <td>107.2</td>\n",
              "      <td>190.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>102.5</td>\n",
              "      <td>20.3</td>\n",
              "      <td>31.3</td>\n",
              "      <td>44.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>142.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>88.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>174.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>186.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>179.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>275.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>346.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>272.0</td>\n",
              "      <td>1846.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a6de9fc-af33-4c05-b8ee-759cc7e88c4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a6de9fc-af33-4c05-b8ee-759cc7e88c4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a6de9fc-af33-4c05-b8ee-759cc7e88c4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds_uni_mean.inputA[-1]\n",
        "output_dim = train_kds_uni_mean.output[-1]\n",
        "user_gru = 64\n",
        "# concat_gru = 32\n",
        "\n",
        "inputA = keras.layers.Input(shape=[None, feature_dim], name='InputA')\n",
        "inputB = keras.layers.Input(shape=[feature_dim-output_dim], name='InputB')\n",
        "\n",
        "batch_1 = keras.layers.BatchNormalization()(inputA)\n",
        "gru_1 = keras.layers.GRU(user_gru, return_sequences=True)(batch_1)\n",
        "dropout_1 = keras.layers.Dropout(0.5)(gru_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
        "gru_out = keras.layers.GRU(user_gru)(batch_2)\n",
        "\n",
        "concat = keras.layers.concatenate([gru_out, inputB])\n",
        "\n",
        "# reshape = keras.layers.Reshape((user_gru+feature_dim-output_dim, 1))(concat)\n",
        "# concat_output = keras.layers.GRU(concat_gru)(reshape)\n",
        "\n",
        "dense_1 = keras.layers.Dense(60)(concat)\n",
        "concat_output = keras.layers.Dense(30)(dense_1)\n",
        "\n",
        "output = keras.layers.Dense(output_dim)(concat_output)\n",
        "\n",
        "##change model name 0\n",
        "model_name = 'NewExp0Gp1'\n",
        "model_NewExp0Gp1 = keras.Model(inputs=[inputA, inputB], outputs=[output], name=model_name)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds_uni_mean.ds\n",
        "testset = test_kds_uni_mean.ds\n",
        "EPOCH = 10\n",
        "\n",
        "def lr_finder(epoch):\n",
        "    num1 = 4 - (epoch - 1) // 3\n",
        "    num2 = 1 + (epoch - 1) % 3 * 3\n",
        "    lr = round(0.1 ** num1 * num2, 7)\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = prep.create_tensorboard_callback(model_name, avg_mode=True)\n",
        "\n",
        "##change model name 3\n",
        "model_NewExp0Gp1.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "\n",
        "##change model name 4 + 5\n",
        "history_NewExp0Gp1 = model_NewExp0Gp1.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[lr_scheduler, tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nid9zs7-sS81",
        "outputId": "7c4159a0-4e26-45a0-f6b3-d56f34bdf3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/NewExp0Gp1/20221206-214948-avg\n",
            "Epoch 1/10\n",
            "909/909 [==============================] - 24s 23ms/step - loss: 110.2130 - mae: 110.9025 - val_loss: 47.3997 - val_mae: 48.0834 - lr: 7.0000e-05\n",
            "Epoch 2/10\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 35.5307 - mae: 36.2048 - val_loss: 27.7815 - val_mae: 28.4526 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 25.5461 - mae: 26.2026 - val_loss: 23.8219 - val_mae: 24.4786 - lr: 4.0000e-04\n",
            "Epoch 4/10\n",
            "909/909 [==============================] - 21s 23ms/step - loss: 14.4531 - mae: 14.9566 - val_loss: 13.8998 - val_mae: 14.5222 - lr: 7.0000e-04\n",
            "Epoch 5/10\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 7.3300 - mae: 7.6678 - val_loss: 13.3545 - val_mae: 13.9846 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 7.5209 - mae: 8.1240 - val_loss: 10.5565 - val_mae: 11.1863 - lr: 0.0040\n",
            "Epoch 7/10\n",
            "909/909 [==============================] - 27s 30ms/step - loss: 6.0415 - mae: 6.6729 - val_loss: 11.6418 - val_mae: 12.3105 - lr: 0.0070\n",
            "Epoch 8/10\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 6.2512 - mae: 6.8931 - val_loss: 11.3689 - val_mae: 12.0383 - lr: 0.0100\n",
            "Epoch 9/10\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 12.3626 - mae: 13.0309 - val_loss: 10.3535 - val_mae: 11.0077 - lr: 0.0400\n",
            "Epoch 10/10\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 11.5242 - mae: 12.1890 - val_loss: 9.9352 - val_mae: 10.5760 - lr: 0.0700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Loss aroun 0.001 is still the best"
      ],
      "metadata": {
        "id": "bElFsB7rvoaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_vs_loss(history_NewExp0Gp1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "4Uunj-uzvMqB",
        "outputId": "915f0419-004b-4e27-ab94-12c2f8f4db05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in test_kds_uni_median.ds_in.take(1):\n",
        "    inputA = a\n",
        "    inputB = b\n",
        "for a in test_kds_uni_median.ds_out.take(1):\n",
        "    output = a\n",
        "model_NewExp0Gp1.predict((inputA, inputB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8lQjLaGvw-M",
        "outputId": "57f52c84-b325-4e87-fabc-b1e3aa742b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 97.225006, 223.56552 ],\n",
              "       [111.63891 , 236.14406 ],\n",
              "       [110.15482 , 375.402   ],\n",
              "       [113.57613 , 237.90764 ],\n",
              "       [ 91.411644, 307.00558 ],\n",
              "       [ 94.30868 , 227.24858 ],\n",
              "       [113.49027 , 237.56604 ],\n",
              "       [110.012215, 374.83264 ],\n",
              "       [129.07881 , 242.87149 ],\n",
              "       [109.95508 , 374.60486 ],\n",
              "       [104.79095 , 202.43713 ],\n",
              "       [108.54989 , 239.14185 ],\n",
              "       [103.37226 , 212.13908 ],\n",
              "       [103.34362 , 212.02515 ],\n",
              "       [108.46427 , 238.80031 ],\n",
              "       [105.81512 , 256.8933  ],\n",
              "       [103.0222  , 211.78677 ],\n",
              "       [109.72649 , 373.69406 ],\n",
              "       [104.616425, 225.53125 ],\n",
              "       [113.11929 , 236.08562 ],\n",
              "       [104.55938 , 225.30356 ],\n",
              "       [107.99679 , 222.99197 ],\n",
              "       [110.98541 , 251.96245 ],\n",
              "       [108.20723 , 237.77553 ],\n",
              "       [128.622   , 241.04955 ],\n",
              "       [ 96.51155 , 220.71854 ],\n",
              "       [109.46978 , 372.66895 ],\n",
              "       [102.94408 , 210.43114 ],\n",
              "       [107.796844, 222.19499 ],\n",
              "       [109.38398 , 372.32748 ],\n",
              "       [102.85833 , 210.08939 ],\n",
              "       [ 96.404465, 205.15527 ],\n",
              "       [107.68275 , 221.73936 ],\n",
              "       [116.7516  , 249.68365 ],\n",
              "       [112.69107 , 234.37753 ],\n",
              "       [109.2128  , 371.64417 ],\n",
              "       [118.19129 , 213.48686 ],\n",
              "       [ 96.23331 , 204.472   ],\n",
              "       [107.51128 , 221.05621 ],\n",
              "       [109.09867 , 371.18866 ],\n",
              "       [110.524734, 231.70311 ],\n",
              "       [107.693275, 235.72575 ],\n",
              "       [112.46277 , 233.46655 ],\n",
              "       [116.466324, 248.54485 ],\n",
              "       [507.7972  , 745.0124  ],\n",
              "       [ 90.24113 , 302.33673 ],\n",
              "       [ 90.21257 , 302.22293 ],\n",
              "       [110.325806, 230.9058  ],\n",
              "       [345.73477 , 246.16685 ],\n",
              "       [109.09222 , 241.3055  ],\n",
              "       [111.86737 , 237.05496 ],\n",
              "       [110.3833  , 376.3129  ],\n",
              "       [ 97.36775 , 224.1349  ],\n",
              "       [ 99.305695, 271.0585  ],\n",
              "       [106.32884 , 258.94302 ],\n",
              "       [114.991776, 223.7773  ],\n",
              "       [ 97.31813 , 208.79915 ],\n",
              "       [110.21203 , 375.62967 ],\n",
              "       [111.63902 , 236.14401 ],\n",
              "       [108.53921 , 225.15556 ],\n",
              "       [113.57614 , 237.9076  ],\n",
              "       [117.57966 , 252.98596 ],\n",
              "       [106.1006  , 258.03204 ],\n",
              "       [226.76636 , 454.86133 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZbiTtm2vw7m",
        "outputId": "5c23f34a-dc50-4521-a1fc-44ddd47703a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 2), dtype=float64, numpy=\n",
              "array([[  99.,  247.],\n",
              "       [ 109.,  232.],\n",
              "       [ 106.,  372.],\n",
              "       [ 113.,  255.],\n",
              "       [  86.,  304.],\n",
              "       [ 101.,  236.],\n",
              "       [ 113.,  255.],\n",
              "       [ 106.,  372.],\n",
              "       [ 131.,  256.],\n",
              "       [ 106.,  372.],\n",
              "       [ 102.,  216.],\n",
              "       [ 104.,  263.],\n",
              "       [ 104.,  242.],\n",
              "       [ 104.,  242.],\n",
              "       [ 104.,  263.],\n",
              "       [ 103.,  274.],\n",
              "       [ 102.,  217.],\n",
              "       [ 106.,  372.],\n",
              "       [  97.,  228.],\n",
              "       [ 113.,  255.],\n",
              "       [  97.,  228.],\n",
              "       [ 111.,  241.],\n",
              "       [ 113.,  256.],\n",
              "       [ 104.,  263.],\n",
              "       [ 131.,  256.],\n",
              "       [  99.,  247.],\n",
              "       [ 106.,  372.],\n",
              "       [ 104.,  242.],\n",
              "       [ 111.,  241.],\n",
              "       [ 106.,  372.],\n",
              "       [ 104.,  242.],\n",
              "       [ 100.,  203.],\n",
              "       [ 111.,  241.],\n",
              "       [ 120.,  247.],\n",
              "       [ 113.,  255.],\n",
              "       [ 106.,  372.],\n",
              "       [ 124.,  256.],\n",
              "       [ 100.,  203.],\n",
              "       [ 111.,  241.],\n",
              "       [ 106.,  372.],\n",
              "       [ 109.,  232.],\n",
              "       [ 104.,  263.],\n",
              "       [ 113.,  255.],\n",
              "       [ 120.,  247.],\n",
              "       [ 981., 1047.],\n",
              "       [  86.,  304.],\n",
              "       [  86.,  304.],\n",
              "       [ 109.,  232.],\n",
              "       [ 337.,  243.],\n",
              "       [ 104.,  263.],\n",
              "       [ 109.,  232.],\n",
              "       [ 106.,  372.],\n",
              "       [  99.,  247.],\n",
              "       [  99.,  262.],\n",
              "       [ 103.,  274.],\n",
              "       [ 117.,  221.],\n",
              "       [ 100.,  203.],\n",
              "       [ 106.,  372.],\n",
              "       [ 109.,  232.],\n",
              "       [ 111.,  241.],\n",
              "       [ 113.,  255.],\n",
              "       [ 120.,  247.],\n",
              "       [ 103.,  274.],\n",
              "       [ 106.,  452.]])>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion"
      ],
      "metadata": {
        "id": "G51WaUfIvw4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU concat layer is BAD. lr $0.001$ is GOOD. (naming convention is bad, forgot to change many places from `mean`-->`median`, so the dataset used to train is actually still `mean`)"
      ],
      "metadata": {
        "id": "Z66-CVGS3QEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group 2: trying multi-user to get a feel\n",
        "\n",
        "* mean --> avg_mode = False\n",
        "* keep Dense layer\n",
        "* epoch 10 --> 15\n",
        "* uniformize naming of variables (independent of hyperparams)"
      ],
      "metadata": {
        "id": "T2sSdQ7wvw26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_mode = False\n",
        "\n",
        "train_df = train_extractor.unigraph\n",
        "test_df = test_extractor.unigraph\n",
        "\n",
        "n_steps = 30\n",
        "shift = 1\n",
        "batch_size = 64\n",
        "\n",
        "train_kds = prep.KDS(train_df, n_steps, shift, batch_size, encoder=uni_encoder, mode='uni')\n",
        "test_kds = prep.KDS(test_df, n_steps, shift, batch_size, encoder=uni_encoder, mode='uni')"
      ],
      "metadata": {
        "id": "LepAL5hivw0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df['PL'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIB8GmdyvwyO",
        "outputId": "58b8f3b2-efaa-4029-8d83-22e6c368c0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1852"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Iy0zhJuWvwvn",
        "outputId": "7b9436d6-9a43-4e67-a5e5-0faf79bc4a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         USER   INDEX      HL      PL\n",
              "count 58246.0 58246.0 58246.0 58246.0\n",
              "mean    180.1    27.0   118.9   275.1\n",
              "std     102.5    19.4   264.9   374.7\n",
              "min       5.0     0.0   -63.0     0.0\n",
              "25%      88.0    11.0    80.0   128.0\n",
              "50%     186.0    24.0   103.0   180.0\n",
              "75%     275.0    39.0   132.0   288.0\n",
              "max     346.0   134.0 29164.0 23604.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71c13506-11a1-4d12-92d6-5c32bafac7ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER</th>\n",
              "      <th>INDEX</th>\n",
              "      <th>HL</th>\n",
              "      <th>PL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>180.1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>118.9</td>\n",
              "      <td>275.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>102.5</td>\n",
              "      <td>19.4</td>\n",
              "      <td>264.9</td>\n",
              "      <td>374.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>88.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>186.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>275.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>288.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>346.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>29164.0</td>\n",
              "      <td>23604.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71c13506-11a1-4d12-92d6-5c32bafac7ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71c13506-11a1-4d12-92d6-5c32bafac7ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71c13506-11a1-4d12-92d6-5c32bafac7ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds.inputA[-1]\n",
        "output_dim = train_kds.output[-1]\n",
        "user_gru = 64\n",
        "# concat_gru = 32\n",
        "\n",
        "inputA = keras.layers.Input(shape=[None, feature_dim], name='InputA')\n",
        "inputB = keras.layers.Input(shape=[feature_dim-output_dim], name='InputB')\n",
        "\n",
        "batch_1 = keras.layers.BatchNormalization()(inputA)\n",
        "gru_1 = keras.layers.GRU(user_gru, return_sequences=True)(batch_1)\n",
        "dropout_1 = keras.layers.Dropout(0.5)(gru_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
        "gru_out = keras.layers.GRU(user_gru)(batch_2)\n",
        "\n",
        "concat = keras.layers.concatenate([gru_out, inputB])\n",
        "\n",
        "# reshape = keras.layers.Reshape((user_gru+feature_dim-output_dim, 1))(concat)\n",
        "# concat_output = keras.layers.GRU(concat_gru)(reshape)\n",
        "\n",
        "dense_1 = keras.layers.Dense(60)(concat)\n",
        "concat_output = keras.layers.Dense(30)(dense_1)\n",
        "\n",
        "output = keras.layers.Dense(output_dim)(concat_output)\n",
        "\n",
        "##change model name 0\n",
        "model_name = 'NewExp0Gp2'\n",
        "model_NewExp0Gp2 = keras.Model(inputs=[inputA, inputB], outputs=[output], name=model_name)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds.ds\n",
        "testset = test_kds.ds\n",
        "EPOCH = 15\n",
        "\n",
        "def lr_finder(epoch):\n",
        "    num1 = 4 - (epoch - 1) // 3\n",
        "    num2 = 1 + (epoch - 1) % 3 * 3\n",
        "    lr = round(0.1 ** num1 * num2, 7)\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = prep.create_tensorboard_callback(model_name, avg_mode=True)\n",
        "\n",
        "##change model name 3\n",
        "model_NewExp0Gp2.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "\n",
        "##change model name 4 + 5\n",
        "history_NewExp0Gp2 = model_NewExp0Gp2.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[lr_scheduler, tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oru5SF3vwrM",
        "outputId": "4cf11581-cf29-4d04-9496-3cd7bd06fd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/NewExp0Gp2/20221206-221835-avg\n",
            "Epoch 1/15\n",
            "909/909 [==============================] - 25s 24ms/step - loss: 141.0952 - mae: 141.7855 - val_loss: 98.1198 - val_mae: 98.8077 - lr: 7.0000e-05\n",
            "Epoch 2/15\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 98.5051 - mae: 99.1925 - val_loss: 96.4227 - val_mae: 97.1093 - lr: 1.0000e-04\n",
            "Epoch 3/15\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 96.1477 - mae: 96.8348 - val_loss: 96.5652 - val_mae: 97.2522 - lr: 4.0000e-04\n",
            "Epoch 4/15\n",
            "909/909 [==============================] - 21s 23ms/step - loss: 95.8032 - mae: 96.4903 - val_loss: 97.0415 - val_mae: 97.7280 - lr: 7.0000e-04\n",
            "Epoch 5/15\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 95.6707 - mae: 96.3576 - val_loss: 97.8181 - val_mae: 98.5045 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 99.0011 - mae: 99.6889 - val_loss: 103.4879 - val_mae: 104.1746 - lr: 0.0040\n",
            "Epoch 7/15\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 99.0333 - mae: 99.7211 - val_loss: 102.1453 - val_mae: 102.8321 - lr: 0.0070\n",
            "Epoch 8/15\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 97.7499 - mae: 98.4376 - val_loss: 99.8099 - val_mae: 100.4968 - lr: 0.0100\n",
            "Epoch 9/15\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 94.6373 - mae: 95.3239 - val_loss: 91.6446 - val_mae: 92.3321 - lr: 0.0400\n",
            "Epoch 10/15\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 95.7539 - mae: 96.4412 - val_loss: 99.1184 - val_mae: 99.8055 - lr: 0.0700\n",
            "Epoch 11/15\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 100.6167 - mae: 101.3046 - val_loss: 91.9258 - val_mae: 92.6123 - lr: 0.1000\n",
            "Epoch 12/15\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 4089.4316 - mae: 4090.1252 - val_loss: 104.1967 - val_mae: 104.8841 - lr: 0.4000\n",
            "Epoch 13/15\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 108.0385 - mae: 108.7267 - val_loss: 96.0226 - val_mae: 96.7102 - lr: 0.7000\n",
            "Epoch 14/15\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 98.8731 - mae: 99.5601 - val_loss: 102.0938 - val_mae: 102.7808 - lr: 1.0000\n",
            "Epoch 15/15\n",
            "909/909 [==============================] - 21s 24ms/step - loss: 1495683.1250 - mae: 1495683.7500 - val_loss: 583.2085 - val_mae: 583.9014 - lr: 4.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_vs_loss(history_NewExp0Gp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "ki9r9Lx3yX75",
        "outputId": "e3594cd3-2812-4562-d404-2615e574e823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in test_kds.ds_in.take(1):\n",
        "    inputA = a\n",
        "    inputB = b\n",
        "for a in test_kds.ds_out.take(1):\n",
        "    output = a\n",
        "model_NewExp0Gp2.predict((inputA, inputB))"
      ],
      "metadata": {
        "id": "3LF0liV1Cq6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion"
      ],
      "metadata": {
        "id": "6KwaaiiuyX5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The traininng with multiple user \"improved\" a lot from previous trainings --> at least the loss looks more resonable now. \n",
        "\n",
        "However, given that the mean and median of the training data is around 200, the loss is not ideal. (This could be because we are experimenting with learning rate at the moment)\n",
        "\n",
        "**Should try training HL and PL separately in NewExp1; to do that: need to modify KDS first**\n",
        "\n",
        "> Forgot to turn `tensorboard` `avg_mode=False`"
      ],
      "metadata": {
        "id": "fyf2_DVcyX2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group 3 (from Group 1)\n",
        "\n",
        "* avg_mode --> median\n",
        "* uni --> di"
      ],
      "metadata": {
        "id": "uPtRfnmf3d1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_mode = 'median'\n",
        "\n",
        "train_df = train_extractor.digraph_avg(avg_mode)\n",
        "test_df = test_extractor.digraph_avg(avg_mode)\n",
        "\n",
        "n_steps = 30\n",
        "shift = 1\n",
        "batch_size = 64\n",
        "\n",
        "train_kds = prep.KDS(train_df, n_steps, shift, batch_size, encoder=di_encoder, mode='di')\n",
        "test_kds = prep.KDS(test_df, n_steps, shift, batch_size, encoder=di_encoder, mode='di')"
      ],
      "metadata": {
        "id": "x2CV-XLj3dy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_fRUN5uc4bC1",
        "outputId": "2c7a74b1-8a32-4d54-f491-274138c0da0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         USER      I1      I2     HL1     HL2      PL\n",
              "count 58246.0 58246.0 58246.0 58246.0 58246.0 58246.0\n",
              "mean    180.1    27.0    28.0   109.6   104.2   203.0\n",
              "std     102.5    19.4    19.4   166.3    48.4   160.8\n",
              "min       5.0     0.0     1.0     0.0     0.0     2.0\n",
              "25%      88.0    11.0    12.0    96.0    95.0   151.0\n",
              "50%     186.0    24.0    25.0   103.0   102.0   169.0\n",
              "75%     275.0    39.0    40.0   110.0   110.0   216.0\n",
              "max     346.0   134.0   135.0 14646.0  9460.0 23604.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ccc21b5-b429-4db6-8121-35bd1051c73e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER</th>\n",
              "      <th>I1</th>\n",
              "      <th>I2</th>\n",
              "      <th>HL1</th>\n",
              "      <th>HL2</th>\n",
              "      <th>PL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "      <td>58246.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>180.1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>109.6</td>\n",
              "      <td>104.2</td>\n",
              "      <td>203.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>102.5</td>\n",
              "      <td>19.4</td>\n",
              "      <td>19.4</td>\n",
              "      <td>166.3</td>\n",
              "      <td>48.4</td>\n",
              "      <td>160.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>88.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>151.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>186.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>169.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>275.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>216.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>346.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>14646.0</td>\n",
              "      <td>9460.0</td>\n",
              "      <td>23604.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ccc21b5-b429-4db6-8121-35bd1051c73e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ccc21b5-b429-4db6-8121-35bd1051c73e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ccc21b5-b429-4db6-8121-35bd1051c73e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds.inputA[-1]\n",
        "output_dim = train_kds.output[-1]\n",
        "user_gru = 64\n",
        "# concat_gru = 32\n",
        "\n",
        "inputA = keras.layers.Input(shape=[None, feature_dim], name='InputA')\n",
        "inputB = keras.layers.Input(shape=[feature_dim-output_dim], name='InputB')\n",
        "\n",
        "batch_1 = keras.layers.BatchNormalization()(inputA)\n",
        "gru_1 = keras.layers.GRU(user_gru, return_sequences=True)(batch_1)\n",
        "dropout_1 = keras.layers.Dropout(0.5)(gru_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
        "gru_out = keras.layers.GRU(user_gru)(batch_2)\n",
        "\n",
        "concat = keras.layers.concatenate([gru_out, inputB])\n",
        "\n",
        "# reshape = keras.layers.Reshape((user_gru+feature_dim-output_dim, 1))(concat)\n",
        "# concat_output = keras.layers.GRU(concat_gru)(reshape)\n",
        "\n",
        "dense_1 = keras.layers.Dense(60)(concat)\n",
        "concat_output = keras.layers.Dense(30)(dense_1)\n",
        "\n",
        "output = keras.layers.Dense(output_dim)(concat_output)\n",
        "\n",
        "##change model name 0\n",
        "model_name = 'NewExp0Gp3'\n",
        "model_NewExp0Gp3 = keras.Model(inputs=[inputA, inputB], outputs=[output], name=model_name)\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds.ds\n",
        "testset = test_kds.ds\n",
        "EPOCH = 15\n",
        "\n",
        "# def lr_finder(epoch):\n",
        "#     num1 = 4 - (epoch - 1) // 3\n",
        "#     num2 = 1 + (epoch - 1) % 3 * 3\n",
        "#     lr = round(0.1 ** num1 * num2, 7)\n",
        "#     return lr\n",
        "\n",
        "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = prep.create_tensorboard_callback(model_name, avg_mode=avg_mode)\n",
        "\n",
        "##change model name 3\n",
        "model_NewExp0Gp3.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "\n",
        "##change model name 4 + 5\n",
        "history_NewExp0Gp3 = model_NewExp0Gp3.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaR2WGKZ3dwy",
        "outputId": "707f7b75-463d-4329-d40c-a75cf5757760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/NewExp0Gp3/20221206-224424-avg\n",
            "Epoch 1/15\n",
            "909/909 [==============================] - 28s 27ms/step - loss: 32.3215 - mae: 32.9854 - val_loss: 28.4961 - val_mae: 29.1557\n",
            "Epoch 2/15\n",
            "909/909 [==============================] - 23s 26ms/step - loss: 23.8059 - mae: 24.4501 - val_loss: 27.5187 - val_mae: 28.1829\n",
            "Epoch 3/15\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 22.4357 - mae: 23.0748 - val_loss: 26.7923 - val_mae: 27.4575\n",
            "Epoch 4/15\n",
            "909/909 [==============================] - 23s 26ms/step - loss: 21.4741 - mae: 22.1098 - val_loss: 26.3017 - val_mae: 26.9653\n",
            "Epoch 5/15\n",
            "909/909 [==============================] - 24s 26ms/step - loss: 20.8148 - mae: 21.4488 - val_loss: 25.8931 - val_mae: 26.5572\n",
            "Epoch 6/15\n",
            "909/909 [==============================] - 25s 27ms/step - loss: 20.3812 - mae: 21.0152 - val_loss: 25.5911 - val_mae: 26.2526\n",
            "Epoch 7/15\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 19.9498 - mae: 20.5849 - val_loss: 25.3259 - val_mae: 25.9914\n",
            "Epoch 8/15\n",
            "909/909 [==============================] - 24s 26ms/step - loss: 19.5125 - mae: 20.1475 - val_loss: 25.1492 - val_mae: 25.8167\n",
            "Epoch 9/15\n",
            "909/909 [==============================] - 22s 25ms/step - loss: 19.0471 - mae: 19.6829 - val_loss: 24.7873 - val_mae: 25.4528\n",
            "Epoch 10/15\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 18.7360 - mae: 19.3687 - val_loss: 24.5837 - val_mae: 25.2448\n",
            "Epoch 11/15\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 18.5322 - mae: 19.1662 - val_loss: 24.3924 - val_mae: 25.0569\n",
            "Epoch 12/15\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 18.1836 - mae: 18.8181 - val_loss: 24.1835 - val_mae: 24.8429\n",
            "Epoch 13/15\n",
            "909/909 [==============================] - 24s 27ms/step - loss: 18.0641 - mae: 18.6981 - val_loss: 24.5846 - val_mae: 25.2508\n",
            "Epoch 14/15\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 17.6278 - mae: 18.2601 - val_loss: 24.0781 - val_mae: 24.7407\n",
            "Epoch 15/15\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 17.3116 - mae: 17.9453 - val_loss: 24.0376 - val_mae: 24.6953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion"
      ],
      "metadata": {
        "id": "-VlHDjHJ98ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model seems to need more training time. Let us try a high epoch with added EarlyStopping"
      ],
      "metadata": {
        "id": "KV4dxO3i3duf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group 4 (from Group 3)\n",
        "\n",
        "* epoch --> 100\n",
        "* earlystopping"
      ],
      "metadata": {
        "id": "Sv-HeIoF-LMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_mode = 'median'\n",
        "\n",
        "train_df = train_extractor.digraph_avg(avg_mode)\n",
        "test_df = test_extractor.digraph_avg(avg_mode)\n",
        "\n",
        "n_steps = 30\n",
        "shift = 1\n",
        "batch_size = 64\n",
        "\n",
        "train_kds = prep.KDS(train_df, n_steps, shift, batch_size, encoder=di_encoder, mode='di')\n",
        "test_kds = prep.KDS(test_df, n_steps, shift, batch_size, encoder=di_encoder, mode='di')"
      ],
      "metadata": {
        "id": "_LxVbWv6-LKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds.inputA[-1]\n",
        "output_dim = train_kds.output[-1]\n",
        "user_gru = 64\n",
        "# concat_gru = 32\n",
        "\n",
        "inputA = keras.layers.Input(shape=[None, feature_dim], name='InputA')\n",
        "inputB = keras.layers.Input(shape=[feature_dim-output_dim], name='InputB')\n",
        "\n",
        "batch_1 = keras.layers.BatchNormalization()(inputA)\n",
        "gru_1 = keras.layers.GRU(user_gru, return_sequences=True)(batch_1)\n",
        "dropout_1 = keras.layers.Dropout(0.5)(gru_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
        "gru_out = keras.layers.GRU(user_gru)(batch_2)\n",
        "\n",
        "concat = keras.layers.concatenate([gru_out, inputB])\n",
        "\n",
        "# reshape = keras.layers.Reshape((user_gru+feature_dim-output_dim, 1))(concat)\n",
        "# concat_output = keras.layers.GRU(concat_gru)(reshape)\n",
        "\n",
        "dense_1 = keras.layers.Dense(60)(concat)\n",
        "concat_output = keras.layers.Dense(30)(dense_1)\n",
        "\n",
        "output = keras.layers.Dense(output_dim)(concat_output)\n",
        "\n",
        "##change model name 0\n",
        "model_name = 'NewExp0Gp4'\n",
        "model_NewExp0Gp4 = keras.Model(inputs=[inputA, inputB], outputs=[output], name=model_name)\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds.ds\n",
        "testset = test_kds.ds\n",
        "EPOCH = 100\n",
        "\n",
        "# def lr_finder(epoch):\n",
        "#     num1 = 4 - (epoch - 1) // 3\n",
        "#     num2 = 1 + (epoch - 1) % 3 * 3\n",
        "#     lr = round(0.1 ** num1 * num2, 7)\n",
        "#     return lr\n",
        "\n",
        "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "# tensorboard = prep.create_tensorboard_callback(model_name, avg_mode=avg_mode)\n",
        "\n",
        "##change model name 3\n",
        "model_NewExp0Gp4.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "\n",
        "##change model name 4 + 5\n",
        "history_NewExp0Gp4 = model_NewExp0Gp4.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=prep.get_callbacks(model_name, 4, avg_mode))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFv-Ledv-LIA",
        "outputId": "6e6d83e5-1240-4db4-c775-ab234594c665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ModelCheckpoint files to :/content/drive/MyDrive/COMP576/experiments/checkpoints/NewExp0Gp4/20221206-230646-avg\n",
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/NewExp0Gp4/20221206-230646-avg\n",
            "Epoch 1/100\n",
            "909/909 [==============================] - 26s 25ms/step - loss: 33.0976 - mae: 33.7631 - val_loss: 28.6564 - val_mae: 29.3196\n",
            "Epoch 2/100\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 23.8340 - mae: 24.4783 - val_loss: 27.5851 - val_mae: 28.2493\n",
            "Epoch 3/100\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 22.4287 - mae: 23.0664 - val_loss: 26.8124 - val_mae: 27.4778\n",
            "Epoch 4/100\n",
            "909/909 [==============================] - 24s 26ms/step - loss: 21.4641 - mae: 22.0980 - val_loss: 26.3186 - val_mae: 26.9836\n",
            "Epoch 5/100\n",
            "909/909 [==============================] - 24s 26ms/step - loss: 20.8247 - mae: 21.4575 - val_loss: 25.9035 - val_mae: 26.5693\n",
            "Epoch 6/100\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 20.3218 - mae: 20.9557 - val_loss: 25.7203 - val_mae: 26.3811\n",
            "Epoch 7/100\n",
            "909/909 [==============================] - 24s 26ms/step - loss: 19.9266 - mae: 20.5600 - val_loss: 25.4405 - val_mae: 26.1043\n",
            "Epoch 8/100\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 19.6504 - mae: 20.2854 - val_loss: 25.1109 - val_mae: 25.7758\n",
            "Epoch 9/100\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 19.1781 - mae: 19.8127 - val_loss: 24.7242 - val_mae: 25.3871\n",
            "Epoch 10/100\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 18.8192 - mae: 19.4524 - val_loss: 24.5681 - val_mae: 25.2314\n",
            "Epoch 11/100\n",
            "909/909 [==============================] - 23s 26ms/step - loss: 18.5613 - mae: 19.1933 - val_loss: 24.4904 - val_mae: 25.1557\n",
            "Epoch 12/100\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 18.4152 - mae: 19.0492 - val_loss: 24.2926 - val_mae: 24.9506\n",
            "Epoch 13/100\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 18.1080 - mae: 18.7402 - val_loss: 24.1671 - val_mae: 24.8277\n",
            "Epoch 14/100\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 17.8383 - mae: 18.4720 - val_loss: 24.2983 - val_mae: 24.9562\n",
            "Epoch 15/100\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 17.4942 - mae: 18.1264 - val_loss: 24.1705 - val_mae: 24.8302\n",
            "Epoch 16/100\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 17.2036 - mae: 17.8331 - val_loss: 23.9926 - val_mae: 24.6491\n",
            "Epoch 17/100\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 16.9213 - mae: 17.5507 - val_loss: 24.0604 - val_mae: 24.7181\n",
            "Epoch 18/100\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 16.5798 - mae: 17.2095 - val_loss: 24.2102 - val_mae: 24.8674\n",
            "Epoch 19/100\n",
            "909/909 [==============================] - 23s 26ms/step - loss: 16.3846 - mae: 17.0147 - val_loss: 24.3740 - val_mae: 25.0333\n",
            "Epoch 20/100\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 16.1333 - mae: 16.7626 - val_loss: 24.4760 - val_mae: 25.1346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in test_kds.ds_in.take(1):\n",
        "    inputA = a\n",
        "    inputB = b\n",
        "for a in test_kds.ds_out.take(1):\n",
        "    output = a\n",
        "model_NewExp0Gp4.predict((inputA, inputB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWrtjUBJ-LF7",
        "outputId": "31f29438-f828-4ef0-fde4-8a5a33de619f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[105.450005, 147.36287 ],\n",
              "       [103.19517 , 146.36296 ],\n",
              "       [106.6376  , 208.12663 ],\n",
              "       [ 76.378265, 446.91904 ],\n",
              "       [ 89.04304 , 100.05393 ],\n",
              "       [104.08657 , 143.08044 ],\n",
              "       [102.950645, 141.02246 ],\n",
              "       [126.86503 , 202.38203 ],\n",
              "       [101.52219 , 152.60733 ],\n",
              "       [102.79365 , 287.39413 ],\n",
              "       [ 87.0023  , 135.38852 ],\n",
              "       [ 95.58018 , 159.52689 ],\n",
              "       [ 95.858604, 165.32254 ],\n",
              "       [ 93.46136 , 164.71614 ],\n",
              "       [ 97.92571 , 161.61295 ],\n",
              "       [ 97.68009 , 146.93051 ],\n",
              "       [102.73592 , 142.59111 ],\n",
              "       [ 99.315   , 221.4344  ],\n",
              "       [105.91718 , 138.64586 ],\n",
              "       [ 99.90802 , 168.36176 ],\n",
              "       [101.18175 , 163.59857 ],\n",
              "       [104.58237 , 150.35895 ],\n",
              "       [ 95.03734 , 155.19727 ],\n",
              "       [126.18613 , 132.51065 ],\n",
              "       [ 90.09935 , 169.27731 ],\n",
              "       [ 97.92497 , 137.5647  ],\n",
              "       [ 96.00238 , 223.25882 ],\n",
              "       [100.249214, 124.70886 ],\n",
              "       [103.38757 , 150.70656 ],\n",
              "       [ 95.96989 , 222.99675 ],\n",
              "       [ 90.32896 , 122.707695],\n",
              "       [100.098885, 134.51035 ],\n",
              "       [111.14595 , 142.25235 ],\n",
              "       [105.94235 , 165.44849 ],\n",
              "       [102.4023  , 141.98259 ],\n",
              "       [113.800156, 226.5277  ],\n",
              "       [ 89.70642 , 165.87634 ],\n",
              "       [100.25536 , 133.81975 ],\n",
              "       [101.06938 , 136.39015 ],\n",
              "       [110.55221 , 252.09926 ],\n",
              "       [ 92.70869 , 158.61975 ],\n",
              "       [106.43424 , 145.12686 ],\n",
              "       [111.406166, 174.24342 ],\n",
              "       [ 84.15681 , 358.2031  ],\n",
              "       [ 63.059303, 519.01276 ],\n",
              "       [ 72.06541 , 358.39233 ],\n",
              "       [108.38027 , 215.76175 ],\n",
              "       [ 84.72667 , 350.2534  ],\n",
              "       [ 96.07062 , 147.25769 ],\n",
              "       [110.15572 , 228.79166 ],\n",
              "       [101.936   , 145.42186 ],\n",
              "       [ 91.65667 , 231.13495 ],\n",
              "       [ 89.576096, 194.22963 ],\n",
              "       [ 96.676544, 207.22011 ],\n",
              "       [109.10145 , 205.45168 ],\n",
              "       [ 93.02286 , 158.95253 ],\n",
              "       [101.96265 , 173.00392 ],\n",
              "       [111.40446 , 256.12186 ],\n",
              "       [102.57285 , 161.5228  ],\n",
              "       [108.06917 , 171.62424 ],\n",
              "       [112.02765 , 193.9102  ],\n",
              "       [ 97.11777 , 177.55852 ],\n",
              "       [ 92.192375, 493.01996 ],\n",
              "       [ 96.47804 , 209.28972 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6-vyBWy-LDl",
        "outputId": "e1442b98-b0eb-41dd-d7d4-fb93806f85f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 2), dtype=float64, numpy=\n",
              "array([[120., 150.],\n",
              "       [102., 144.],\n",
              "       [114., 305.],\n",
              "       [ 78., 442.],\n",
              "       [104., 240.],\n",
              "       [114., 190.],\n",
              "       [104., 141.],\n",
              "       [122., 198.],\n",
              "       [109., 162.],\n",
              "       [102., 304.],\n",
              "       [ 96., 159.],\n",
              "       [ 95., 181.],\n",
              "       [ 96., 151.],\n",
              "       [ 96., 150.],\n",
              "       [ 96., 163.],\n",
              "       [102., 138.],\n",
              "       [ 99., 136.],\n",
              "       [ 86., 230.],\n",
              "       [105., 137.],\n",
              "       [ 98., 168.],\n",
              "       [ 96., 174.],\n",
              "       [ 95., 163.],\n",
              "       [106., 172.],\n",
              "       [113., 157.],\n",
              "       [ 80., 176.],\n",
              "       [103., 166.],\n",
              "       [ 97., 208.],\n",
              "       [100., 129.],\n",
              "       [108., 152.],\n",
              "       [ 97., 208.],\n",
              "       [ 93., 118.],\n",
              "       [104., 150.],\n",
              "       [105., 128.],\n",
              "       [112., 185.],\n",
              "       [104., 141.],\n",
              "       [117., 242.],\n",
              "       [102., 170.],\n",
              "       [104., 150.],\n",
              "       [108., 152.],\n",
              "       [117., 233.],\n",
              "       [ 96., 146.],\n",
              "       [ 99., 145.],\n",
              "       [113., 193.],\n",
              "       [ 96., 259.],\n",
              "       [ 80., 581.],\n",
              "       [ 80., 155.],\n",
              "       [110., 146.],\n",
              "       [ 72., 448.],\n",
              "       [ 95., 140.],\n",
              "       [105., 173.],\n",
              "       [102., 144.],\n",
              "       [ 88., 192.],\n",
              "       [ 69., 183.],\n",
              "       [ 88., 201.],\n",
              "       [112., 168.],\n",
              "       [ 88., 140.],\n",
              "       [115., 178.],\n",
              "       [117., 233.],\n",
              "       [100., 112.],\n",
              "       [100., 284.],\n",
              "       [113., 193.],\n",
              "       [103., 256.],\n",
              "       [ 88., 497.],\n",
              "       [113., 163.]])>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion"
      ],
      "metadata": {
        "id": "pn00rgzg-LBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance is not bad, but also not ideal compared to uni-graph models. This could be because of the one-hot encoding on the pair of keycodes makes the feature inputs become 2X more sparse."
      ],
      "metadata": {
        "id": "IWf2X9gz-K_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8pM5as_je8Qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NExp1: `sample_size = 100`, `train_size = 0.8`\n",
        "\n",
        "**FIRST MODEL THAT WORKS \"NORMALLY\"!!**\n",
        "from **10^12 loss --> 500 + 11080 loss --> within 10^2 loss!!, good job Xingya**\n",
        "\n",
        "Goal: \n",
        "1. have a baseline learning rate (just use one set of parameters)\n",
        "2. decide `avg` should be `mean` or `median`\n",
        "\n",
        "Preping mode: \n",
        "* add_layout = False\n",
        "* remove_outliers = 1\n",
        "* conn_latency = 'PL'\n",
        "* n_steps = 30\n",
        "* shift = 1\n",
        "* batch_size = 64\n",
        "\n",
        "Total trainings: 8"
      ],
      "metadata": {
        "id": "ZHPoTbzqgkTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_dim = train_kds_uni_mean.inputA[-1]\n",
        "output_dim = train_kds_uni_mean.output[-1]\n",
        "user_gru = 64\n",
        "concat_gru = 32\n",
        "\n",
        "inputA = keras.layers.Input(shape=[None, feature_dim], name='InputA')\n",
        "inputB = keras.layers.Input(shape=[feature_dim-output_dim], name='InputB')\n",
        "\n",
        "batch_1 = keras.layers.BatchNormalization()(inputA)\n",
        "gru_1 = keras.layers.GRU(user_gru, return_sequences=True)(batch_1)\n",
        "dropout_1 = keras.layers.Dropout(0.5)(gru_1)\n",
        "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
        "gru_out = keras.layers.GRU(user_gru)(batch_2)\n",
        "\n",
        "concat = keras.layers.concatenate([gru_out, inputB])\n",
        "\n",
        "reshape = keras.layers.Reshape((user_gru+feature_dim-output_dim, 1))(concat)\n",
        "concat_output = keras.layers.GRU(concat_gru)(reshape)\n",
        "\n",
        "output = keras.layers.Dense(output_dim)(concat_output)\n",
        "\n",
        "##change model name 0\n",
        "model_name = 'NExp1Gp0'\n",
        "model_NExp1Gp0 = keras.Model(inputs=[inputA, inputB], outputs=[output], name=model_name)"
      ],
      "metadata": {
        "id": "40eAfjuYhTQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.LogCosh()\n",
        "metrics = ['mae']\n",
        "\n",
        "trainset = train_kds_uni_mean.ds\n",
        "testset = test_kds_uni_mean.ds\n",
        "EPOCH = 20\n",
        "patience = 4\n",
        "\n",
        "def lr_finder(epoch):\n",
        "    num1 = 4 - (epoch - 1) // 3\n",
        "    num2 = 1 + (epoch - 1) % 3 * 3\n",
        "    lr = round(0.1 ** num1 * num2, 7)\n",
        "    if lr < 0.01:\n",
        "        return lr\n",
        "    return 0.01\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_finder)\n",
        "tensorboard = prep.create_tensorboard_callback(model_name, avg_mode=True)\n",
        "\n",
        "##change model name 3\n",
        "model_NExp1Gp0.compile(optimizer=optimizer,\n",
        "                        loss=loss,\n",
        "                        metrics=metrics)\n",
        "\n",
        "##change model name 4 + 5\n",
        "history_NExp1Gp0 = model_NExp1Gp0.fit(trainset, epochs=EPOCH, validation_data=testset, callbacks=[lr_scheduler, tensorboard])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84PTmDdohVwO",
        "outputId": "767d581e-0d11-492b-9cd7-1d6cc6658050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/experiments/tensorboard/NExp1Gp0/20221206-210429-avg\n",
            "Epoch 1/20\n",
            "909/909 [==============================] - 35s 30ms/step - loss: 193.3844 - mae: 194.0775 - val_loss: 190.2764 - val_mae: 190.9695 - lr: 7.0000e-05\n",
            "Epoch 2/20\n",
            "909/909 [==============================] - 25s 27ms/step - loss: 188.1275 - mae: 188.8205 - val_loss: 186.4287 - val_mae: 187.1219 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "909/909 [==============================] - 25s 27ms/step - loss: 179.9754 - mae: 180.6683 - val_loss: 173.7352 - val_mae: 174.4283 - lr: 4.0000e-04\n",
            "Epoch 4/20\n",
            "909/909 [==============================] - 25s 27ms/step - loss: 162.9701 - mae: 163.6637 - val_loss: 152.3162 - val_mae: 153.0093 - lr: 7.0000e-04\n",
            "Epoch 5/20\n",
            "909/909 [==============================] - 25s 27ms/step - loss: 137.1953 - mae: 137.8885 - val_loss: 122.1051 - val_mae: 122.7983 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "909/909 [==============================] - 25s 27ms/step - loss: 80.9242 - mae: 81.6001 - val_loss: 50.2217 - val_mae: 50.9067 - lr: 0.0040\n",
            "Epoch 7/20\n",
            "909/909 [==============================] - 26s 28ms/step - loss: 31.5239 - mae: 32.1887 - val_loss: 27.8796 - val_mae: 28.5646 - lr: 0.0070\n",
            "Epoch 8/20\n",
            "909/909 [==============================] - 26s 28ms/step - loss: 29.1841 - mae: 29.8428 - val_loss: 27.8878 - val_mae: 28.5739 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "909/909 [==============================] - 27s 29ms/step - loss: 29.1867 - mae: 29.8452 - val_loss: 27.8981 - val_mae: 28.5842 - lr: 0.0100\n",
            "Epoch 10/20\n",
            "909/909 [==============================] - 26s 29ms/step - loss: 29.1898 - mae: 29.8479 - val_loss: 27.9160 - val_mae: 28.6015 - lr: 0.0100\n",
            "Epoch 11/20\n",
            "909/909 [==============================] - 25s 28ms/step - loss: 29.1925 - mae: 29.8507 - val_loss: 27.9299 - val_mae: 28.6146 - lr: 0.0100\n",
            "Epoch 12/20\n",
            "909/909 [==============================] - 27s 29ms/step - loss: 29.1944 - mae: 29.8529 - val_loss: 27.9366 - val_mae: 28.6215 - lr: 0.0100\n",
            "Epoch 13/20\n",
            "909/909 [==============================] - 25s 28ms/step - loss: 29.1954 - mae: 29.8543 - val_loss: 27.9394 - val_mae: 28.6245 - lr: 0.0100\n",
            "Epoch 14/20\n",
            "909/909 [==============================] - 25s 28ms/step - loss: 29.1959 - mae: 29.8549 - val_loss: 27.9406 - val_mae: 28.6257 - lr: 0.0100\n",
            "Epoch 15/20\n",
            "909/909 [==============================] - 26s 29ms/step - loss: 29.1961 - mae: 29.8552 - val_loss: 27.9410 - val_mae: 28.6261 - lr: 0.0100\n",
            "Epoch 16/20\n",
            "909/909 [==============================] - 25s 28ms/step - loss: 29.1962 - mae: 29.8553 - val_loss: 27.9412 - val_mae: 28.6263 - lr: 0.0100\n",
            "Epoch 17/20\n",
            "909/909 [==============================] - 26s 28ms/step - loss: 29.1963 - mae: 29.8553 - val_loss: 27.9413 - val_mae: 28.6264 - lr: 0.0100\n",
            "Epoch 18/20\n",
            "909/909 [==============================] - 25s 27ms/step - loss: 29.1963 - mae: 29.8554 - val_loss: 27.9413 - val_mae: 28.6264 - lr: 0.0100\n",
            "Epoch 19/20\n",
            "909/909 [==============================] - 25s 27ms/step - loss: 29.1963 - mae: 29.8554 - val_loss: 27.9413 - val_mae: 28.6264 - lr: 0.0100\n",
            "Epoch 20/20\n",
            "909/909 [==============================] - 25s 28ms/step - loss: 29.1963 - mae: 29.8554 - val_loss: 27.9413 - val_mae: 28.6264 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_vs_loss(history_NExp1Gp0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "_lh8aZkhnFeX",
        "outputId": "40d09924-0dcb-4658-cca5-4b0966ffb53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zQl74X1onHTW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}