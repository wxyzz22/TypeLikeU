{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7txYt9YKv0tO",
    "outputId": "dd1ab7cc-b5d4-4dd5-bd0c-40c8b75ecbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  3 16:08:47 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   27C    P0    49W / 400W |   1418MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIK53pSvWTvc"
   },
   "source": [
    "# Importing Libraries --> `train_data`, `test_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XB6h-h9xVfHa",
    "outputId": "5231e19e-ab86-41c1-ce8d-4c3091d9fa58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ObBsUgQWk6h"
   },
   "outputs": [],
   "source": [
    "def processing_folder(folder_path, train_size=0.8):\n",
    "    os.chdir(folder_path)\n",
    "    files = sorted(os.listdir(folder_path), key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "    samples = []\n",
    "    cols = []\n",
    "    for i, path in enumerate(files):\n",
    "        with open(path, encoding='utf-8',           ##https://stackoverflow.com/questions/12468179/unicodedecodeerror-utf8-codec-cant-decode-byte-0x9c\n",
    "                 errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "        ## extract column names (once)\n",
    "        if i == 1:\n",
    "            ls = lines[0].split('\\t')\n",
    "            if re.findall(r'\\w+|\\d+', ls[-1]):\n",
    "                ls[-1] = re.findall(r'\\w+|\\d+', ls[-1])[0]\n",
    "                cols = ls\n",
    "        ## extracting all samples from the current file\n",
    "        sample = []\n",
    "        curr_text_id = ''\n",
    "        curr_index = -1\n",
    "        for line in lines[1:]:\n",
    "            ls = line.split('\\t')\n",
    "            # if len(ls) != 9:\n",
    "            #     print(path, line)\n",
    "            if re.findall(r'\\w+|\\d+', ls[-1]):\n",
    "                ls[-1] = re.findall(r'\\w+|\\d+', ls[-1])[0]\n",
    "                if ls[1] != curr_text_id:\n",
    "                    curr_index = 0\n",
    "                    curr_text_id = ls[1]\n",
    "                else:\n",
    "                    curr_index += 1\n",
    "                ls.append(curr_index)\n",
    "                sample.append(ls)\n",
    "        ##  split the current data into train-test-sets\n",
    "        split_index = int(train_size * len(sample))\n",
    "        train_samples = train_samples + sample[:split_index]\n",
    "        test_samples = test_samples + sample[split_index:]\n",
    "        samples = samples + sample\n",
    "    ## forming dataframes\n",
    "    df_all = pd.DataFrame(samples)\n",
    "    df_train = pd.DataFrame(train_samples)\n",
    "    df_test = pd.DataFrame(test_samples)\n",
    "    ## renaming columns\n",
    "    cols = cols + ['INDEX']\n",
    "    df_all.columns, df_train.columns, df_test.columns = cols, cols, cols\n",
    "    return df_all, df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DPZk0OsWnFO"
   },
   "outputs": [],
   "source": [
    "## --> 7001\n",
    "folder_path = \"/content/drive/MyDrive/COMP576/keystroke-samples\"\n",
    "## baby sample\n",
    "folder_path = \"/content/drive/MyDrive/COMP576/raw-keystroke\"\n",
    "## mini sample\n",
    "folder_path = \"/content/drive/MyDrive/COMP576/train-dev-test\"\n",
    "data, train_data, test_data = processing_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKZVn2PY73gE"
   },
   "source": [
    "> Baby sample takes about 10 seconds\n",
    "> Large sample takes about 5 minutes (30X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "j3LAc-FU6PGb",
    "outputId": "969bb30c-1541-4449-b9e9-ddf0bc355ab9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ae228541-8c6c-48c4-b6a8-c68eb2a60e5b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARTICIPANT_ID</th>\n",
       "      <th>TEST_SECTION_ID</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>USER_INPUT</th>\n",
       "      <th>KEYSTROKE_ID</th>\n",
       "      <th>PRESS_TIME</th>\n",
       "      <th>RELEASE_TIME</th>\n",
       "      <th>LETTER</th>\n",
       "      <th>KEYCODE</th>\n",
       "      <th>INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>20212</td>\n",
       "      <td>I think that will help.</td>\n",
       "      <td>I think that will help</td>\n",
       "      <td>964481</td>\n",
       "      <td>1471960160759</td>\n",
       "      <td>1471960161309</td>\n",
       "      <td>SHIFT</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>20212</td>\n",
       "      <td>I think that will help.</td>\n",
       "      <td>I think that will help</td>\n",
       "      <td>964485</td>\n",
       "      <td>1471960161197</td>\n",
       "      <td>1471960161324</td>\n",
       "      <td>I</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>20212</td>\n",
       "      <td>I think that will help.</td>\n",
       "      <td>I think that will help</td>\n",
       "      <td>964490</td>\n",
       "      <td>1471960161356</td>\n",
       "      <td>1471960161479</td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae228541-8c6c-48c4-b6a8-c68eb2a60e5b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ae228541-8c6c-48c4-b6a8-c68eb2a60e5b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ae228541-8c6c-48c4-b6a8-c68eb2a60e5b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  PARTICIPANT_ID TEST_SECTION_ID                 SENTENCE  \\\n",
       "0           2004           20212  I think that will help.   \n",
       "1           2004           20212  I think that will help.   \n",
       "2           2004           20212  I think that will help.   \n",
       "\n",
       "               USER_INPUT KEYSTROKE_ID     PRESS_TIME   RELEASE_TIME LETTER  \\\n",
       "0  I think that will help       964481  1471960160759  1471960161309  SHIFT   \n",
       "1  I think that will help       964485  1471960161197  1471960161324      I   \n",
       "2  I think that will help       964490  1471960161356  1471960161479          \n",
       "\n",
       "  KEYCODE  INDEX  \n",
       "0      16      0  \n",
       "1      73      1  \n",
       "2      32      2  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUb_4DzxWo7V"
   },
   "outputs": [],
   "source": [
    "df = feature_extractor(data)\n",
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tmkdl01OWU1-",
    "outputId": "ca785884-7d61-4d97-9d63-e9f375e0be4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830783.5129967456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['IL'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xOAdKgZWsLrf",
    "outputId": "8d83524f-60af-4665-85e9-682bd3a404f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total 360 many users contained in the train dataset\n",
      "There are in total 360 many users contained in the test dataset\n",
      "There are in total 360 many users contained in the entire dataset\n",
      "There are in total 263807 many keystrokes contained in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are in total {len(train_data['PARTICIPANT_ID'].unique())} many users contained in the train dataset\")\n",
    "print(f\"There are in total {len(test_data['PARTICIPANT_ID'].unique())} many users contained in the test dataset\")\n",
    "print(f\"There are in total {len(data['PARTICIPANT_ID'].unique())} many users contained in the entire dataset\")\n",
    "print(f\"There are in total {len(data)} many keystrokes contained in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3Ztvf8Tt2Py"
   },
   "source": [
    "> Baby sample contains 360 users with 263807 keystrokes\n",
    "\n",
    "> Main sample contains 2329 users with 1701206 keystrokes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgV6MMiq69X_"
   },
   "source": [
    "# Feature Engineering (unit token: 2 keycodes) --> `train_df`, `test_df`, `data_df`\n",
    "\n",
    "> Expensive preprocessing step: for baby sample $\\approx 500$ users, takes 5-6 min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvNXbMOu7X5h"
   },
   "outputs": [],
   "source": [
    "def feature_extractor(data, keyboard=None, user_int=True, keycode_int=True):\n",
    "    df = data[['PARTICIPANT_ID', 'PRESS_TIME', 'RELEASE_TIME', 'KEYCODE', 'INDEX']]\n",
    "    df = df.astype('float64')\n",
    "    if user_int:\n",
    "        df['PARTICIPANT_ID'] = df['PARTICIPANT_ID'].astype('int64')\n",
    "    df = df.rename(columns={'PARTICIPANT_ID': 'USER'})\n",
    "\n",
    "    df['K1'] = df['KEYCODE']\n",
    "    if keycode_int:\n",
    "        df['K1'] = df['K1'].astype('int64')\n",
    "    df['K2'] = pd.concat([df['KEYCODE'][1:], pd.Series([0])], ignore_index=True)\n",
    "    if keycode_int:\n",
    "        df['K2'] = df['K2'].astype('int64')\n",
    "    df['I1'] = df['INDEX']\n",
    "    df['I2'] = pd.concat([df['INDEX'][1:], pd.Series([0])], ignore_index=True)\n",
    "    df['HL1'] = df['RELEASE_TIME'] - df['PRESS_TIME']\n",
    "    df['IL'] = pd.concat([df['PRESS_TIME'][1:], pd.Series([0])], ignore_index=True) - df['RELEASE_TIME']\n",
    "    df['HL2'] = pd.concat([df['HL1'][1:], pd.Series([0])], ignore_index=True)\n",
    "\n",
    "    if keyboard:\n",
    "        keycode_dist = []\n",
    "        home_dist = []\n",
    "        for row in df.index:\n",
    "            keycode_dist.append(keyboard['keycode'](keyboard['pos'], df['K1'][row], df['K2'][row]))\n",
    "            home_dist.append(keyboard['home'](keyboard['pos'], [df['K1'][row], df['K2'][row]]))\n",
    "        df['KD'] = keycode_dist\n",
    "        df['HD'] = home_dist\n",
    "\n",
    "    df = df.drop(columns=['PRESS_TIME', 'RELEASE_TIME', 'KEYCODE', 'INDEX'])\n",
    "    df = df.iloc[:-1, :]\n",
    "    return df\n",
    "\n",
    "def extract_avg_pair(df, drop_origin=True, rename_avg=True, round_avg=True):\n",
    "    df['K1_K2'] = df[['K1', 'K2']].apply(tuple, axis=1)\n",
    "    df['HL1_avg'] = df['HL1']\n",
    "    df['IL_avg'] = df['IL']\n",
    "    df['HL2_avg'] = df['HL2']\n",
    "    for pair in df['K1_K2'].unique():\n",
    "        avg_df = df[df['K1_K2'] == pair][['HL1', 'IL', 'HL2']].mean()\n",
    "        mask = df['K1_K2'] == pair\n",
    "        df.loc[mask, 'HL1_avg'] = avg_df['HL1']\n",
    "        df.loc[mask, 'IL_avg'] = avg_df['IL']\n",
    "        df.loc[mask, 'HL2_avg'] = avg_df['HL2']\n",
    "    if round_avg:\n",
    "        df['HL1_avg'] = round(df['HL1_avg'])\n",
    "        df['IL_avg'] = round(df['IL_avg'])\n",
    "        df['HL2_avg'] = round(df['HL2_avg'])\n",
    "    if drop_origin:\n",
    "        df = df.drop(columns=['HL1', 'IL', 'HL2', 'K1_K2'])\n",
    "    if drop_origin and rename_avg:\n",
    "        df = df.rename(columns={'HL1_avg':'HL1', 'IL_avg':'IL', 'HL2_avg':'HL2'})\n",
    "    return df\n",
    "\n",
    "def general_preprocess_pair(data, return_avg=False):\n",
    "    df = feature_extractor(data)\n",
    "    if return_avg:\n",
    "        df = extract_avg_pair(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3_DVuulglPH"
   },
   "outputs": [],
   "source": [
    "train_df = general_preprocess_pair(train_data)\n",
    "test_df = general_preprocess_pair(test_data)\n",
    "# data_df = general_preprocess_pair(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk7DS4ZNfra3"
   },
   "source": [
    "# Structure ONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cJASdotxFBk"
   },
   "source": [
    "## Srtucture ONE: Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnYweJq8l386"
   },
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "n_steps = 30\n",
    "window_length = n_steps\n",
    "shift = 1\n",
    "batch_size = 128\n",
    "unique_keycode = 82\n",
    "\n",
    "onehot_encoder = OneHotEncoder().fit(pd.concat([train_df[['K1', 'K2']], test_df[['K1', 'K2']]]).astype(str))\n",
    "# onehot_encoder.transform(train_df[['K1', 'K2']].astype(str)).toarray().shape\n",
    "\n",
    "unit_time_depth = unique_keycode * 2 + 4    ## 4 is for ['I1', 'I2', 'HL1_avg', 'HL2_avg']\n",
    "\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nReGX8IOr6ru",
    "outputId": "3bd5a4e9-0dbd-4cba-ff82-67b32dfc641e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210898, 164)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.transform(train_df[['K1', 'K2']].astype(str)).toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vImKVyohAqF"
   },
   "source": [
    "## Structure ONE: Preparation --> `train_ds`, `test_ds`\n",
    "\n",
    "> shape: \n",
    "* Input: (`batch_size`, `window_length`, `num_features`), e.g. (128, 30, 168)\n",
    "* Output: (`batch_size`, `window_length`), e.g. (128, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IE69tJ-jftbx"
   },
   "outputs": [],
   "source": [
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#\n",
    "def structure_one(preprocessed_data, encoder):\n",
    "    df = preprocessed_data[['K1', 'K2', 'I1', 'I2', 'HL1_avg', 'IL_avg', 'HL2_avg']]\n",
    "    df = np.concatenate([encoder.transform(df[['K1', 'K2']].astype(str)).toarray(), df[['I1', 'I2', 'HL1_avg', 'IL_avg', 'HL2_avg']]], axis=1)\n",
    "    # df = pd.concat([pd.get_dummies(df[['K1', 'K2']].astype(str)), df[['I1', 'I2', 'HL1_avg', 'IL_avg', 'HL2_avg']]], axis=1)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(df).window(size=window_length, shift=shift, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length)).batch(batch_size)\n",
    "    dataset = dataset.map(lambda windows: (windows[:, :, :-1], windows[:, :, -1]))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bg_8bagQjXU-"
   },
   "outputs": [],
   "source": [
    "train_ds = structure_one(train_df, onehot_encoder)\n",
    "test_ds = structure_one(test_df, onehot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SNXMHhdlJ4d",
    "outputId": "e21eb37c-82bb-4b1b-f968-ca06ce039b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 30, 168) (128, 30)\n"
     ]
    }
   ],
   "source": [
    "for a, b in train_ds.take(1):\n",
    "    print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_yS7eV1loD5"
   },
   "source": [
    "## Structure ONE: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00ypnFKflq6R",
    "outputId": "cc40d744-54fc-477d-e0ee-a7a7db93998f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, None, 128)         114432    \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, None, 128)         99072     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 1)          129       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,633\n",
      "Trainable params: 213,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ONE_base = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, unit_time_depth], dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "])\n",
    "model_ONE_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhY5kI_hTyfn"
   },
   "source": [
    "> overfitting: test error significantly higher than train error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy4B8HJhMCVL",
    "outputId": "23ec2b7d-7d88-46c1-b64a-55f120386622"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, None, 128)         114432    \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, None, 128)         99072     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, None, 1)          129       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,633\n",
      "Trainable params: 213,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ONE_1 = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, unit_time_depth], dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1, activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "])\n",
    "model_ONE_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlzexKcVT59P"
   },
   "source": [
    "> Fixed overfitting, but training is too slow (need to (1)trim down regularization (`model2`) or (2)add more layer (`model3`))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xl7Rw4drUHrG",
    "outputId": "3e99ca03-fa7c-45b3-e148-bf92eeaa60f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, None, 128)         114432    \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, None, 128)         99072     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, None, 1)          129       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,633\n",
      "Trainable params: 213,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ONE_2 = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, unit_time_depth], dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1, activity_regularizer=tf.keras.regularizers.L2(0.001)))\n",
    "])\n",
    "model_ONE_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QexADf7GdCjY",
    "outputId": "b78d3991-e5da-406f-8ede-a1c1613ee8b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_8 (GRU)                 (None, None, 128)         114432    \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, None, 128)         99072     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, None, 32)         4128      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, None, 1)          33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 217,665\n",
      "Trainable params: 217,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ONE_3 = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, unit_time_depth], dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(32, activity_regularizer=tf.keras.regularizers.L2(0.001))),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "])\n",
    "model_ONE_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAHlabfv562r",
    "outputId": "87fed554-f560-4cad-9b16-299c4a07f93d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_10 (GRU)                (None, None, 128)         114432    \n",
      "                                                                 \n",
      " gru_11 (GRU)                (None, None, 128)         99072     \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, None, 64)         8256      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, None, 32)         2080      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, None, 1)          33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 223,873\n",
      "Trainable params: 223,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ONE_4 = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, unit_time_depth], dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(64, activity_regularizer=tf.keras.regularizers.L2(0.01))),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(32, activity_regularizer=tf.keras.regularizers.L2(0.01))),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "])\n",
    "model_ONE_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_YQFyU-UQ5P"
   },
   "source": [
    "### Callbakcs, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KRYeEzkmmcb"
   },
   "outputs": [],
   "source": [
    "def structure_one_metric(loss='poisson'):\n",
    "    if loss == 'mse':\n",
    "        def mse_metric(Y_true, Y_pred):\n",
    "            return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "        return mse_metric\n",
    "    elif loss == 'mae':\n",
    "        def mae_metric(Y_true, Y_pred):\n",
    "            return keras.metrics.mean_absolute_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "        return mae_metric\n",
    "    else:\n",
    "        def poisson_metric(Y_true, Y_pred):\n",
    "            return tf.keras.metrics.poisson(Y_true[:, -1], Y_pred[:, -1])\n",
    "        return poisson_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBwXefNRw5mI"
   },
   "outputs": [],
   "source": [
    "## functionalize callbacks\n",
    "\n",
    "def create_checkpoint_callback(experiment_name, \n",
    "                               save_weights_only=True, \n",
    "                               monitor='val_loss', \n",
    "                               mode='min', \n",
    "                               save_best_only=True):\n",
    "    path = '/content/drive/MyDrive/COMP576/training-logs'\n",
    "    checkpoint_filepath = path + \"/\" + \"checkpoints\" + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                             save_weights_only=save_weights_only,\n",
    "                                                             monitor=monitor,\n",
    "                                                             mode=mode,\n",
    "                                                             save_best_only=save_best_only)\n",
    "    print(f\"Saving Model Checkpoint files to :{checkpoint_filepath}\")\n",
    "    return checkpoint_callback\n",
    "\n",
    "def create_tensorboard_callback(experiment_name):\n",
    "    path = '/content/drive/MyDrive/COMP576/training-logs'\n",
    "    log_dir = path + \"/\" + \"tensorboard\" + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    print(f\"Saving TensorBoard log files to :{log_dir}\")\n",
    "    return tensorboard_callback\n",
    "\n",
    "def create_earlystopping_callback(monitor='val_loss',\n",
    "                                  patience=5):\n",
    "    return tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=patience)\n",
    "\n",
    "def get_callbacks(experiment_name):\n",
    "    earlystopping = create_earlystopping_callback()\n",
    "    modelcheckpoint = create_checkpoint_callback(experiment_name=experiment_name)\n",
    "    tensorboard = create_tensorboard_callback(experiment_name=experiment_name)\n",
    "    return [earlystopping, modelcheckpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRuEfyPw89oi"
   },
   "source": [
    "### LOSS + Metric: `mse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGuiwXCYm11V",
    "outputId": "fb5e57d7-f9cd-4f11-9792-a37f230b2172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Checkpoint files to :/content/drive/MyDrive/COMP576/training-logs/checkpoints/ONE_base/20221203-033649\n",
      "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/training-logs/tensorboard/ONE_base/20221203-033649\n",
      "Epoch 1/10\n",
      "1648/1648 [==============================] - 313s 187ms/step - loss: 3020.6680 - mse_metric: 3028.2458 - val_loss: 21595.8652 - val_mse_metric: 21592.2246\n",
      "Epoch 2/10\n",
      "1648/1648 [==============================] - 306s 185ms/step - loss: 2860.1240 - mse_metric: 2860.3904 - val_loss: 21575.7578 - val_mse_metric: 21626.3984\n",
      "Epoch 3/10\n",
      "1648/1648 [==============================] - 303s 184ms/step - loss: 2850.1633 - mse_metric: 2852.1621 - val_loss: 21579.6934 - val_mse_metric: 21560.1445\n",
      "Epoch 4/10\n",
      "1648/1648 [==============================] - 304s 185ms/step - loss: 2812.7163 - mse_metric: 2816.5339 - val_loss: 21819.8164 - val_mse_metric: 21813.6504\n",
      "Epoch 5/10\n",
      "1648/1648 [==============================] - 304s 185ms/step - loss: 2785.7065 - mse_metric: 2805.1736 - val_loss: 21865.0117 - val_mse_metric: 21888.5020\n",
      "Epoch 6/10\n",
      "1648/1648 [==============================] - 303s 184ms/step - loss: 2784.0947 - mse_metric: 2802.6758 - val_loss: 21871.1094 - val_mse_metric: 21890.3867\n",
      "Epoch 7/10\n",
      "1648/1648 [==============================] - 304s 184ms/step - loss: 2767.3420 - mse_metric: 2769.1709 - val_loss: 21487.7324 - val_mse_metric: 21466.5645\n",
      "Epoch 8/10\n",
      "1648/1648 [==============================] - 304s 184ms/step - loss: 2735.1599 - mse_metric: 2736.3677 - val_loss: 21296.7539 - val_mse_metric: 21287.0000\n",
      "Epoch 9/10\n",
      "1648/1648 [==============================] - 304s 184ms/step - loss: 2714.0581 - mse_metric: 2714.1648 - val_loss: 21298.3770 - val_mse_metric: 21248.7246\n",
      "Epoch 10/10\n",
      "1648/1648 [==============================] - 303s 184ms/step - loss: 2709.4800 - mse_metric: 2719.3203 - val_loss: 21269.3633 - val_mse_metric: 21273.0391\n"
     ]
    }
   ],
   "source": [
    "model_ONE_base.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[structure_one_metric('mse')])\n",
    "\n",
    "history = model_ONE_base.fit(train_ds, epochs=10, \n",
    "                              validation_data=test_ds,\n",
    "                              callbacks=get_callbacks('ONE_base'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cUCfq2C9uKc",
    "outputId": "e0533122-7198-4d7f-e7c8-852c9cd5f5a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - 10s 25ms/step - loss: 21468.7656 - mse_metric: 21424.3867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[21468.765625, 21424.38671875]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ONE_base.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNxsS6u090IN"
   },
   "outputs": [],
   "source": [
    "for a, b in test_ds.take(1):\n",
    "    X, y_true = a, b\n",
    "model_ONE_base.predict(X), y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeEyPKhR9okX",
    "outputId": "036d57a5-d6cb-41ac-bcab-7ae4d9cb6eae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - 10s 25ms/step - loss: 21468.7656 - mse_metric: 21424.3867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[21468.765625, 21424.38671875]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ONE_base.load_weights('/content/drive/MyDrive/COMP576/training-logs/checkpoint')\n",
    "model_ONE_base.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouoxk2YyEUyD"
   },
   "source": [
    "### LOSS + Metric: `mae`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZhlvVsIEYww",
    "outputId": "1a6a5ea6-6d44-48a6-abcb-77a3c1ea701d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Checkpoint files to :/content/drive/MyDrive/COMP576/training-logs/checkpoints/ONE_base_mae/20221203-042738\n",
      "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/training-logs/tensorboard/ONE_base_mae/20221203-042738\n",
      "Epoch 1/10\n",
      "1648/1648 [==============================] - 308s 185ms/step - loss: 6.9690 - mae_metric: 6.9882 - val_loss: 17.3063 - val_mae_metric: 17.4347\n",
      "Epoch 2/10\n",
      "1648/1648 [==============================] - 305s 185ms/step - loss: 6.4037 - mae_metric: 6.3865 - val_loss: 16.7239 - val_mae_metric: 16.8905\n",
      "Epoch 3/10\n",
      "1648/1648 [==============================] - 305s 185ms/step - loss: 6.0681 - mae_metric: 6.0638 - val_loss: 17.4892 - val_mae_metric: 17.8451\n",
      "Epoch 4/10\n",
      "1648/1648 [==============================] - 303s 184ms/step - loss: 5.8141 - mae_metric: 5.7738 - val_loss: 15.9823 - val_mae_metric: 16.3704\n",
      "Epoch 5/10\n",
      "1648/1648 [==============================] - 304s 185ms/step - loss: 5.6250 - mae_metric: 5.5825 - val_loss: 17.0338 - val_mae_metric: 17.4546\n",
      "Epoch 6/10\n",
      "1648/1648 [==============================] - 305s 185ms/step - loss: 5.5475 - mae_metric: 5.4924 - val_loss: 16.1410 - val_mae_metric: 16.3482\n",
      "Epoch 7/10\n",
      "1648/1648 [==============================] - 305s 185ms/step - loss: 5.4376 - mae_metric: 5.4295 - val_loss: 16.5576 - val_mae_metric: 16.7328\n",
      "Epoch 8/10\n",
      "1648/1648 [==============================] - 303s 184ms/step - loss: 5.2283 - mae_metric: 5.1904 - val_loss: 15.4528 - val_mae_metric: 15.8100\n",
      "Epoch 9/10\n",
      "1648/1648 [==============================] - 306s 186ms/step - loss: 5.1392 - mae_metric: 5.1169 - val_loss: 13.9683 - val_mae_metric: 14.2007\n",
      "Epoch 10/10\n",
      " 223/1648 [===>..........................] - ETA: 4:18 - loss: 5.1092 - mae_metric: 5.1259"
     ]
    }
   ],
   "source": [
    "model_ONE_base.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=[structure_one_metric('mae')])\n",
    "\n",
    "history = model_ONE_base.fit(train_ds, epochs=10, \n",
    "                    validation_data=test_ds,\n",
    "                    callbacks=get_callbacks('ONE_base_mae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6RrSVeoMMp0",
    "outputId": "8be3487f-ce2c-4e3e-9476-fe678d96da29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Checkpoint files to :/content/drive/MyDrive/COMP576/training-logs/checkpoints/ONE_1_mae/20221203-051829\n",
      "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/training-logs/tensorboard/ONE_1_mae/20221203-051829\n",
      "Epoch 1/10\n",
      "1648/1648 [==============================] - 306s 183ms/step - loss: 91.8535 - mae_metric: 70.3434 - val_loss: 92.8052 - val_mae_metric: 67.7627\n",
      "Epoch 2/10\n",
      "1648/1648 [==============================] - 303s 184ms/step - loss: 90.8067 - mae_metric: 65.8111 - val_loss: 92.8051 - val_mae_metric: 67.7597\n",
      "Epoch 3/10\n",
      "1648/1648 [==============================] - 307s 186ms/step - loss: 90.8054 - mae_metric: 65.8172 - val_loss: 92.8051 - val_mae_metric: 67.7657\n",
      "Epoch 4/10\n",
      "1648/1648 [==============================] - 306s 186ms/step - loss: 90.8047 - mae_metric: 65.8213 - val_loss: 92.8050 - val_mae_metric: 67.7686\n",
      "Epoch 5/10\n",
      "1648/1648 [==============================] - 304s 184ms/step - loss: 90.8045 - mae_metric: 65.8222 - val_loss: 92.8050 - val_mae_metric: 67.7683\n",
      "Epoch 6/10\n",
      "1648/1648 [==============================] - 307s 186ms/step - loss: 90.8047 - mae_metric: 65.8212 - val_loss: 92.8050 - val_mae_metric: 67.7744\n",
      "Epoch 7/10\n",
      "1648/1648 [==============================] - 305s 185ms/step - loss: 90.8043 - mae_metric: 65.8235 - val_loss: 92.8050 - val_mae_metric: 67.7734\n",
      "Epoch 8/10\n",
      "1648/1648 [==============================] - 306s 185ms/step - loss: 90.8042 - mae_metric: 65.8234 - val_loss: 92.8050 - val_mae_metric: 67.7723\n",
      "Epoch 9/10\n",
      "1648/1648 [==============================] - 306s 185ms/step - loss: 90.8042 - mae_metric: 65.8244 - val_loss: 92.8050 - val_mae_metric: 67.7720\n",
      "Epoch 10/10\n",
      "1648/1648 [==============================] - 306s 186ms/step - loss: 90.8041 - mae_metric: 65.8247 - val_loss: 92.8050 - val_mae_metric: 67.7723\n"
     ]
    }
   ],
   "source": [
    "model_ONE_1.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=[structure_one_metric('mae')])\n",
    "\n",
    "history1 = model_ONE_1.fit(train_ds, epochs=10, \n",
    "                      validation_data=test_ds,\n",
    "                      callbacks=get_callbacks('ONE_1_mae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ft-uYI6ZOO25",
    "outputId": "e197d3f0-8428-421a-8960-20940027eddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Checkpoint files to :/content/drive/MyDrive/COMP576/training-logs/checkpoints/ONE_2_mae/20221203-060925\n",
      "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/training-logs/tensorboard/ONE_2_mae/20221203-060925\n",
      "Epoch 1/3\n",
      "1648/1648 [==============================] - 310s 185ms/step - loss: 41.8071 - mae_metric: 33.6599 - val_loss: 29.6624 - val_mae_metric: 18.5546\n",
      "Epoch 2/3\n",
      "1648/1648 [==============================] - 307s 186ms/step - loss: 25.3369 - mae_metric: 14.2207 - val_loss: 26.7973 - val_mae_metric: 15.9804\n",
      "Epoch 3/3\n",
      "1443/1648 [=========================>....] - ETA: 37s - loss: 23.2550 - mae_metric: 11.9190"
     ]
    }
   ],
   "source": [
    "model_ONE_2.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=[structure_one_metric('mae')])\n",
    "\n",
    "history2 = model_ONE_2.fit(train_ds, epochs=10, \n",
    "                      validation_data=test_ds,\n",
    "                      callbacks=get_callbacks('ONE_2_mae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUHcPkTzdl6H",
    "outputId": "3cac401f-c850-4b8f-e4c0-d18dd3e0d86b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Checkpoint files to :/content/drive/MyDrive/COMP576/training-logs/checkpoints/ONE_3_mae/20221203-062451\n",
      "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/training-logs/tensorboard/ONE_3_mae/20221203-062451\n",
      "Epoch 1/3\n",
      "1648/1648 [==============================] - 314s 188ms/step - loss: 19.6242 - mae_metric: 17.6082 - val_loss: 17.2411 - val_mae_metric: 16.0063\n",
      "Epoch 2/3\n",
      "1648/1648 [==============================] - 309s 188ms/step - loss: 13.4379 - mae_metric: 12.4733 - val_loss: 16.7149 - val_mae_metric: 16.0885\n",
      "Epoch 3/3\n",
      " 130/1648 [=>............................] - ETA: 4:37 - loss: 12.7055 - mae_metric: 11.9840"
     ]
    }
   ],
   "source": [
    "model_ONE_3.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=[structure_one_metric('mae')])\n",
    "\n",
    "history3 = model_ONE_3.fit(train_ds, epochs=10, \n",
    "                      validation_data=test_ds,\n",
    "                      callbacks=get_callbacks('ONE_3_mae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHQecuKx6D16",
    "outputId": "53afa638-5dab-4c98-facf-5fe869a10f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Checkpoint files to :/content/drive/MyDrive/COMP576/training-logs/checkpoints/ONE_4_mae/20221203-064022\n",
      "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/training-logs/tensorboard/ONE_4_mae/20221203-064022\n",
      "Epoch 1/10\n",
      "1648/1648 [==============================] - 315s 188ms/step - loss: 27.7627 - mae_metric: 14.4663 - val_loss: 24.1738 - val_mae_metric: 18.0135\n",
      "Epoch 2/10\n",
      "1648/1648 [==============================] - 308s 187ms/step - loss: 12.7218 - mae_metric: 7.7491 - val_loss: 21.8458 - val_mae_metric: 18.1661\n",
      "Epoch 3/10\n",
      "1648/1648 [==============================] - 306s 185ms/step - loss: 9.9453 - mae_metric: 6.5708 - val_loss: 20.1338 - val_mae_metric: 17.4279\n",
      "Epoch 4/10\n",
      "1648/1648 [==============================] - 308s 187ms/step - loss: 9.1892 - mae_metric: 6.6243 - val_loss: 21.3654 - val_mae_metric: 19.2029\n",
      "Epoch 5/10\n",
      "1648/1648 [==============================] - 310s 188ms/step - loss: 8.3084 - mae_metric: 6.1611 - val_loss: 19.8902 - val_mae_metric: 18.0050\n",
      "Epoch 6/10\n",
      "1648/1648 [==============================] - 310s 188ms/step - loss: 7.7927 - mae_metric: 5.9766 - val_loss: 19.9483 - val_mae_metric: 18.4597\n",
      "Epoch 7/10\n",
      "1648/1648 [==============================] - 308s 187ms/step - loss: 7.3081 - mae_metric: 5.6908 - val_loss: 18.4601 - val_mae_metric: 17.1243\n",
      "Epoch 8/10\n",
      "1648/1648 [==============================] - 308s 187ms/step - loss: 6.8434 - mae_metric: 5.3860 - val_loss: 18.8185 - val_mae_metric: 17.6451\n",
      "Epoch 9/10\n",
      "1648/1648 [==============================] - 307s 186ms/step - loss: 6.4889 - mae_metric: 5.1134 - val_loss: 17.8585 - val_mae_metric: 16.6835\n",
      "Epoch 10/10\n",
      " 400/1648 [======>.......................] - ETA: 3:43 - loss: 6.5166 - mae_metric: 5.2089"
     ]
    }
   ],
   "source": [
    "model_ONE_4.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=[structure_one_metric('mae')])\n",
    "\n",
    "history4 = model_ONE_4.fit(train_ds, epochs=10, \n",
    "                      validation_data=test_ds,\n",
    "                      callbacks=get_callbacks('ONE_4_mae'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNcF3YWK9B2i"
   },
   "source": [
    "### LOSS + Metric: Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1jnVTRC-gTY",
    "outputId": "170770b0-f733-4338-e542-733690ccad38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model Checkpoint files to :/content/drive/MyDrive/COMP576/training-logs/checkpoints/ONE_base_huber/20221203-073147\n",
      "Saving TensorBoard log files to :/content/drive/MyDrive/COMP576/training-logs/tensorboard/ONE_base_huber/20221203-073147\n",
      "Epoch 1/10\n",
      "1648/1648 [==============================] - 310s 185ms/step - loss: 31.6177 - mae: 5.1399 - val_loss: 114.5496 - val_mae: 14.3999\n",
      "Epoch 2/10\n",
      "1648/1648 [==============================] - 307s 186ms/step - loss: 32.5228 - mae: 5.2837 - val_loss: 121.1243 - val_mae: 15.0422\n",
      "Epoch 3/10\n",
      "1648/1648 [==============================] - 306s 186ms/step - loss: 32.3419 - mae: 5.2713 - val_loss: 129.3637 - val_mae: 15.9388\n",
      "Epoch 4/10\n",
      "1648/1648 [==============================] - 305s 185ms/step - loss: 31.3946 - mae: 5.1648 - val_loss: 116.8425 - val_mae: 14.6393\n",
      "Epoch 5/10\n",
      "1648/1648 [==============================] - 307s 186ms/step - loss: 30.9280 - mae: 5.0822 - val_loss: 117.2078 - val_mae: 14.7197\n",
      "Epoch 6/10\n",
      "1648/1648 [==============================] - 307s 186ms/step - loss: 29.6066 - mae: 4.9389 - val_loss: 134.4884 - val_mae: 16.4873\n"
     ]
    }
   ],
   "source": [
    "model_ONE_base.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.Huber(delta=10),\n",
    "              metrics='mae')\n",
    "\n",
    "history = model_ONE_base.fit(train_ds, epochs=10, \n",
    "                    validation_data=test_ds,\n",
    "                    callbacks=get_callbacks('ONE_base_huber'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azh6zbKK8KY7"
   },
   "source": [
    "# Feature Engineering (unit token: 1 keycode) --> `train_df`, `test_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cUiC0Jp_FMW"
   },
   "outputs": [],
   "source": [
    "def feature_extractor(data, keyboard=None, user_int=True, keycode_int=True, drop_user=True):\n",
    "    df = data[['PARTICIPANT_ID', 'PRESS_TIME', 'RELEASE_TIME', 'KEYCODE', 'INDEX']]\n",
    "    df = df.astype('float64')\n",
    "    if user_int:\n",
    "        df['PARTICIPANT_ID'] = df['PARTICIPANT_ID'].astype('int64')\n",
    "    df = df.rename(columns={'PARTICIPANT_ID': 'USER'})\n",
    "    if drop_user:\n",
    "        df = df.drop(columns=['USER'])\n",
    "\n",
    "    if keycode_int:\n",
    "        df['KEYCODE'] = df['KEYCODE'].astype('int64')\n",
    "    df['HL'] = df['RELEASE_TIME'] - df['PRESS_TIME']\n",
    "    df['IL'] = pd.concat([df['PRESS_TIME'][1:], pd.Series([0])], ignore_index=True) - df['RELEASE_TIME']\n",
    "    df['PL'] = pd.concat([df['PRESS_TIME'][1:], pd.Series([0])], ignore_index=True) - df['PRESS_TIME']\n",
    "    df['RL'] = pd.concat([df['RELEASE_TIME'][1:], pd.Series([0])], ignore_index=True) - df['RELEASE_TIME']\n",
    "\n",
    "    if keyboard:\n",
    "        keycode_dist = []\n",
    "        home_dist = []\n",
    "        for row in df.index:\n",
    "            keycode_dist.append(keyboard['keycode'](keyboard['pos'], df['K1'][row], df['K2'][row]))\n",
    "            home_dist.append(keyboard['home'](keyboard['pos'], [df['K1'][row], df['K2'][row]]))\n",
    "        df['KD'] = keycode_dist\n",
    "        df['HD'] = home_dist\n",
    "\n",
    "    df = df.drop(columns=['PRESS_TIME', 'RELEASE_TIME'])\n",
    "    df = df.iloc[:-1, :]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6HlfjXKnlCl"
   },
   "outputs": [],
   "source": [
    "train_df = feature_extractor(train_data)\n",
    "test_df = feature_extractor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "wRMllYT5pRiR",
    "outputId": "efd7dbb6-e91b-4a6d-d743-60f3a81a1ecb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9b558f76-bdd6-4f81-8504-59bcf09eb82d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEYCODE</th>\n",
       "      <th>INDEX</th>\n",
       "      <th>HL</th>\n",
       "      <th>IL</th>\n",
       "      <th>PL</th>\n",
       "      <th>RL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b558f76-bdd6-4f81-8504-59bcf09eb82d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9b558f76-bdd6-4f81-8504-59bcf09eb82d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9b558f76-bdd6-4f81-8504-59bcf09eb82d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   KEYCODE  INDEX     HL     IL     PL     RL\n",
       "0       16    0.0  550.0 -112.0  438.0   15.0\n",
       "1       73    1.0  127.0   32.0  159.0  155.0\n",
       "2       32    2.0  123.0    0.0  123.0  196.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfXA9whKntrO"
   },
   "source": [
    "# Structure TypeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdV1AmlQo2p7"
   },
   "source": [
    "## Structure TypeNet: Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xc_zctKCo7Va"
   },
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "n_steps = 30\n",
    "window_length = n_steps + 1\n",
    "shift = 1\n",
    "batch_size = 128\n",
    "unique_keycode = 82\n",
    "\n",
    "onehot_encoder = OneHotEncoder().fit(train_df[['KEYCODE']].astype(str))\n",
    "\n",
    "unit_time_depth = unique_keycode + 5    ## 5 is for ['INDEX', 'HL', 'IL', 'PL', 'RL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9lQejHloimA"
   },
   "source": [
    "## Structure TypeNet: Preparation --> `train_ds`, `test_ds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqG-IKpBozYI"
   },
   "outputs": [],
   "source": [
    "def structure_typenet(df, encoder, zip_in_out=True):\n",
    "    df = np.concatenate([encoder.transform(df[['KEYCODE']].astype(str)).toarray(), df[['INDEX', 'HL', 'IL', 'PL', 'RL']]], axis=1)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(df).window(size=window_length, shift=shift, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length)).batch(batch_size)\n",
    "    ds_in = dataset.map(lambda window: (window[:, :n_steps, :], window[:, -1, :-4]))\n",
    "    ds_out = dataset.map(lambda window: window[:, -1, -4:-2])\n",
    "\n",
    "    if zip_in_out:\n",
    "        dataset = tf.data.Dataset.zip((ds_in, ds_out))\n",
    "        return dataset\n",
    "    return ds_in, ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILbRb6A1rsEf"
   },
   "outputs": [],
   "source": [
    "train_ds = structure_typenet(train_df, onehot_encoder)\n",
    "test_ds = structure_typenet(test_df, onehot_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTvrvNJCtA4N"
   },
   "source": [
    "## Structure TypeNet: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfBoupZ1tpay",
    "outputId": "1760013a-96c7-4b06-df65-3277a46bc2ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " 0-N char with timestamps (Inpu  [(None, None, 87)]  0           []                               \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, None, 87)    348         ['0-N char with timestamps[0][0]'\n",
      " rmalization)                                                    ]                                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, None, 128)    110592      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, None, 128)    0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, None, 128)   512         ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 128)          131584      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " N+1 char without timestamps (I  [(None, 83)]        0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 211)          0           ['lstm_3[0][0]',                 \n",
      "                                                                  'N+1 char without timestamps[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 211, 1)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " gru_25 (GRU)                   (None, 64)           12864       ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 2)            130         ['gru_25[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,030\n",
      "Trainable params: 255,600\n",
      "Non-trainable params: 430\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1 = keras.layers.Input(shape=[None, unit_time_depth], name='0-N char with timestamps')\n",
    "input_2 = keras.layers.Input(shape=[unit_time_depth-4], name='N+1 char without timestamps')\n",
    "batch_1 = keras.layers.BatchNormalization()(input_1)\n",
    "lstm_1 = keras.layers.LSTM(128, return_sequences=True, recurrent_dropout=0.2)(batch_1)\n",
    "dropout_1 = keras.layers.Dropout(0.5)(lstm_1)\n",
    "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
    "lstm_2 = keras.layers.LSTM(128, recurrent_dropout=0.2)(batch_2)\n",
    "concat = keras.layers.concatenate([lstm_2, input_2])\n",
    "reshape = keras.layers.Reshape((128+unit_time_depth-4, 1))(concat)\n",
    "gru_1 = keras.layers.GRU(64, recurrent_dropout=0.2)(reshape)\n",
    "output = keras.layers.Dense(2)(gru_1)\n",
    "model = keras.Model(inputs=[input_1, input_2], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9W-1bdx5uGVe",
    "outputId": "0c68ac76-63fa-43a2-8d6b-0977cb9b1827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1648/1648 [==============================] - 1459s 882ms/step - loss: 1611.8051 - mae_metric: 3184.1465 - val_loss: 5859.9131 - val_mae_metric: 11655.5625\n",
      "Epoch 2/3\n",
      "1648/1648 [==============================] - 1385s 840ms/step - loss: 1611.0323 - mae_metric: 3183.7246 - val_loss: 5859.8379 - val_mae_metric: 11655.4326\n",
      "Epoch 3/3\n",
      "1648/1648 [==============================] - 1375s 834ms/step - loss: 1611.0187 - mae_metric: 3183.6997 - val_loss: 5859.8291 - val_mae_metric: 11655.4316\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(train_ds, epochs=3, \n",
    "                    validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eoEsuewyVXn"
   },
   "source": [
    "> `model1`: update from `model` by\n",
    "  1. changing the GRU layer to 2 dense layer\n",
    "  2. change the customize metric to `mae` (since we are not doing the sequence-to-sequence prediction here any more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rgy0yyTKx9c3",
    "outputId": "4c3963cd-a2b1-4b1d-8f99-c153e083a83c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " 0-N char with timestamps (Inpu  [(None, None, 87)]  0           []                               \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, None, 87)    348         ['0-N char with timestamps[0][0]'\n",
      " rmalization)                                                    ]                                \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, None, 128)    110592      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, None, 128)    0           ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, None, 128)   512         ['dropout_3[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, 128)          131584      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " N+1 char without timestamps (I  [(None, 83)]        0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 211)          0           ['lstm_7[0][0]',                 \n",
      "                                                                  'N+1 char without timestamps[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 100)          21200       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 30)           3030        ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 2)            62          ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 267,328\n",
      "Trainable params: 266,898\n",
      "Non-trainable params: 430\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1 = keras.layers.Input(shape=[None, unit_time_depth], name='0-N char with timestamps')\n",
    "input_2 = keras.layers.Input(shape=[unit_time_depth-4], name='N+1 char without timestamps')\n",
    "batch_1 = keras.layers.BatchNormalization()(input_1)\n",
    "lstm_1 = keras.layers.LSTM(128, return_sequences=True, recurrent_dropout=0.2)(batch_1)\n",
    "dropout_1 = keras.layers.Dropout(0.5)(lstm_1)\n",
    "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
    "lstm_2 = keras.layers.LSTM(128, recurrent_dropout=0.2)(batch_2)\n",
    "concat = keras.layers.concatenate([lstm_2, input_2])\n",
    "dense_1 = keras.layers.Dense(100)(concat)\n",
    "dense_2 = keras.layers.Dense(30)(dense_1)\n",
    "output = keras.layers.Dense(2)(dense_2)\n",
    "model1 = keras.Model(inputs=[input_1, input_2], outputs=[output])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KjQq10UySmP",
    "outputId": "8ddd6d47-cfc7-4f4a-fed8-4ad6d37a3f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1648/1648 [==============================] - 414s 249ms/step - loss: 1611.4108 - mae: 1611.4108 - val_loss: 5857.7964 - val_mae: 5857.7964\n",
      "Epoch 2/3\n",
      "1648/1648 [==============================] - 420s 255ms/step - loss: 1606.4955 - mae: 1606.4955 - val_loss: 5857.0015 - val_mae: 5857.0015\n",
      "Epoch 3/3\n",
      "1648/1648 [==============================] - 410s 249ms/step - loss: 1602.3168 - mae: 1602.3168 - val_loss: 5855.7227 - val_mae: 5855.7227\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "history1 = model1.fit(train_ds, epochs=3, \n",
    "                      validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PWaMq3Q78GQ"
   },
   "source": [
    "> Update from `model1` by\n",
    "  1. change loss to Poisson (`model2`)\n",
    "  2. add regularization to Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trObImzs8rcv",
    "outputId": "e656984e-a768-459f-d66d-1dce8989888b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " 0-N char with timestamps (Inpu  [(None, None, 87)]  0           []                               \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, None, 87)    348         ['0-N char with timestamps[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " lstm_14 (LSTM)                 (None, None, 128)    110592      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, None, 128)    0           ['lstm_14[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, None, 128)   512         ['dropout_7[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)                 (None, 128)          131584      ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " N+1 char without timestamps (I  [(None, 83)]        0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 211)          0           ['lstm_15[0][0]',                \n",
      "                                                                  'N+1 char without timestamps[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 211, 1)       0           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " gru_29 (GRU)                   (None, 211, 128)     50304       ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " time_distributed_20 (TimeDistr  (None, 211, 64)     8256        ['gru_29[0][0]']                 \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " gru_30 (GRU)                   (None, 32)           9408        ['time_distributed_20[0][0]']    \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 2)            66          ['gru_30[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 311,070\n",
      "Trainable params: 310,640\n",
      "Non-trainable params: 430\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1 = keras.layers.Input(shape=[None, unit_time_depth], name='0-N char with timestamps')\n",
    "input_2 = keras.layers.Input(shape=[unit_time_depth-4], name='N+1 char without timestamps')\n",
    "batch_1 = keras.layers.BatchNormalization()(input_1)\n",
    "lstm_1 = keras.layers.LSTM(128, return_sequences=True, recurrent_dropout=0.2)(batch_1)\n",
    "dropout_1 = keras.layers.Dropout(0.5)(lstm_1)\n",
    "batch_2 = keras.layers.BatchNormalization()(dropout_1)\n",
    "lstm_2 = keras.layers.LSTM(128, recurrent_dropout=0.2)(batch_2)\n",
    "concat = keras.layers.concatenate([lstm_2, input_2])\n",
    "reshape = keras.layers.Reshape((128+unit_time_depth-4, 1))(concat)\n",
    "gru_1 = keras.layers.GRU(128, return_sequences=True, recurrent_dropout=0.2)(reshape)\n",
    "dense_1 = keras.layers.TimeDistributed(keras.layers.Dense(64), activity_regularizer=tf.keras.regularizers.L2(0.01))(gru_1)\n",
    "gru_2 = keras.layers.GRU(32, recurrent_dropout=0.2)(dense_1)\n",
    "output = keras.layers.Dense(2)(gru_2)\n",
    "model3 = keras.Model(inputs=[input_1, input_2], outputs=[output])\n",
    "\n",
    "model3.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jdV1AmlQo2p7",
    "Q9lQejHloimA"
   ],
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
