{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0057f9-9fcc-4864-82a4-dca536191c0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing Libraries and Preprocessing Function (add `INDEX`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3bf7d2-0439-401e-8c38-ef901c5bdb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c7e90d-4bf8-49c6-91c0-790651bda432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_folder(folder_path, train_size=0.8):\n",
    "    path = os.path.join(os.getcwd(), folder_path)\n",
    "    files = sorted(os.listdir(path), key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "    samples = []\n",
    "    cols = []\n",
    "    for i, path in enumerate(files):\n",
    "        path = os.path.join(os.getcwd(), folder_path, path)\n",
    "        with open(path) as f:\n",
    "            lines = f.readlines()\n",
    "        ## extract column names (once)\n",
    "        if i == 1:\n",
    "            ls = lines[0].split('\\t')\n",
    "            if re.findall(r'\\w+|\\d+', ls[-1]):\n",
    "                ls[-1] = re.findall(r'\\w+|\\d+', ls[-1])[0]\n",
    "                cols = ls\n",
    "        ## extracting all samples from the current file\n",
    "        sample = []\n",
    "        curr_text_id = ''\n",
    "        curr_index = -1\n",
    "        for line in lines[1:]:\n",
    "            ls = line.split('\\t')\n",
    "            if re.findall(r'\\w+|\\d+', ls[-1]):\n",
    "                ls[-1] = re.findall(r'\\w+|\\d+', ls[-1])[0]\n",
    "                if ls[1] != curr_text_id:\n",
    "                    curr_index = 0\n",
    "                    curr_text_id = ls[1]\n",
    "                else:\n",
    "                    curr_index += 1\n",
    "                ls.append(curr_index)\n",
    "                sample.append(ls)\n",
    "        ##  split the current data into train-test-sets\n",
    "        split_index = int(train_size * len(sample))\n",
    "        train_samples = train_samples + sample[:split_index]\n",
    "        test_samples = test_samples + sample[split_index:]\n",
    "        samples = samples + sample\n",
    "    ## forming dataframes\n",
    "    df_all = pd.DataFrame(samples)\n",
    "    df_train = pd.DataFrame(train_samples)\n",
    "    df_test = pd.DataFrame(test_samples)\n",
    "    ## renaming columns\n",
    "    cols = cols + ['INDEX']\n",
    "    df_all.columns, df_train.columns, df_test.columns = cols, cols, cols\n",
    "    return df_all, df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b309877-eae0-478e-9220-eca9b7e48be5",
   "metadata": {},
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a8eccbe-403a-4059-9d50-94aaa79e7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../data/keystroke_sample_old\"\n",
    "data, train_data, test_data = processing_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64ed22e6-98de-4d47-942f-396f5c6ee4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire dataset: 149 users; \n",
      "Train dataset: 149 users; \n",
      "Test dataset: 149 users.\n"
     ]
    }
   ],
   "source": [
    "## number of users used in this dataset\n",
    "print(f\"Entire dataset: {len(data['PARTICIPANT_ID'].unique())} users; \\\n",
    "\\nTrain dataset: {len(train_data['PARTICIPANT_ID'].unique())} users; \\\n",
    "\\nTest dataset: {len(test_data['PARTICIPANT_ID'].unique())} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd865650-c0d6-4908-b60a-164bf8f59bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARTICIPANT_ID</th>\n",
       "      <th>TEST_SECTION_ID</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>USER_INPUT</th>\n",
       "      <th>KEYSTROKE_ID</th>\n",
       "      <th>PRESS_TIME</th>\n",
       "      <th>RELEASE_TIME</th>\n",
       "      <th>LETTER</th>\n",
       "      <th>KEYCODE</th>\n",
       "      <th>INDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>The others raise their eyebrows.</td>\n",
       "      <td>The others raise their eyebrows</td>\n",
       "      <td>204</td>\n",
       "      <td>1471934383592</td>\n",
       "      <td>1471934383760</td>\n",
       "      <td>SHIFT</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>The others raise their eyebrows.</td>\n",
       "      <td>The others raise their eyebrows</td>\n",
       "      <td>203</td>\n",
       "      <td>1471934383701</td>\n",
       "      <td>1471934383760</td>\n",
       "      <td>T</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>The others raise their eyebrows.</td>\n",
       "      <td>The others raise their eyebrows</td>\n",
       "      <td>205</td>\n",
       "      <td>1471934383838</td>\n",
       "      <td>1471934383910</td>\n",
       "      <td>h</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PARTICIPANT_ID TEST_SECTION_ID                          SENTENCE  \\\n",
       "0              5               7  The others raise their eyebrows.   \n",
       "1              5               7  The others raise their eyebrows.   \n",
       "2              5               7  The others raise their eyebrows.   \n",
       "\n",
       "                        USER_INPUT KEYSTROKE_ID     PRESS_TIME   RELEASE_TIME  \\\n",
       "0  The others raise their eyebrows          204  1471934383592  1471934383760   \n",
       "1  The others raise their eyebrows          203  1471934383701  1471934383760   \n",
       "2  The others raise their eyebrows          205  1471934383838  1471934383910   \n",
       "\n",
       "  LETTER KEYCODE  INDEX  \n",
       "0  SHIFT      16      0  \n",
       "1      T      84      1  \n",
       "2      h      72      2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b852f7-7be3-4a72-b064-4259449a1e0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Keyboard Layout Encoding (QWERTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96391e5d-072c-45ae-840c-e16df55d9caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>111</td>\n",
       "      <td>106</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>67</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>191</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>110</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1    2    3    4    5    6    7    8    9   ...   13  14  15   16  \\\n",
       "0   27  27  112  113  114  115  116  117  118  119  ...  123   0   0  145   \n",
       "1    0   0    0    0    0    0    0    0    0    0  ...    0   0   0    0   \n",
       "2  192  49   50   51   52   53   54   55   56   57  ...    8   0  45   36   \n",
       "3    9  81   87   69   82   84   89   85   73   79  ...  220   0  46   35   \n",
       "4   20  65   83   68   70   71   72   74   75   76  ...   13   0   0    0   \n",
       "5   16  16   90   88   67   86   66   78   77  188  ...   16   0   0   38   \n",
       "6   17  17  191   18   32   32   32   32   32   18  ...   17   0  37   40   \n",
       "\n",
       "    17  18   19   20   21   22  \n",
       "0  126   0    0    0    0    0  \n",
       "1    0   0    0    0    0    0  \n",
       "2   33   0  144  111  106  109  \n",
       "3   34   0  103  104  105  107  \n",
       "4    0   0  100  101  102  107  \n",
       "5    0   0   97   98   99   13  \n",
       "6   39   0   96   96  110   13  \n",
       "\n",
       "[7 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = [27, 27, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 0, 0, 145, 126, 0, 0, 0, 0, 0]\n",
    "space = [0] * 23\n",
    "second_row = [192, 49, 50, 51, 52, 53, 54, 55, 56, 57, 48, 189, 187, 8, 0, 45, 36, 33, 0, 144, 111, 106, 109]\n",
    "third_row = [9, 81, 87, 69, 82, 84, 89, 85, 73, 79, 80, 219, 221, 220, 0, 46, 35, 34, 0, 103, 104, 105, 107]\n",
    "fourth_row = [20, 65, 83, 68, 70, 71, 72, 74, 75, 76, 186, 222, 13, 13, 0, 0, 0, 0, 0, 100, 101, 102, 107]\n",
    "fifth_row = [16, 16, 90, 88, 67, 86, 66, 78, 77, 188, 190, 191, 16, 16, 0, 0, 38, 0, 0, 97, 98, 99, 13]\n",
    "sixth_row = [17, 17, 191, 18, 32, 32, 32, 32, 32, 18, 92, 93, 17, 17, 0, 37, 40, 39, 0, 96, 96, 110, 13]\n",
    "qwerty_keyboard = pd.DataFrame({'1st': first_row,\n",
    "                                'space': space,\n",
    "                                '2nd': second_row,\n",
    "                                '3rd': third_row,\n",
    "                                '4th': fourth_row,\n",
    "                                '5th': fifth_row,\n",
    "                                '6th': sixth_row}).transpose()\n",
    "qwerty_keyboard.index = list(range(7))\n",
    "qwerty_keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "292fde17-d8d8-484f-b9ff-df44ef33263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function turning the pandas dataframe keyboard into dictionary\n",
    "def keycode_position(keyboard):\n",
    "    keyboard_dict = {}\n",
    "    for row in keyboard.index:\n",
    "        for col, entry in enumerate(keyboard.iloc[row, :]):\n",
    "            if entry in keyboard_dict:\n",
    "                keyboard_dict[entry].append([row, col])\n",
    "            else:\n",
    "                keyboard_dict[entry] = [[row, col]]\n",
    "    return keyboard_dict\n",
    "\n",
    "## function determining the keycode distances (if multiple entry exists, assumes the shortest one)\n",
    "def keycode_distance(keyboard_pos, keycode1, keycode2):\n",
    "    def manhattan_dist(arr1, arr2):\n",
    "        return abs(arr1[0] - arr2[0]) + abs(arr1[1] - arr2[1])\n",
    "    distance = 30 ## any integer larger than 22+6\n",
    "    if keycode1 in keyboard_pos and keycode2 in keyboard_pos:\n",
    "        for arr1 in keyboard_pos[keycode1]:\n",
    "            for arr2 in keyboard_pos[keycode2]:\n",
    "                curr_dist = manhattan_dist(arr1, arr2)\n",
    "                if curr_dist < distance:\n",
    "                    distance = curr_dist\n",
    "        if distance < 5:\n",
    "            return distance\n",
    "    return 5\n",
    "\n",
    "## function determining the distance of a list of keys to the home keys (ASDF JKL;)\n",
    "def home_distance(keyboard_pos, keycode_list):\n",
    "    '''\n",
    "    In QWERTY keyboard, F and H are the home keys with keycodes 70 and 74 resp.\n",
    "    '''\n",
    "    sum = 0\n",
    "    for key in keycode_list:\n",
    "        sum += min([keycode_distance(keyboard_pos, 70, key), keycode_distance(keyboard_pos, 74, key)])\n",
    "    return sum/len(keycode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d02e8ba-69a5-43d1-92de-be3d36b8c3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwerty_keyboard_pos = keycode_position(qwerty_keyboard)\n",
    "keycode_distance(qwerty_keyboard_pos, 85, 117), home_distance(qwerty_keyboard_pos, [72])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5200915-8cb6-4dde-868a-427652cf1c83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preprocessing - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05070591-313b-4015-8f2f-94e39dc5b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(data, keycode_distance, home_distance, keyboard_pos):\n",
    "    df = data[['PARTICIPANT_ID', 'PRESS_TIME', 'RELEASE_TIME', 'KEYCODE', 'INDEX']]\n",
    "    df = df.astype('int64')\n",
    "    df = df.rename(columns={'PARTICIPANT_ID': 'USER'})\n",
    "\n",
    "    df['K1'] = df['KEYCODE']\n",
    "    df['K2'] = pd.concat([df['KEYCODE'][1:], pd.Series([0])], ignore_index=True)\n",
    "    df['I1'] = df['INDEX']\n",
    "    df['I2'] = pd.concat([df['INDEX'][1:], pd.Series([0])], ignore_index=True)\n",
    "    df['HL1'] = df['RELEASE_TIME'] - df['PRESS_TIME']\n",
    "    df['IL'] = pd.concat([df['PRESS_TIME'][1:], pd.Series([0])], ignore_index=True) - df['RELEASE_TIME']\n",
    "    df['HL2'] = pd.concat([df['HL1'][1:], pd.Series([0])], ignore_index=True)\n",
    "\n",
    "    keycode_dist = []\n",
    "    home_dist = []\n",
    "    for row in df.index:\n",
    "        keycode_dist.append(keycode_distance(keyboard_pos, df['K1'][row], df['K2'][row]))\n",
    "        home_dist.append(home_distance(keyboard_pos, [df['K1'][row], df['K2'][row]]))\n",
    "    df['KD'] = keycode_dist\n",
    "    df['HD'] = home_dist\n",
    "\n",
    "    df = df.drop(columns=['PRESS_TIME', 'RELEASE_TIME', 'KEYCODE', 'INDEX'])\n",
    "    df = df.iloc[:-1, :]\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_keycode_dict(top=42, add_UNK=True):\n",
    "    keycode_dict = {keycode: i for i, keycode in enumerate(data['KEYCODE'].astype('int32').value_counts()[:top].to_dict().keys())}\n",
    "    if add_UNK:\n",
    "        keycode_dict[0] = len(keycode_dict)\n",
    "    return keycode_dict\n",
    "\n",
    "\n",
    "def single_kdi_image(curr_chunk, mat_length, keycode_dict):\n",
    "    mat_kd = np.zeros((mat_length, mat_length))\n",
    "    mat_hd = np.zeros((mat_length, mat_length))\n",
    "    mat_index = np.zeros((mat_length, mat_length))\n",
    "    mat_hl1 = np.zeros((mat_length, mat_length))\n",
    "    mat_il = np.zeros((mat_length, mat_length))\n",
    "    mat_hl2 = np.zeros((mat_length, mat_length))\n",
    "    count = np.zeros((mat_length, mat_length))\n",
    "\n",
    "    ## form input image\n",
    "    for row in curr_chunk.index[:-1]:\n",
    "        i = curr_chunk['K1'][row]\n",
    "        j = curr_chunk['K2'][row]\n",
    "        if i in keycode_dict:\n",
    "            i = keycode_dict[i]\n",
    "        else:\n",
    "            i = keycode_dict[0]\n",
    "        if j in keycode_dict:\n",
    "            j = keycode_dict[j]\n",
    "        else:\n",
    "            j = keycode_dict[0]\n",
    "\n",
    "        mat_kd[i, j] += curr_chunk['KD'][row]\n",
    "        mat_hd[i, j] += curr_chunk['HD'][row]\n",
    "        mat_index[i, j] += curr_chunk['I1'][row]\n",
    "        mat_hl1[i, j] += curr_chunk['HL1'][row]\n",
    "        mat_il[i, j] += curr_chunk['IL'][row]\n",
    "        mat_hl2[i, j] += curr_chunk['HL2'][row]\n",
    "        count[i, j] += 1\n",
    "    mat_kd = np.divide(mat_kd, count, out=np.zeros_like(mat_kd), where=count!=0)\n",
    "    mat_hd = np.divide(mat_hd, count, out=np.zeros_like(mat_hd), where=count!=0)\n",
    "    mat_index = np.divide(mat_index, count, out=np.zeros_like(mat_index), where=count!=0)\n",
    "    mat_hl1 = np.divide(mat_hl1, count, out=np.zeros_like(mat_hl1), where=count!=0)\n",
    "    mat_il = np.divide(mat_il, count, out=np.zeros_like(mat_il), where=count!=0)\n",
    "    mat_hl2 = np.divide(mat_hl2, count, out=np.zeros_like(mat_hl2), where=count!=0)\n",
    "\n",
    "    kdi_image = np.stack([mat_kd, mat_hd, mat_index, mat_hl1, mat_il, mat_hl2], axis=-1)\n",
    "\n",
    "    ## form output vector\n",
    "    row = curr_chunk.index[-1]\n",
    "    b1_a1 = curr_chunk['IL'][row]\n",
    "    b2_b1 = curr_chunk['HL2'][row]\n",
    "    \n",
    "    return kdi_image, np.array([b1_a1, b2_b1])\n",
    "\n",
    "\n",
    "def generate_kdi_images(data, mat_length, window, shift):\n",
    "    keycode_dict = generate_keycode_dict(top=mat_length-1)    ## -1 to offset the 0:mat_length in dict\n",
    "    window_length = window + 1\n",
    "    input_arr = []\n",
    "    output_arr = []\n",
    "    for user in data['USER'].unique():\n",
    "        curr_ds = data[data['USER'] == user]\n",
    "        i = 0\n",
    "        while i + window_length < len(curr_ds.index):\n",
    "            curr_chunk = curr_ds.loc[curr_ds.index[i:i+window_length]]\n",
    "            curr_image, curr_output = single_kdi_image(curr_chunk, mat_length, keycode_dict)\n",
    "            input_arr.append(curr_image)\n",
    "            output_arr.append(curr_output)\n",
    "            i = i + shift\n",
    "        if i < len(curr_ds.index) - 1:\n",
    "            curr_chunk = curr_ds.loc[curr_ds.index[i:]]\n",
    "            curr_image, curr_output = single_kdi_image(curr_chunk, mat_length, keycode_dict)\n",
    "            input_arr.append(curr_image)\n",
    "            output_arr.append(curr_output)\n",
    "    return np.stack(input_arr, axis=0), np.stack(output_arr, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773aedb-8a45-405f-94c2-f6e00659d816",
   "metadata": {},
   "source": [
    "# Generate `tf.data.Dataset` Object for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eface99-fa85-4161-a12e-958d9fdf2152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:37:59.281568: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-11 15:37:59.281950: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "mat_length = 40\n",
    "window = 30\n",
    "shift = 5\n",
    "batch_size = 128\n",
    "\n",
    "train_df = feature_extractor(train_data, keycode_distance, home_distance, qwerty_keyboard_pos)\n",
    "test_df = feature_extractor(test_data, keycode_distance, home_distance, qwerty_keyboard_pos)\n",
    "\n",
    "train_kdi, train_output = generate_kdi_images(train_df, mat_length=mat_length, window=window, shift=shift)\n",
    "test_kdi, test_output = generate_kdi_images(test_df, mat_length=mat_length, window=window, shift=shift)\n",
    "\n",
    "train_kdi_ds = tf.data.Dataset.from_tensor_slices(train_kdi).batch(batch_size)\n",
    "train_output_ds = tf.data.Dataset.from_tensor_slices(train_output).batch(batch_size)\n",
    "\n",
    "test_kdi_ds = tf.data.Dataset.from_tensor_slices(test_kdi).batch(batch_size)\n",
    "test_output_ds = tf.data.Dataset.from_tensor_slices(test_output).batch(batch_size)\n",
    "\n",
    "trainset = tf.data.Dataset.zip((train_kdi_ds, train_output_ds))\n",
    "testset = tf.data.Dataset.zip((test_kdi_ds, test_output_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b81dd5b-e559-46b7-b945-08897b153acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 40, 40, 6]), TensorShape([128, 2]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a in test_kdi_ds.take(1):\n",
    "    tensor = a\n",
    "for a in test_output_ds.take(1):\n",
    "    output = a\n",
    "tensor.shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d40d4f-337f-4c56-a7f7-f75b750b4bb7",
   "metadata": {},
   "source": [
    "# Training: CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99492f6c-69a3-4100-acad-64f5e26764eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 38, 38, 64)        3520      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 36, 36, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 18, 18, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,506,626\n",
      "Trainable params: 3,506,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## CNN model structure\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(mat_length, mat_length, 6)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='tanh'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faf8aacd-9c17-4b97-af78-6787d529c246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:38:56.193454: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-11 15:38:56.194104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 1784040783872.0000 - mse: 1784040783872.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:39:05.602139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 10s 60ms/step - loss: 1784040783872.0000 - mse: 1784040783872.0000 - val_loss: 8155167195136.0000 - val_mse: 8155167195136.0000\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 6s 45ms/step - loss: 1784040783872.0000 - mse: 1784040783872.0000 - val_loss: 8155167195136.0000 - val_mse: 8155167195136.0000\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 6s 45ms/step - loss: 1784040783872.0000 - mse: 1784040783872.0000 - val_loss: 8155167195136.0000 - val_mse: 8155167195136.0000\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 6s 45ms/step - loss: 1784040783872.0000 - mse: 1784040783872.0000 - val_loss: 8155167195136.0000 - val_mse: 8155167195136.0000\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 6s 45ms/step - loss: 1784040783872.0000 - mse: 1784040783872.0000 - val_loss: 8155167195136.0000 - val_mse: 8155167195136.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mse', metrics=['mse'])\n",
    "EPOCH = 5\n",
    "history = model.fit(trainset, epochs=EPOCH, validation_data=testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06ab12bb-8a58-4a6e-baa6-6a14c581f26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:39:35.822281: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - ETA: 0s - loss: 29637.6016 - mae: 29637.6016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:39:41.684231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 7s 47ms/step - loss: 29637.6016 - mae: 29637.6016 - val_loss: 134478.5312 - val_mae: 134478.5312\n",
      "Epoch 2/5\n",
      "133/133 [==============================] - 6s 45ms/step - loss: 29637.6016 - mae: 29637.6016 - val_loss: 134478.5312 - val_mae: 134478.5312\n",
      "Epoch 3/5\n",
      "133/133 [==============================] - 6s 44ms/step - loss: 29637.6016 - mae: 29637.6016 - val_loss: 134478.5312 - val_mae: 134478.5312\n",
      "Epoch 4/5\n",
      "133/133 [==============================] - 6s 44ms/step - loss: 29637.6016 - mae: 29637.6016 - val_loss: 134478.5312 - val_mae: 134478.5312\n",
      "Epoch 5/5\n",
      "133/133 [==============================] - 6s 44ms/step - loss: 29637.6016 - mae: 29637.6016 - val_loss: 134478.5312 - val_mae: 134478.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mae', metrics=['mae'])\n",
    "EPOCH = 5\n",
    "history = model.fit(trainset, epochs=EPOCH, validation_data=testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86d98639-eb81-495a-aeb9-9eedfdadd692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER</th>\n",
       "      <th>K1</th>\n",
       "      <th>K2</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>HL1</th>\n",
       "      <th>IL</th>\n",
       "      <th>HL2</th>\n",
       "      <th>KD</th>\n",
       "      <th>HD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "      <td>88037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>258.6</td>\n",
       "      <td>66.3</td>\n",
       "      <td>66.3</td>\n",
       "      <td>27.3</td>\n",
       "      <td>27.3</td>\n",
       "      <td>118.6</td>\n",
       "      <td>-30.4</td>\n",
       "      <td>118.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>143.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>266.6</td>\n",
       "      <td>827577.3</td>\n",
       "      <td>266.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-86613766.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>124.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>274.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>382.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>44252.0</td>\n",
       "      <td>86190442.0</td>\n",
       "      <td>44252.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         USER      K1      K2      I1      I2     HL1          IL     HL2  \\\n",
       "count 88037.0 88037.0 88037.0 88037.0 88037.0 88037.0     88037.0 88037.0   \n",
       "mean    258.6    66.3    66.3    27.3    27.3   118.6       -30.4   118.6   \n",
       "std     143.2    32.2    32.2    19.4    19.4   266.6    827577.3   266.6   \n",
       "min       5.0     8.0     8.0     0.0     0.0   -63.0 -86613766.0   -63.0   \n",
       "25%     124.0    59.0    59.0    12.0    12.0    80.0        11.0    80.0   \n",
       "50%     274.0    72.0    72.0    24.0    24.0   104.0        80.0   104.0   \n",
       "75%     382.0    80.0    80.0    40.0    40.0   133.0       187.0   133.0   \n",
       "max     500.0   226.0   226.0   135.0   135.0 44252.0  86190442.0 44252.0   \n",
       "\n",
       "           KD      HD  \n",
       "count 88037.0 88037.0  \n",
       "mean      3.4     2.2  \n",
       "std       1.5     0.9  \n",
       "min       0.0     0.0  \n",
       "25%       2.0     1.5  \n",
       "50%       4.0     2.0  \n",
       "75%       5.0     2.5  \n",
       "max       5.0     5.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc40ff02-b732-4022-842b-53d2fc1aab9e",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Using MSE loss function exagerated the effect from outliers; changing to MAE, the loss looks much more reasonable. However, the training loss and validation loss is not improving at all, it might be because of the large standard deviation in the `IL` time latency feature.\n",
    "\n",
    "NEXT: \n",
    "* Try different model\n",
    "* Try looking into discarding outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5db18-17e1-4e2b-a7a7-54f4a3c0997a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
